{"cells":[{"cell_type":"markdown","source":["#**Wine Types Analysis Exercise**\n","\n","We will now focus on our main objectives of building predictive models to predict the wine types (red or white wine) based on other features. We will be following the standard classification Machine Learning pipeline in this case. \n","\n","Adapted from Dipanjan Sarkar et al. 2018. [Practical Machine Learning with Python](https://link.springer.com/book/10.1007/978-1-4842-3207-1)."],"metadata":{"id":"aDjF76ImzxKN"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"jeqbjUnXy2TX"},"outputs":[],"source":["# Import necessary dependencies\n","# We wil use matplotlib and seaborn for exploratory data analysis and visualizations\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from collections import Counter\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import LabelEncoder\n","\n","%matplotlib inline"]},{"cell_type":"markdown","source":["#Download Wine Quality Datasets"],"metadata":{"id":"saX_8Cah4fxQ"}},{"cell_type":"code","source":["!pip install wget\n","!python -m wget -o winequality-red.csv \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n","!python -m wget -o winequality-white.csv \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n","!python -m wget -o winequality.names \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality.names\""],"metadata":{"id":"Rq_CPonD4mg0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pbb4BZzYy2TY"},"source":["# Load and merge datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5u2b3VtPy2TZ"},"outputs":[],"source":["white_wine = pd.read_csv('winequality-white.csv', sep=';')\n","red_wine = # Your code goes here\n","\n","# store wine type as an attribute\n","red_wine['wine_type'] = 'red'   \n","white_wine['wine_type'] = 'white'\n","# bucket wine quality scores into qualitative quality labels\n","# Wine quality scores of 3, 4, and 5 are mapped to low quality,\n","# 6 and 7 are mapped to medium quality, 8 and 9 are mapped to high quality \n","# wines under the quality_label attribute. \n","red_wine['quality_label'] = red_wine['quality'].apply(lambda value: 'low' \n","                                                          if value <= 5 else 'medium' \n","                                                              if value <= 7 else 'high')\n","red_wine['quality_label'] = pd.Categorical(red_wine['quality_label'], \n","                                           categories=['low', 'medium', 'high'])\n","\n","white_wine['quality_label'] = white_wine['quality'].apply(lambda value: 'low' \n","                                                              if value <= 5 else 'medium' \n","                                                                  if value <= 7 else 'high')\n","white_wine['quality_label'] = pd.Categorical(white_wine['quality_label'], \n","                                             categories=['low', 'medium', 'high'])\n","\n","# merge red and white wine datasets\n","wines = pd.concat([red_wine, white_wine])\n","# re-shuffle records just to randomize data points\n","wines = wines.sample(frac=1, random_state=42).reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{"id":"6NisWsPzy2Ta"},"source":["# Understand dataset features and values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NNVKwRe6y2Ta"},"outputs":[],"source":["print(white_wine.shape, red_wine.shape)\n","print(wines.info())"]},{"cell_type":"markdown","source":["We have 4898 white wine data points and 1599 red wine data points. The\n","merged dataset contains a total of 6497 data points and we also get an idea of numeric and categorical\n","attributes."],"metadata":{"id":"K3thHV0SEuIf"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"23TI5msyy2Tb"},"outputs":[],"source":["# Letâ€™s take a peek at our dataset to see some sample data points.\n","wines.head()"]},{"cell_type":"markdown","source":["#Utilty functions for model evaluation"],"metadata":{"id":"HDPzEHdm26N7"}},{"cell_type":"code","source":["from sklearn import metrics\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.base import clone\n","from sklearn.preprocessing import label_binarize\n","from scipy import interp\n","from sklearn.metrics import roc_curve, auc \n","\n","def get_metrics(true_labels, predicted_labels):\n","    \n","    print('Accuracy:', np.round(\n","                        metrics.accuracy_score(true_labels, \n","                                               predicted_labels),\n","                        4))\n","    print('Precision:', np.round(\n","                        metrics.precision_score(true_labels, \n","                                               predicted_labels,\n","                                               average='weighted'),\n","                        4))\n","    print('Recall:', np.round(\n","                        metrics.recall_score(true_labels, \n","                                               predicted_labels,\n","                                               average='weighted'),\n","                        4))\n","    print('F1 Score:', np.round(\n","                        metrics.f1_score(true_labels, \n","                                               predicted_labels,\n","                                               average='weighted'),\n","                        4))\n","def display_classification_report(true_labels, predicted_labels, classes=[1,0]):\n","\n","    report = metrics.classification_report(y_true=true_labels, \n","                                           y_pred=predicted_labels, \n","                                           labels=classes) \n","    print(report)\n","    \n","def display_confusion_matrix(true_labels, predicted_labels, classes=[1,0]):\n","    \n","    total_classes = len(classes)\n","    level_labels = [total_classes*[0], list(range(total_classes))]\n","    cm = metrics.confusion_matrix(y_true=true_labels, y_pred=predicted_labels, \n","                                  labels=classes)\n","    cm_frame = pd.DataFrame(data=cm, \n","                            columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n","                                                  codes=level_labels), \n","                            index=pd.MultiIndex(levels=[['Actual:'], classes], \n","                                                codes=level_labels)) \n","    print(cm_frame) \n","\n","def display_model_performance_metrics(true_labels, predicted_labels, classes=[1,0]):\n","    print('Model Performance metrics:')\n","    print('-'*30)\n","    get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)\n","    print('\\nModel Classification report:')\n","    print('-'*30)\n","    display_classification_report(true_labels=true_labels, predicted_labels=predicted_labels, \n","                                  classes=classes)\n","    print('\\nPrediction Confusion Matrix:')\n","    print('-'*30)\n","    display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels, \n","                             classes=classes)\n","\n","def plot_model_roc_curve(clf, features, true_labels, label_encoder=None, class_names=None):\n","    \n","    ## Compute ROC curve and ROC area for each class\n","    fpr = dict()\n","    tpr = dict()\n","    roc_auc = dict()\n","    if hasattr(clf, 'classes_'):\n","        class_labels = clf.classes_\n","    elif label_encoder:\n","        class_labels = label_encoder.classes_\n","    elif class_names:\n","        class_labels = class_names\n","    else:\n","        raise ValueError('Unable to derive prediction classes, please specify class_names!')\n","    n_classes = len(class_labels)\n","    y_test = label_binarize(true_labels, classes=class_labels)\n","    if n_classes == 2:\n","        if hasattr(clf, 'predict_proba'):\n","            prob = clf.predict_proba(features)\n","            y_score = prob[:, prob.shape[1]-1] \n","        elif hasattr(clf, 'decision_function'):\n","            prob = clf.decision_function(features)\n","            y_score = prob[:, prob.shape[1]-1]\n","        else:\n","            raise AttributeError(\"Estimator doesn't have a probability or confidence scoring system!\")\n","        \n","        fpr, tpr, _ = roc_curve(y_test, y_score)      \n","        roc_auc = auc(fpr, tpr)\n","        plt.plot(fpr, tpr, label='ROC curve (area = {0:0.2f})'\n","                                 ''.format(roc_auc),\n","                 linewidth=2.5)\n","        \n","    elif n_classes > 2:\n","        if hasattr(clf, 'predict_proba'):\n","            y_score = clf.predict_proba(features)\n","        elif hasattr(clf, 'decision_function'):\n","            y_score = clf.decision_function(features)\n","        else:\n","            raise AttributeError(\"Estimator doesn't have a probability or confidence scoring system!\")\n","\n","        for i in range(n_classes):\n","            fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n","            roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","        ## Compute micro-average ROC curve and ROC area\n","        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n","        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","\n","        ## Compute macro-average ROC curve and ROC area\n","        # First aggregate all false positive rates\n","        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n","        # Then interpolate all ROC curves at this points\n","        mean_tpr = np.zeros_like(all_fpr)\n","        for i in range(n_classes):\n","            mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n","        # Finally average it and compute AUC\n","        mean_tpr /= n_classes\n","        fpr[\"macro\"] = all_fpr\n","        tpr[\"macro\"] = mean_tpr\n","        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","\n","        ## Plot ROC curves\n","        plt.figure(figsize=(6, 4))\n","        plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n","                 label='micro-average ROC curve (area = {0:0.2f})'\n","                       ''.format(roc_auc[\"micro\"]), linewidth=3)\n","\n","        plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n","                 label='macro-average ROC curve (area = {0:0.2f})'\n","                       ''.format(roc_auc[\"macro\"]), linewidth=3)\n","\n","        for i, label in enumerate(class_labels):\n","            plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n","                                           ''.format(label, roc_auc[i]), \n","                     linewidth=2, linestyle=':')\n","    else:\n","        raise ValueError('Number of classes should be atleast 2 or more')\n","        \n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver Operating Characteristic (ROC) Curve')\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","def plot_model_decision_surface(clf, train_features, train_labels,\n","                                plot_step=0.02, cmap=plt.cm.RdYlBu,\n","                                markers=None, alphas=None, colors=None):\n","    \n","    if train_features.shape[1] != 2:\n","        raise ValueError(\"X_train should have exactly 2 columnns!\")\n","    \n","    x_min, x_max = train_features[:, 0].min() - plot_step, train_features[:, 0].max() + plot_step\n","    y_min, y_max = train_features[:, 1].min() - plot_step, train_features[:, 1].max() + plot_step\n","    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n","                         np.arange(y_min, y_max, plot_step))\n","\n","    clf_est = clone(clf)\n","    clf_est.fit(train_features,train_labels)\n","    if hasattr(clf_est, 'predict_proba'):\n","        Z = clf_est.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:,1]\n","    else:\n","        Z = clf_est.predict(np.c_[xx.ravel(), yy.ravel()])    \n","    Z = Z.reshape(xx.shape)\n","    cs = plt.contourf(xx, yy, Z, cmap=cmap)\n","    \n","    le = LabelEncoder()\n","    y_enc = le.fit_transform(train_labels)\n","    n_classes = len(le.classes_)\n","    plot_colors = ''.join(colors) if colors else [None] * n_classes\n","    label_names = le.classes_\n","    markers = markers if markers else [None] * n_classes\n","    alphas = alphas if alphas else [None] * n_classes\n","    for i, color in zip(range(n_classes), plot_colors):\n","        idx = np.where(y_enc == i)\n","        plt.scatter(train_features[idx, 0], train_features[idx, 1], c=color,\n","                    label=label_names[i], cmap=cmap, edgecolors='black', \n","                    marker=markers[i], alpha=alphas[i])\n","    plt.legend()\n","    plt.show()\n"],"metadata":{"id":"mtYsmo4VaLUG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Predicting Wine Types\n","\n","We will predict the wine type based on other features. To start with, we\n","will first select our necessary features and separate out the prediction class labels and prepare train and test\n","datasets. We use the prefix **wtp_** in our variables to easily identify them as needed, where **wtp** depicts wine\n","type prediction."],"metadata":{"id":"EshuYVJGaZKT"}},{"cell_type":"code","source":["wtp_features = wines.iloc[:,:-3]\n","wtp_feature_names = wtp_features.columns\n","wtp_class_labels = np.array(wines['wine_type'])\n","\n","# prepare train and test datasets\n","\n","wtp_train_X, wtp_test_X, wtp_train_y, wtp_test_y = # Your code goes here\n","\n","print(Counter(wtp_train_y), Counter(wtp_test_y))\n","print('Features:', list(wtp_feature_names))"],"metadata":{"id":"aBMtfCKVaxYL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The numbers show us the wine samples for each class and we can also see the feature names which will\n","be used in our feature set."],"metadata":{"id":"P-vSMGE3a4l5"}},{"cell_type":"markdown","source":["##Feature Scaling\n","\n","We will be using a standard scaler in this\n","scenario."],"metadata":{"id":"v3dBYvDYbAj3"}},{"cell_type":"code","source":["# Define the scaler \n","wtp_ss = # Your code goes here\n","\n","# Scale the train set\n","wtp_train_SX = wtp_ss.transform(wtp_train_X)\n","\n","# Scale the test set\n","wtp_test_SX = # Your code goes here"],"metadata":{"id":"VPL5QwIpbO6k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Train a Model using Logistic Regression\n","Since we are dealing with a binary classification problem, one of the traditional Machine Learning\n","algorithms we can use is the logistic regression model."],"metadata":{"id":"2p3HzmG0blZh"}},{"cell_type":"markdown","source":["###Train the model using LogisticRegression"],"metadata":{"id":"66IV1ND_0IU0"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","# Your code goes here\n"],"metadata":{"id":"KMh1giqObxdH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Evaluate model performance"],"metadata":{"id":"4DJq-KA_rjm8"}},{"cell_type":"code","source":["# letâ€™s predict the wine types for our test data samples and evaluate the performance.\n","\n","wtp_lr_predictions = # Your code goes here\n","display_model_performance_metrics(true_labels=wtp_test_y, predicted_labels=wtp_lr_predictions, \n","                                      classes=['red', 'white'])"],"metadata":{"id":"hacpZPrHb-Ll"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We get an overall F1 Score and model accuracy of 99.2%! In spite of low samples of red wine, we seem to do pretty well. In case your models do not perform\n","well on other datasets due to a class imbalance problem, you can consider over-sampling or under-sampling\n","techniques including sample selection as well as SMOTE."],"metadata":{"id":"drwr0kBNcVE7"}},{"cell_type":"markdown","source":["##Model Interpretation"],"metadata":{"id":"rNUM5Wj2rKMy"}},{"cell_type":"code","source":["# Install skater package\n","!pip install git+https://github.com/oracle/Skater.git"],"metadata":{"id":"_xfBUs0JqmO6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Visualize Feature Importances"],"metadata":{"id":"PVgC2kDWrZOg"}},{"cell_type":"code","source":["from skater.core.explanations import Interpretation\n","from skater.model import InMemoryModel\n","\n","wtp_interpreter = # Your code goes here\n","wtp_im_model = # Your code goes here\n","plots = wtp_interpreter.feature_importance.plot_feature_importance(wtp_im_model, ascending=False)"],"metadata":{"id":"JCzpeRfKqZF0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can see that density, total sulfur dioxide, and residual sugar are the top three\n","features that contributed toward classifying wine samples as red or white"],"metadata":{"id":"vYK6tpgW0a8H"}},{"cell_type":"markdown","source":["###Visualize model ROC Curve"],"metadata":{"id":"2NcRRSCb0qL3"}},{"cell_type":"code","source":["plot_model_roc_curve(wtp_lr, wtp_test_SX, wtp_test_y)"],"metadata":{"id":"BsVsCzYp0xtp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We achieved almost 100% accuracy if you remember for this model and hence the ROC curve is almost\n","perfect where we also see that the area under curve (AUC) is 1 which is perfect."],"metadata":{"id":"ys3iimL-1cLU"}},{"cell_type":"markdown","source":["###Visualize Model Decision Surface"],"metadata":{"id":"goqrBr9X1knL"}},{"cell_type":"code","source":["feature_indices = [i for i, feature in enumerate(wtp_feature_names) \n","                       if feature in ['density', 'total sulfur dioxide']]\n","plot_model_decision_surface(clf=wtp_lr, train_features=wtp_train_SX[:, feature_indices], \n","                                train_labels=wtp_train_y, plot_step=0.02, cmap=plt.cm.Wistia_r,\n","                                markers=[',', 'o'], alphas=[0.9, 0.6], colors=['r', 'y'])"],"metadata":{"id":"737qMam-1zwK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The plot shows that our model has learned the underlying patterns\n","quite well based on just the two most important features, which it has used to separate out majority\n","of the red wine samples from the white wine samples depicted by the scatter dots. There are very few\n","misclassifications here and there, which are evident based on the statistics we obtained earlier in the\n","confusion matrices."],"metadata":{"id":"hD8r0szw16DM"}}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python [conda root]","language":"python","name":"conda-root-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"Day_4_Exercise_2_Predicting_Wine_Types.ipynb","provenance":[{"file_id":"1BAwv-ZWceuHdPiMHaH5pIYTodebTOpPD","timestamp":1647425924042},{"file_id":"1BEYzOscw_o15MGFSkP82XY8ULEb0CBuY","timestamp":1647425788020},{"file_id":"https://github.com/dipanjanS/practical-machine-learning-with-python/blob/master/notebooks/Ch09_Analyzing_Wine_Types_and_Quality/Exploratory%20Data%20Analysis.ipynb","timestamp":1647368180157}],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}