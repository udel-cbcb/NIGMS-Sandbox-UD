{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c62320c1-a28c-45b6-80e1-121c99c5ecd1",
   "metadata": {},
   "source": [
    "# **Diabetes Prediction using Logistic Regression (Exercise)**\n",
    "\n",
    "Adapted from Dipanjan Sarkar et al. 2018. [Practical Machine Learning with Python](https://link.springer.com/book/10.1007/978-1-4842-3207-1).\n",
    "\n",
    "## **Overview**\n",
    "This notebook aims to develop a **logistic regression model** to predict whether a patient has diabetes based on medical measurements. We will perform **data preprocessing, model training, evaluation, and interpretability analysis** using **SHAP**.\n",
    "\n",
    "The dataset used is the **Pima Indians Diabetes Dataset**, which contains medical diagnostic data such as glucose level, BMI, insulin levels, and age.\n",
    "\n",
    "---\n",
    "\n",
    "## **Learning Objectives**\n",
    "By the end of this notebook, you will be able to:\n",
    "- Load and preprocess a real-world medical dataset.\n",
    "- Train and evaluate a **logistic regression classifier** for diabetes prediction.\n",
    "- Analyze model performance using metrics such as **accuracy, precision, recall, and F1-score**.\n",
    "- Visualize the **ROC curve** to assess the classifier’s ability to distinguish between diabetic and non-diabetic patients.\n",
    "- Use **SHAP** to interpret model predictions and understand feature importance.\n",
    "- Plot the **decision boundary** of the classifier to visualize how features contribute to predictions.\n",
    "\n",
    "---\n",
    "\n",
    "## **Tasks to Complete**\n",
    "1. **Load and explore the dataset**\n",
    "   - Read the dataset and check for missing values or inconsistencies.\n",
    "   - Convert categorical labels into meaningful categories.\n",
    "\n",
    "2. **Preprocess the data**\n",
    "   - Standardize numerical features using **StandardScaler**.\n",
    "   - Split the data into **training and test sets**.\n",
    "\n",
    "3. **Train a logistic regression model**\n",
    "   - Fit a logistic regression model to predict diabetes.\n",
    "   - Evaluate the model using **classification metrics**.\n",
    "\n",
    "4. **Interpret the model’s decisions**\n",
    "   - Generate **SHAP summary plots** to understand feature importance.\n",
    "   - Plot the **ROC curve** to assess model discrimination ability.\n",
    "\n",
    "5. **Visualize decision boundaries**\n",
    "   - Plot decision surfaces for **Glucose** and **BMI** to understand decision regions.\n",
    "\n",
    "---\n",
    "\n",
    "## **Prerequisites**\n",
    "Before running this notebook, ensure you have the following:\n",
    "- **Python 3.6+**\n",
    "- Required libraries installed:\n",
    "  ```bash\n",
    "  pip install numpy pandas matplotlib seaborn shap scikit-learn lime\n",
    "\n",
    "\n",
    "## Get Started\n",
    "\n",
    "- Please select kernel \"conda_tensorflow2_p310\" from SageMaker notebook instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0a490f-f6fe-453f-bd92-25ff17eae5af",
   "metadata": {},
   "source": [
    "### Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3d18f1-cad4-4eac-baa4-daa1176a522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic command to install required Python packages using pip: numpy, pandas, matplotlib, seaborn, shap, scikit-learn, and lime.\n",
    "%pip install numpy pandas matplotlib seaborn shap scikit-learn lime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c90b8aa-dd9d-4ed7-b975-eeec7178dbed",
   "metadata": {},
   "source": [
    "### Import necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473e1b70-4b8a-4af5-894c-3387379ab138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the matplotlib.pyplot module for plotting and visualization, aliased as plt.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imports the numpy library for numerical operations, especially for arrays and matrices, aliased as np.\n",
    "import numpy as np\n",
    "\n",
    "# Imports the pandas library for data manipulation and analysis, particularly using DataFrames, aliased as pd.\n",
    "import pandas as pd\n",
    "\n",
    "# Imports the read_csv function from pandas to read CSV files into DataFrames.\n",
    "from pandas import read_csv\n",
    "\n",
    "# Imports the shap library for explaining the output of machine learning models.\n",
    "import shap\n",
    "\n",
    "# Imports the lime library for explaining individual predictions of machine learning models.\n",
    "import lime\n",
    "\n",
    "# Imports the lime_tabular module from the lime library, specifically for tabular data explanation.\n",
    "import lime.lime_tabular\n",
    "\n",
    "# Imports the Counter class from the collections module to count hashable objects.\n",
    "from collections import Counter\n",
    "\n",
    "# Imports the metrics module from scikit-learn for evaluating model performance.\n",
    "from sklearn import metrics\n",
    "\n",
    "# Imports the clone function from scikit-learn.base to create copies of estimators.\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Imports the LogisticRegression class from scikit-learn.linear_model for logistic regression models.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Imports the auc and roc_curve functions from scikit-learn.metrics for ROC curve analysis.\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "# Imports the train_test_split function from scikit-learn.model_selection to split data into training and testing sets.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Imports LabelEncoder and StandardScaler from scikit-learn.preprocessing for data preprocessing tasks like label encoding and standardization.\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, label_binarize\n",
    "\n",
    "# Set up plotting style\n",
    "# plt.style.use(\"seaborn-whitegrid\")\n",
    "# Magic command for Jupyter/IPython to display matplotlib plots inline within the notebook.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6acbb6e-ec37-40dc-bc4a-1d8c5ed06253",
   "metadata": {},
   "source": [
    "# Pima Indians Diabetes Dataset\n",
    "\n",
    "## Overview\n",
    "The **Pima Indians Diabetes Dataset** is a well-known dataset used for binary classification tasks in machine learning, specifically for predicting whether a patient has diabetes based on various medical attributes. The dataset originates from the **National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK)** and focuses on female patients of **Pima Indian heritage**.\n",
    "\n",
    "## Source\n",
    "- **Dataset Repository:** [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/12/pima+indians+diabetes)\n",
    "- **Original Source:** National Institute of Diabetes and Digestive and Kidney Diseases\n",
    "- **Purpose:** Predicting the onset of diabetes based on diagnostic measurements.\n",
    "\n",
    "## Dataset Description\n",
    "The dataset contains **768 samples** with **8 numerical features** and **1 binary target variable** (diabetes outcome).\n",
    "\n",
    "### **Features:**\n",
    "1. **Pregnancies** – Number of times pregnant  \n",
    "2. **Glucose** – Plasma glucose concentration over 2 hours in an oral glucose tolerance test  \n",
    "3. **BloodPressure** – Diastolic blood pressure (mm Hg)  \n",
    "4. **SkinThickness** – Triceps skinfold thickness (mm)  \n",
    "5. **Insulin** – 2-Hour serum insulin (mu U/ml)  \n",
    "6. **BMI** – Body mass index (weight in kg/(height in m²))  \n",
    "7. **DiabetesPedigreeFunction** – Diabetes pedigree function (genetic influence)  \n",
    "8. **Age** – Age of the patient (years)  \n",
    "9. **Outcome** – Binary classification (1 = Diabetic, 0 = Non-Diabetic)  \n",
    "\n",
    "## Summary Statistics\n",
    "- **Total samples:** 768  \n",
    "- **Diabetes positive cases (Outcome = 1):** ~35%  \n",
    "- **Diabetes negative cases (Outcome = 0):** ~65%  \n",
    "- **Missing values:** Some attributes contain zero values which may indicate missing data (e.g., Glucose, BloodPressure).\n",
    "\n",
    "## Example Usage\n",
    "This dataset is frequently used in **machine learning** and **statistical modeling** for:\n",
    "- Logistic Regression\n",
    "- Decision Trees & Random Forests\n",
    "- Support Vector Machines (SVM)\n",
    "- Deep Learning\n",
    "- Feature Engineering and Imputation Techniques\n",
    "\n",
    "## References\n",
    "- UCI Machine Learning Repository: [Pima Indians Diabetes Dataset](https://archive.ics.uci.edu/dataset/12/pima+indians+diabetes)\n",
    "- Smith, J. W., et al. \"Using the ADAP learning algorithm to forecast the onset of diabetes mellitus.\" In Proceedings of the Annual Symposium on Computer Application in Medical Care. American Medical Informatics Association, 1988."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9613c6a8-faad-4ab5-8579-cddb6afe2e5b",
   "metadata": {},
   "source": [
    "## Load pima-indians-diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99f8004-739f-4e7f-98b0-a66fc008af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pima-indians-diabetes dataset with the correct structure\n",
    "# Specify the file path to the dataset\n",
    "diabetes_data = \"../../Data/pima-indians-diabetes.csv\"\n",
    "\n",
    "# Define column names for the dataset based on pima-indians-diabetes.names\n",
    "# The 'Outcome' column is the target variable (class), indicating diabetes (1) or no diabetes (0)\n",
    "columns = [\n",
    "    'Pregnancies',              # Number of times pregnant\n",
    "    'Glucose',                  # Plasma glucose concentration (2 hours in an oral glucose tolerance test)\n",
    "    'BloodPressure',            # Diastolic blood pressure (mm Hg)\n",
    "    'SkinThickness',            # Triceps skinfold thickness (mm)\n",
    "    'Insulin',                  # 2-Hour serum insulin (mu U/ml)\n",
    "    'BMI',                      # Body mass index (weight in kg / (height in m)^2)\n",
    "    'DiabetesPedigreeFunction', # Diabetes pedigree function (a genetic risk score)\n",
    "    'Age',                      # Age in years\n",
    "    'Outcome'                   # Target variable: 1 = diabetes, 0 = no diabetes\n",
    "]\n",
    "\n",
    "# Load the dataset using pandas' read_csv function\n",
    "# Parameters:\n",
    "# - diabetes_data: Path to the CSV file\n",
    "# - header=None: The file has no header row\n",
    "# - names=columns: Use the defined column names\n",
    "# - na_values=\"?\": Treat \"?\" as missing values\n",
    "# - sep=',': The file is comma-separated\n",
    "df = read_csv(\n",
    "    diabetes_data,\n",
    "    header=None,\n",
    "    names=columns,\n",
    "    na_values=\"?\",\n",
    "    sep=','\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17684ea-e1ac-49fb-afdc-abaeb45c45b8",
   "metadata": {},
   "source": [
    "## Understand dataset features and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b250e7-3873-4543-8d2f-08fd1bff7b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts numerical 'Outcome' column to categorical 'outcome' column with string labels for better readability.\n",
    "df['outcome'] = df['Outcome'].map({0: 'non-diabetic', 1: 'diabetic'})\n",
    "\n",
    "# Creates a new column 'outcome_numeric' with explicitly numerical labels for model training (non-diabetic: 0, diabetic: 1).\n",
    "df['outcome_numeric'] = df['outcome'].map({'non-diabetic': 0, 'diabetic': 1})\n",
    "\n",
    "# Assigns the 'outcome_numeric' column to the variable 'labels_numeric' to be used as numerical labels for training.\n",
    "labels_numeric = df['outcome_numeric'] # Use numerical labels for training\n",
    "\n",
    "\n",
    "# Create age groups\n",
    "# Defines bins for age groups, used to categorize patients by age ranges.\n",
    "bins = [20, 30, 40, 50, 60, 100]\n",
    "\n",
    "# Defines labels for each age group bin, providing descriptive names for the age categories.\n",
    "labels = ['20-29', '30-39', '40-49', '50-59', '60+']\n",
    "\n",
    "# Creates a new column 'age_group' by categorizing the 'Age' column into the defined age bins and assigning corresponding labels.\n",
    "df['age_group'] = pd.cut(df['Age'], bins=bins, labels=labels)\n",
    "\n",
    "# Prints the shape of the DataFrame (number of rows and columns).\n",
    "print(df.shape)\n",
    "\n",
    "# Prints a concise summary of the DataFrame, including data types and non-null values.\n",
    "print(df.info())\n",
    "\n",
    "# Displays the first few rows of the DataFrame to visually inspect the data and column structure.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa43647-8b38-4284-ae3d-9513459d985e",
   "metadata": {},
   "source": [
    "## Domain Knowledge\n",
    "\n",
    "### Key Health Indicators\n",
    "\n",
    "- **Pregnancies:** Number of times pregnant\n",
    "- **Glucose:** Plasma glucose concentration (mg/dL)\n",
    "- **BloodPressure:** Diastolic blood pressure (mm Hg)\n",
    "- **SkinThickness:** Triceps skin fold thickness (mm)\n",
    "- **Insulin:** 2-Hour serum insulin (mu U/ml)\n",
    "- **BMI:** Body mass index (kg/m²)\n",
    "- **DiabetesPedigreeFunction:** Diabetes risk genetic score\n",
    "- **Age:** Years\n",
    "- **Outcome:** Diabetes diagnosis (0 = Negative, 1 = Positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd0bb1b-f080-46a8-b1ed-991c71dfbef0",
   "metadata": {},
   "source": [
    "## Define helper functions for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cda3d1-d572-4bed-930c-e212cf5a73ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes accuracy, precision, recall, and F1 score.\n",
    "# Defines a function called 'get_metrics' that takes true labels and predicted labels as input.\n",
    "def get_metrics(true_labels, predicted_labels):\n",
    "    \"\"\"Calculate and print accuracy, precision, recall, and F1 score.\"\"\"\n",
    "    # Prints the accuracy score, rounded to 4 decimal places, by comparing true and predicted labels.\n",
    "    print(\"Accuracy:\", np.round(metrics.accuracy_score(true_labels, predicted_labels), 4))\n",
    "    \n",
    "    # Prints the precision score, rounded to 4 decimal places, using weighted average for multi-class, comparing true and predicted labels.\n",
    "    print(\"Precision:\", np.round(metrics.precision_score(true_labels, predicted_labels, average=\"weighted\"), 4))\n",
    "    \n",
    "    # Prints the recall score, rounded to 4 decimal places, using weighted average for multi-class, comparing true and predicted labels.\n",
    "    print(\"Recall:\", np.round(metrics.recall_score(true_labels, predicted_labels, average=\"weighted\"), 4))\n",
    "    \n",
    "    # Prints the F1 score, rounded to 4 decimal places, using weighted average for multi-class, comparing true and predicted labels.\n",
    "    print(\"F1 Score:\", np.round(metrics.f1_score(true_labels, predicted_labels, average=\"weighted\"), 4))\n",
    "\n",
    "# Defines a function called 'display_classification_report' that takes true labels, predicted labels, and class names as input.\n",
    "def display_classification_report(true_labels, predicted_labels, classes):\n",
    "    # Docstring explaining the function's purpose: \"Display a detailed classification report.\"\n",
    "    \"\"\"Display a detailed classification report.\"\"\"\n",
    "    # Generates a classification report using scikit-learn's metrics.classification_report, including precision, recall, F1-score, and support.\n",
    "    report = metrics.classification_report(true_labels, predicted_labels, labels=classes)\n",
    "    \n",
    "    # Prints the generated classification report to the console.\n",
    "    print(report)\n",
    "\n",
    "# Defines a function to display a confusion matrix.\n",
    "def display_confusion_matrix(true_labels, predicted_labels, classes):\n",
    "    \"\"\"Display a confusion matrix.\"\"\"\n",
    "    # Calculates the confusion matrix using true labels and predicted labels, specifying the order of classes.\n",
    "    cm = metrics.confusion_matrix(true_labels, predicted_labels, labels=classes)\n",
    "    \n",
    "    # Creates a Pandas DataFrame from the confusion matrix, using class names for index and columns.\n",
    "    cm_frame = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "    \n",
    "    # Prints the title \"Confusion Matrix:\".\n",
    "    print(\"Confusion Matrix:\")\n",
    "    \n",
    "    # Prints the confusion matrix DataFrame.\n",
    "    print(cm_frame)\n",
    "\n",
    "# Combines the above functions to display overall model performance.\n",
    "# Defines a function called 'display_model_performance_metrics' that takes true labels, predicted labels, and class names as input.\n",
    "def display_model_performance_metrics(true_labels, predicted_labels, classes):\n",
    "    \"\"\"Display model performance metrics.\"\"\"\n",
    "    # Prints a title \"Model Performance Metrics:\" to indicate the start of the metrics display.\n",
    "    print(\"Model Performance Metrics:\")\n",
    "    \n",
    "    # Prints a separator line of 30 hyphens for visual clarity.\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Calls the 'get_metrics' function to calculate and print accuracy, precision, recall, and F1 score.\n",
    "    get_metrics(true_labels, predicted_labels)\n",
    "    \n",
    "    # Prints a newline character to create spacing before the classification report.\n",
    "    print(\"\\nClassification Report:\")\n",
    "    \n",
    "    # Prints another separator line of 30 hyphens for visual clarity.\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Calls the 'display_classification_report' function to print a detailed classification report.\n",
    "    display_classification_report(true_labels, predicted_labels, classes)\n",
    "    \n",
    "    # Prints a newline character to create spacing before the confusion matrix.\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    \n",
    "    # Prints another separator line of 30 hyphens for visual clarity.\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Calls the 'display_confusion_matrix' function to print the confusion matrix.\n",
    "    display_confusion_matrix(true_labels, predicted_labels, classes)\n",
    "\n",
    "# Plots the ROC curve and calculates the AUC (Area Under the Curve).\n",
    "# Defines a function to plot the ROC curve for a given classifier.\n",
    "def plot_model_roc_curve(clf, features, true_labels, class_names):\n",
    "    \"\"\"Plot ROC curve for the model.\"\"\"\n",
    "    # Binarizes the true labels to be compatible with ROC curve calculation, handling multiple classes if present.\n",
    "    y_test = label_binarize(true_labels, classes=class_names)\n",
    "    \n",
    "    # Checks if the classifier 'clf' has a 'predict_proba' method (for probabilistic classifiers).\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        # If 'predict_proba' exists, use it to get probability scores for each class.\n",
    "        y_score = clf.predict_proba(features)\n",
    "        \n",
    "    # If 'predict_proba' does not exist (for non-probabilistic classifiers).\n",
    "    else:\n",
    "        # Use 'decision_function' to get decision scores (fallback for ROC curve calculation).\n",
    "        y_score = clf.decision_function(features)\n",
    "\n",
    "    # Calculates the False Positive Rate (fpr), True Positive Rate (tpr), and thresholds for the ROC curve.\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score[:, 1])\n",
    "    \n",
    "    # Calculates the Area Under the ROC Curve (AUC) using the calculated fpr and tpr.\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Create a new figure with a specified size (8 inches wide, 6 inches tall)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # Plot the ROC curve:\n",
    "    # - fpr: False Positive Rate (x-axis)\n",
    "    # - tpr: True Positive Rate (y-axis)\n",
    "    # - Label the curve with the AUC (Area Under the Curve) value, formatted to 2 decimal places\n",
    "    # - Set the line width to 2 for better visibility\n",
    "    plt.plot(fpr, tpr, label=f\"ROC curve (area = {roc_auc:.2f})\", linewidth=2)\n",
    "    \n",
    "    # Plot the diagonal dashed line (representing a random classifier):\n",
    "    # - [0, 1] and [0, 1] define the start and end points of the line\n",
    "    # - \"k--\" specifies a black dashed line\n",
    "    # - Set the line width to 2 for consistency\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", linewidth=2)\n",
    "    \n",
    "    # Set the x-axis limits to range from 0.0 to 1.0\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    \n",
    "    # Set the y-axis limits to range from 0.0 to 1.05 (slightly above 1.0 for better visualization)\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    \n",
    "    # Label the x-axis as \"False Positive Rate\"\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    \n",
    "    # Label the y-axis as \"True Positive Rate\"\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    \n",
    "    # Set the title of the plot to \"Receiver Operating Characteristic (ROC) Curve\"\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "    \n",
    "    # Add a legend to the plot, positioned in the lower right corner\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "# Visualizes the decision boundary of a model for two features.\n",
    "# Defines a function to plot the decision surface of a classifier.\n",
    "def plot_model_decision_surface(\n",
    "    clf, # Classifier object (e.g., LogisticRegression) to plot decision surface for.\n",
    "    train_features, # Training features (NumPy array or DataFrame) - should have exactly 2 columns.\n",
    "    train_labels, # Training labels (NumPy array or Series) corresponding to train_features.\n",
    "    plot_step=0.02, # Step size for creating the meshgrid for the plot.\n",
    "    cmap=plt.cm.RdYlBu, # Colormap to use for filling the contour plot regions.\n",
    "    markers=None, # List of markers to use for each class in the scatter plot.\n",
    "    alphas=None, # List of alpha values for each class in the scatter plot.\n",
    "    colors=None, # List of colors to use for each class in the scatter plot.\n",
    "):\n",
    "    # Checks if the input training features have exactly 2 columns, raises ValueError if not.\n",
    "    if train_features.shape[1] != 2:\n",
    "        raise ValueError(\"X_train should have exactly 2 columnns!\")\n",
    "\n",
    "    # Calculate minimum and maximum values for the first feature (x-axis) and add plot_step margin.\n",
    "    x_min, x_max = (\n",
    "        train_features[:, 0].min() - plot_step,\n",
    "        train_features[:, 0].max() + plot_step,\n",
    "    )\n",
    "    \n",
    "    # Calculate minimum and maximum values for the second feature (y-axis) and add plot_step margin.\n",
    "    y_min, y_max = (\n",
    "        train_features[:, 1].min() - plot_step,\n",
    "        train_features[:, 1].max() + plot_step,\n",
    "    )\n",
    "    \n",
    "    # Create a meshgrid of points using numpy.arange for x and y ranges with plot_step intervals.\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.arange(x_min, x_max, plot_step), np.arange(y_min, y_max, plot_step)\n",
    "    )\n",
    "\n",
    "    # Create a clone of the classifier to avoid modifying the original classifier.\n",
    "    clf_est = clone(clf)\n",
    "    \n",
    "    # Fit the cloned classifier on the provided training features and labels.\n",
    "    clf_est.fit(train_features, train_labels)\n",
    "    \n",
    "    # Checks if the classifier has a 'predict_proba' method (for probability estimates).\n",
    "    if hasattr(clf_est, \"predict_proba\"):\n",
    "        # Predict probabilities for each point in the meshgrid using the fitted classifier, taking probability of the positive class ([:, 1]).\n",
    "        Z = clf_est.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "        \n",
    "    # If 'predict_proba' is not available, use 'predict' for class labels directly.\n",
    "    else:\n",
    "        # Predict class labels for each point in the meshgrid using the fitted classifier.\n",
    "        Z = clf_est.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        \n",
    "    # Reshape the prediction results 'Z' to match the shape of the meshgrid 'xx'.\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Create a filled contour plot (decision surface) using matplotlib, with colors based on 'Z' and colormap 'cmap'.\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=cmap)\n",
    "\n",
    "    # Initialize LabelEncoder to encode string labels to numerical values.\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    # Fit and transform the training labels to numerical encoded labels.\n",
    "    y_enc = le.fit_transform(train_labels)\n",
    "    \n",
    "    # Determine the number of classes from the LabelEncoder.\n",
    "    n_classes = len(le.classes_)\n",
    "    \n",
    "    # Use provided colors or default to None, joining colors into a string if provided.\n",
    "    plot_colors = \"\".join(colors) if colors else [None] * n_classes\n",
    "    \n",
    "    # Get the class names from the LabelEncoder.\n",
    "    label_names = le.classes_\n",
    "    \n",
    "    # Use provided markers or default to None.\n",
    "    markers = markers if markers else [None] * n_classes\n",
    "    \n",
    "    # Use provided alpha values or default to None.\n",
    "    alphas = alphas if alphas else [None] * n_classes\n",
    "    \n",
    "    # Iterate through each class index and color.\n",
    "    for i, color in zip(range(n_classes), plot_colors):\n",
    "        # Find indices of data points belonging to the current class.\n",
    "        idx = np.where(y_enc == i)\n",
    "        \n",
    "        # Create a scatter plot for each class, using features from train_features, color, label, edge color, marker, and alpha.\n",
    "        plt.scatter(\n",
    "            train_features[idx, 0],\n",
    "            train_features[idx, 1],\n",
    "            c=[color] * len(idx[0]),  # Ensure color mapping\n",
    "            label=label_names[i],\n",
    "            edgecolors=\"black\",\n",
    "            marker=markers[i],\n",
    "            alpha=alphas[i],\n",
    "        )\n",
    "    # Display the legend to identify classes in the scatter plot.\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show the plot.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcd7687-6b7e-4227-a234-f2c3f6f95f8e",
   "metadata": {},
   "source": [
    "### Prepare Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc3374f-82c6-47d0-81e5-3da2d4a6a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and labels\n",
    "# Features are prepared by dropping non-feature columns (Outcome, outcome, age_group).\n",
    "features = df.drop(columns=['Outcome', 'outcome', 'age_group', 'outcome_numeric'])  # Drop non-feature columns\n",
    "feature_names = features.columns\n",
    "\n",
    "# Labels are set as the categorical outcome column.\n",
    "labels = df['outcome']  # Use the categorical outcome column\n",
    "\n",
    "# The data is split into training and testing sets using an 70-30 split.\n",
    "\n",
    "train_X, test_X, train_y, test_y =# Your code goes here\n",
    "\n",
    "print(\"Train Class Distribution:\", Counter(train_y))\n",
    "print(\"Test Class Distribution:\", Counter(test_y))\n",
    "print(\"Features:\", list(feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de359e5a-4a57-4ff2-b03c-7ac30e40d02f",
   "metadata": {},
   "source": [
    "### Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020cf5b6-1065-4665-8674-040939335652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The features are standardized using StandardScaler to ensure all features are on the same scale.\n",
    "# Initializes StandardScaler and fits it to the training feature data (train_X) to learn scaling parameters (mean and std).\n",
    "\n",
    "# Your code goes here\n",
    "\n",
    "# Transforms the training feature data (train_X) using the fitted scaler to standardize it (mean=0, std=1), storing the result in train_SX.\n",
    "train_SX = scaler.transform(train_X)\n",
    "\n",
    "# Transforms the testing feature data (test_X) using the SAME fitted scaler to standardize it, ensuring consistent scaling with training data, storing the result in test_SX.\n",
    "test_SX = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cab2942-ceb7-42f4-87f1-9b3132319864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# Initializes a Logistic Regression model from scikit-learn.\n",
    "\n",
    "# Your code goes here\n",
    "\n",
    "# Trains the Logistic Regression model using the standardized training features (train_SX) and training labels (train_y).\n",
    "\n",
    "# Your code goes here\n",
    "\n",
    "# Prints the class labels that the model has been trained to predict, useful for understanding class order.\n",
    "print(\"Model Classes:\", model.classes_) # Check the order of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c22fb51-cccd-4fd5-9775-8e27e1d9ed92",
   "metadata": {},
   "source": [
    "### Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88272b10-bbfe-4aa5-9351-e035b41f78a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions are made on the test set using the trained logistic regression model.\n",
    "\n",
    "# Your code goes here\n",
    "\n",
    "# Model performance is evaluated and printed to console.\n",
    "# Prints a header indicating the start of model performance metrics.\n",
    "print(\"Model Performance:\")\n",
    "\n",
    "# Prints the classification report, including precision, recall, F1-score, and support for each class, using true test labels and model predictions.\n",
    "print(metrics.classification_report(test_y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd80dd6-6ec0-4629-b07b-b4349d15a61b",
   "metadata": {},
   "source": [
    "The model is doing a decent job overall (74% accuracy) at predicting diabetes. However, it's better at identifying non-diabetic patients than diabetic patients. When it predicts someone is diabetic, it's correct about 62% of the time, and it only correctly identifies about 62% of all the truly diabetic patients in your test data.  For non-diabetic patients, it's more accurate and finds a larger proportion of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a3ccfb-1471-45f1-9d80-9dc912ea0619",
   "metadata": {},
   "source": [
    "### Interpret the Model\n",
    "#### SHAP summary plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034d4d9b-1ca9-4c98-95e0-ea89b444352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP (SHapley Additive exPlanations) is used to explain the model's predictions by calculating feature importance and visualizing it using a summary plot.\n",
    "# Creates a SHAP explainer object for the logistic regression model, using the scaled training features as background data.\n",
    "\n",
    "# Your code goes here\n",
    "\n",
    "# Calculates SHAP values for the test dataset using the explainer.\n",
    "\n",
    "# Your code goes here\n",
    "\n",
    "# Generates a SHAP summary plot to visualize feature importance and their impact on model output, passing class names for clarity.\n",
    "shap.summary_plot(shap_values, test_SX, feature_names=feature_names, class_names=model.classes_) # Pass class_names to summary_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c01c418-434e-4aa3-bdde-509cf5c9319b",
   "metadata": {},
   "source": [
    "**SHAP Summary Plot Interpretation:**\n",
    "\n",
    "This SHAP summary plot shows the relationships between the features and the diabetes prediction model.  \n",
    "\n",
    "Here's a breakdown of feature importance and their impact:\n",
    "\n",
    "*   **Glucose:** **Most important feature.** Higher glucose levels strongly **increase** the model's prediction of diabetes (red dots on the right). Lower glucose levels decrease the prediction (blue dots on the left).\n",
    "\n",
    "*   **BMI (Body Mass Index):** **Second most important.** Higher BMI values **increase** the likelihood of a \"diabetic\" prediction (red dots on the right). Lower BMI values decrease the prediction (blue dots on the left).\n",
    "\n",
    "*   **Age:** **Positive impact on diabetes prediction.** Older age tends to **increase** the prediction of diabetes (redder dots slightly on the right).\n",
    "\n",
    "*   **DiabetesPedigreeFunction:** **Positive influence.** Higher DiabetesPedigreeFunction (family history) **increases** the diabetes prediction (red dots shifted to the right).\n",
    "\n",
    "*   **Pregnancies:** **Weak positive association.** Higher number of pregnancies might have a slight tendency to **increase** diabetes prediction, but the effect is less clear and more mixed.\n",
    "\n",
    "*   **BloodPressure:** **Weak and mixed impact.**  BloodPressure has a less strong and less consistent impact, with a slight tendency for higher blood pressure to weakly **increase** diabetes prediction.\n",
    "\n",
    "*   **Insulin & SkinThickness:** **Weakest impact.** These features appear to be the least influential in this model for diabetes prediction, showing minimal and inconsistent effects.\n",
    "\n",
    "**Key Takeaway:**\n",
    "\n",
    "The SHAP plot now provides a much more **sensible and clinically plausible interpretation** of the logistic regression model's behavior for diabetes prediction. The model now highlights Glucose and BMI as dominant risk factors, with Age and family history also contributing in the positive direction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83606dc2-62a5-42d4-aa32-0d3bd5874f7d",
   "metadata": {},
   "source": [
    "#### Plots the ROC curve and calculates the AUC (Area Under the Curve)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd84e577-ac20-4808-9a5f-6719049f5e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calls the function 'plot_model_roc_curve' to generate and display the ROC curve.\n",
    "plot_model_roc_curve(\n",
    "    # Specifies the trained machine learning model (Logistic Regression).\n",
    "    model,\n",
    "    # Specifies the standardized features of the test dataset.\n",
    "    test_SX,\n",
    "    # Specifies the true labels for the test dataset.\n",
    "    test_y,\n",
    "    # Passes the class names from the trained model to be used in the ROC curve plot.\n",
    "    class_names=model.classes_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32596e58-782c-4fa8-9834-a17ea1208d6e",
   "metadata": {},
   "source": [
    "**Interpretation of the ROC Curve (AUC = 0.80)**\n",
    "\n",
    "The **Receiver Operating Characteristic (ROC) curve** is a visual tool to evaluate the performance of a binary classification model, showing the trade-off between the True Positive Rate (TPR) and False Positive Rate (FPR) at different thresholds.\n",
    "\n",
    "**Key Components:**\n",
    "\n",
    "*   **X-axis: False Positive Rate (FPR)**:  The proportion of actual non-diabetic patients incorrectly predicted as diabetic. Lower is better.\n",
    "*   **Y-axis: True Positive Rate (TPR)**: The proportion of actual diabetic patients correctly predicted as diabetic (Sensitivity/Recall). Higher is better.\n",
    "*   **Diagonal Dashed Line**: Represents a random classifier (no discriminatory ability).\n",
    "*   **Blue Curve (Model's ROC Curve)**: Shows the performance of the Logistic Regression model. The further the curve is towards the top-left corner, the better the model.\n",
    "*   **AUC (Area Under the Curve) = 0.80**: A single value summarizing the overall performance.\n",
    "\n",
    "**Interpreting the ROC Curve and AUC = 0.80:**\n",
    "\n",
    "*   **Curve Shape**: The blue curve is significantly above the diagonal line, indicating the model performs **much better than random guessing**. It demonstrates a good ability to distinguish between diabetic and non-diabetic patients.\n",
    "*   **AUC Value**:  An AUC of **0.80 is considered excellent discrimination**.  It suggests that there's an 80% chance the model can correctly differentiate between a randomly selected diabetic and non-diabetic patient.\n",
    "*   **Trade-off**: The curve illustrates the balance between TPR and FPR. Moving right on the curve (higher FPR) increases TPR. The optimal threshold depends on the desired balance between minimizing false positives vs. false negatives for the specific application.\n",
    "\n",
    "**Overall Model Performance:**\n",
    "\n",
    "The ROC curve and AUC of 0.80 indicate that the Logistic Regression model exhibits **good to excellent performance** in classifying diabetes risk based on the provided features. It demonstrates a strong ability to discriminate between diabetic and non-diabetic patients within the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d9e00d-a4d2-44d6-84ae-63d0d0487eba",
   "metadata": {},
   "source": [
    "### Plot decision surface for Glucose and BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd4bbfb-128d-4f58-8bbb-511c417c4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The decision surface for two specific features (Glucose and BMI) is plotted to visualize how the model separates the classes.\n",
    "# Define a list to store the indices of the features 'Glucose' and 'BMI'.\n",
    "feature_indices = [\n",
    "    # Iterate through the feature names along with their indices.\n",
    "    i\n",
    "    # 'enumerate(feature_names)' generates pairs of (index, feature_name).\n",
    "    for i, feature in enumerate(feature_names)\n",
    "    # Check if the current 'feature' is either \"Glucose\" or \"BMI\".\n",
    "    if feature in [\"Glucose\", \"BMI\"]\n",
    "]\n",
    "# Call the function 'plot_model_decision_surface' to visualize the decision boundary.\n",
    "plot_model_decision_surface(\n",
    "    # Pass the trained Logistic Regression model 'model' to the function.\n",
    "    clf=model,\n",
    "    # Select the standardized training features corresponding to 'Glucose' and 'BMI' using 'feature_indices'.\n",
    "\n",
    "    # Your code goes here\n",
    "    \n",
    "    # Pass the training labels 'train_y' to the function.\n",
    "\n",
    "    # Your code goes here\n",
    "    \n",
    "    # Set the step size for creating the meshgrid for the decision surface plot.\n",
    "\n",
    "    # Your code goes here\n",
    "    \n",
    "    # Choose the colormap 'Wistia_r' for the decision surface plot.\n",
    "    cmap=plt.cm.Wistia_r,\n",
    "    # Define markers for the scatter plot points representing different classes.\n",
    "    markers=[\",\", \"o\"],\n",
    "    # Set alpha transparency values for the scatter plot points.\n",
    "    alphas=[0.9, 0.6],\n",
    "    # Define colors for the scatter plot points representing different classes.\n",
    "    colors=[\"r\", \"y\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9d3c47-af94-469b-a4f5-1532a10a3716",
   "metadata": {},
   "source": [
    "**Interpretation of the Decision Surface for Glucose and BMI**\n",
    "\n",
    "This plot visualizes the **decision surface** of the Logistic Regression model when using only **Glucose** and **BMI** as predictor features for diabetes. It shows how the model separates the feature space into regions associated with 'non-diabetic' (Class 0) and 'diabetic' (Class 1) predictions.\n",
    "\n",
    "**Key Components:**\n",
    "\n",
    "*   **X-axis: Glucose**: Represents the standardized Glucose level.\n",
    "*   **Y-axis: BMI**: Represents the standardized Body Mass Index.\n",
    "*   **Background Colors**:\n",
    "    *   **Yellow Region (Upper Right)**:  Represents the decision region where the model predicts **'diabetic' (Class 1)**.  Any data point falling in this yellow area would be classified as diabetic by the model.\n",
    "    *   **Orange/Red Region (Lower Left)**: Represents the decision region where the model predicts **'non-diabetic' (Class 0)**. Data points in this area would be classified as non-diabetic.\n",
    "    *   **Color Gradient**: The gradual change in color from orange to yellow visually represents the probability gradient.  Areas closer to yellow have a higher probability of being classified as 'diabetic', while areas closer to orange have a higher probability of being 'non-diabetic'.\n",
    "*   **Markers**:\n",
    "    *   **Red Squares**: Represent the actual data points from the **'non-diabetic' (Class 0)** training set.\n",
    "    *   **Yellow Circles**: Represent the actual data points from the **'diabetic' (Class 1)** training set.\n",
    "\n",
    "**Decision Boundary:**\n",
    "\n",
    "*   The **boundary** between the orange/red and yellow regions is the **decision boundary** of the Logistic Regression model.  It's approximately a straight, diagonal line running from the top-left to the bottom-right of the plot.\n",
    "*   This line represents where the model is **50% confident** in predicting either class. On one side of the line, the probability of 'diabetic' is greater than 50%, and on the other side, it's less than 50%.\n",
    "\n",
    "**Interpreting the Decision Surface:**\n",
    "\n",
    "*   **Glucose and BMI as Predictors**: The plot clearly shows how Glucose and BMI together influence the model's diabetes predictions.\n",
    "*   **Higher Glucose and BMI = 'Diabetic' Prediction**:  As you move towards the **upper-right** of the plot (increasing both Glucose and BMI), you enter the yellow 'diabetic' prediction region. This visually confirms that **higher Glucose and higher BMI values increase the likelihood of the model predicting diabetes.** This aligns with medical understanding of diabetes risk factors.\n",
    "*   **Lower Glucose and BMI = 'Non-Diabetic' Prediction**: Conversely, as you move towards the **lower-left** (decreasing both Glucose and BMI), you are in the orange/red 'non-diabetic' region. **Lower Glucose and BMI values decrease the likelihood of a 'diabetic' prediction.**\n",
    "*   **Linear Decision Boundary**: The straight line decision boundary is characteristic of Logistic Regression. It indicates that the model is learning a linear relationship between the log-odds of diabetes and the combination of Glucose and BMI.\n",
    "*   **Data Point Distribution**: You can observe how the actual data points (squares and circles) are distributed relative to the decision boundary. There is some overlap, especially in the middle, which is expected in real-world datasets.  The model is trying to find the best linear separation possible.\n",
    "\n",
    "**In Summary:**\n",
    "\n",
    "The decision surface plot effectively visualizes how your Logistic Regression model uses Glucose and BMI to predict diabetes. It demonstrates that the model learns to associate higher Glucose and BMI values with a higher probability of diabetes, and vice versa, using a linear decision boundary to separate the two classes in the Glucose-BMI feature space. This plot provides an intuitive understanding of the model's decision-making process based on these two important features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887fdac8-5726-40d1-a573-bb1caf375c88",
   "metadata": {},
   "source": [
    "## Prediction using new patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335dda0f-e14d-452c-bfaa-d1605f38c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create new sample data (replace with your desired sample data)\n",
    "new_samples_data = {\n",
    "    'Sample1': {'Pregnancies': 2, 'Glucose': 100, 'BloodPressure': 70, 'SkinThickness': 25, 'Insulin': 50, 'BMI': 30.0, 'DiabetesPedigreeFunction': 0.5, 'Age': 35},\n",
    "    'Sample2': # Your code goes here\n",
    "}\n",
    "new_samples_df = pd.DataFrame.from_dict(new_samples_data, orient='index')\n",
    "\n",
    "# 2. Preprocess the new samples using the SAME scaler fitted on training data\n",
    "new_samples_scaled = scaler.transform(new_samples_df)\n",
    "\n",
    "# 3. Make predictions\n",
    "new_predictions = model.predict(new_samples_scaled)\n",
    "new_probabilities = model.predict_proba(new_samples_scaled) # Get probabilities\n",
    "\n",
    "# 4. Display the predictions\n",
    "print(\"\\n--- Predictions for New Samples ---\")\n",
    "for i, sample_name in enumerate(new_samples_data.keys()):\n",
    "    prediction = new_predictions[i]\n",
    "    probability_non_diabetic = new_probabilities[i][0] * 100 # Probability for 'non-diabetic' class\n",
    "    probability_diabetic = new_probabilities[i][1] * 100    # Probability for 'diabetic' class\n",
    "    print(f\"Sample: {sample_name}\")\n",
    "    print(f\"  Predicted Outcome: {prediction}\")\n",
    "    print(f\"  Probability (non-diabetic): {probability_non_diabetic:.2f}%\")\n",
    "    print(f\"  Probability (diabetic): {probability_diabetic:.2f}%\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e529d0c-414d-4abb-a54d-96e2edede30a",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Through this module, we learned how to:\n",
    "\n",
    "- Develop model that predicts diabetes risk using logistic regression.\n",
    "- Apply feature scaling to improve performance.\n",
    "- Confirm model accuracy using evaluation metrics .\n",
    "- Use SHAP to understand feature importance.\n",
    "- Use visualization techniques (ROC curve, decision boundary) to gain insights.\n",
    "\n",
    "## Clean up\n",
    "\n",
    "Remember to:\n",
    "\n",
    "- Save any generated plots and analysis results\n",
    "- Clear notebook output if sharing\n",
    "- Close dataset files\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
