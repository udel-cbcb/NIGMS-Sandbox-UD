{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Quality Analysis Exercise Solution\n",
    "\n",
    "Adapted from Dipanjan Sarkar et al. 2018. [Practical Machine Learning with Python](https://link.springer.com/book/10.1007/978-1-4842-3207-1).\n",
    "\n",
    "## Overview\n",
    "\n",
    "This module focuses on building predictive models to predict wine quality (low, medium and high) based on other features, following the standard classification Machine Learning pipeline.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Build and evaluate predictive models for wine quality classification\n",
    "- Apply and compare different machine learning algorithms:\n",
    "  - Decision Trees\n",
    "  - Random Forests\n",
    "  - Extreme Gradient Boosting\n",
    "- Interpret model results using:\n",
    "  - Feature importance analysis\n",
    "  - ROC curves\n",
    "  - Decision surfaces\n",
    "  - Partial dependence plots\n",
    "\n",
    "### Tasks to complete\n",
    "\n",
    "- Train and evaluate models using:\n",
    "  - Decision Trees\n",
    "  - Random Forests\n",
    "  - XGBoost\n",
    "- Generate model interpretations and visualizations\n",
    "- Compare model performances\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python programming environment\n",
    "- Basic understanding of statistical and machine learning concepts\n",
    "- Familiarity with common ML libraries\n",
    "\n",
    "## Get Started\n",
    "\n",
    "- Please select kernel \"conda_tensorflow2_p310\" from SageMaker notebook instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install xgboost graphviz shap lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary dependencies\n",
    "import os\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "from graphviz import Source\n",
    "from IPython.display import Image\n",
    "from numpy import interp\n",
    "from sklearn import metrics, tree\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, label_binarize\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# Set matplotlib inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and merge datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "white_wine_path = \"../../Data/winequality-white.csv\"\n",
    "red_wine_path = \"../../Data/winequality-red.csv\"\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    white_wine = pd.read_csv(white_wine_path, sep=\";\")\n",
    "    red_wine = pd.read_csv(red_wine_path, sep=\";\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Preprocessing functions\n",
    "def preprocess_wine_data(wine_df, color):\n",
    "    wine_df[\"wine_type\"] = color\n",
    "    wine_df[\"quality_label\"] = wine_df[\"quality\"].apply(\n",
    "        lambda v: \"low\" if v <= 5 else \"medium\" if v <= 7 else \"high\"\n",
    "    )\n",
    "    wine_df[\"quality_label\"] = pd.Categorical(\n",
    "        wine_df[\"quality_label\"], categories=[\"low\", \"medium\", \"high\"]\n",
    "    )\n",
    "    return wine_df\n",
    "\n",
    "# Preprocess data\n",
    "red_wine = preprocess_wine_data(red_wine, \"red\")\n",
    "white_wine = preprocess_wine_data(white_wine, \"white\")\n",
    "\n",
    "# Combine datasets\n",
    "wines = pd.concat([red_wine, white_wine], ignore_index=True)\n",
    "wines = wines.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand dataset features and values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(white_wine.shape, red_wine.shape)\n",
    "print(wines.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 4898 white wine data points and 1599 red wine data points. The\n",
    "merged dataset contains a total of 6497 data points and we also get an idea of numeric and categorical\n",
    "attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s take a peek at our dataset to see some sample data points.\n",
    "wines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilty functions for model evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(true_labels, predicted_labels):\n",
    "    print(\n",
    "        \"Accuracy:\", np.round(metrics.accuracy_score(true_labels, predicted_labels), 4)\n",
    "    )\n",
    "    print(\n",
    "        \"Precision:\",\n",
    "        np.round(\n",
    "            metrics.precision_score(true_labels, predicted_labels, average=\"weighted\"),\n",
    "            4,\n",
    "        ),\n",
    "    )\n",
    "    print(\n",
    "        \"Recall:\",\n",
    "        np.round(\n",
    "            metrics.recall_score(true_labels, predicted_labels, average=\"weighted\"), 4\n",
    "        ),\n",
    "    )\n",
    "    print(\n",
    "        \"F1 Score:\",\n",
    "        np.round(\n",
    "            metrics.f1_score(true_labels, predicted_labels, average=\"weighted\"), 4\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def display_classification_report(true_labels, predicted_labels, classes=None): # classes can be None\n",
    "    report = metrics.classification_report(y_true=true_labels, y_pred=predicted_labels, labels=classes)\n",
    "    print(report)\n",
    "\n",
    "\n",
    "def display_confusion_matrix(true_labels, predicted_labels, classes=[1, 0]):\n",
    "    total_classes = len(classes)\n",
    "    level_labels = [total_classes * [0], list(range(total_classes))]\n",
    "    cm = metrics.confusion_matrix(\n",
    "        y_true=true_labels, y_pred=predicted_labels, labels=classes\n",
    "    )\n",
    "    cm_frame = pd.DataFrame(\n",
    "        data=cm,\n",
    "        columns=pd.MultiIndex(levels=[[\"Predicted:\"], classes], codes=level_labels),\n",
    "        index=pd.MultiIndex(levels=[[\"Actual:\"], classes], codes=level_labels),\n",
    "    )\n",
    "    print(cm_frame)\n",
    "\n",
    "\n",
    "def display_model_performance_metrics(true_labels, predicted_labels, classes=[1, 0]):\n",
    "    print(\"Model Performance metrics:\")\n",
    "    print(\"-\" * 30)\n",
    "    get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)\n",
    "    print(\"\\nModel Classification report:\")\n",
    "    print(\"-\" * 30)\n",
    "    display_classification_report(\n",
    "        true_labels=true_labels, predicted_labels=predicted_labels, classes=classes\n",
    "    )\n",
    "    print(\"\\nPrediction Confusion Matrix:\")\n",
    "    print(\"-\" * 30)\n",
    "    display_confusion_matrix(\n",
    "        true_labels=true_labels, predicted_labels=predicted_labels, classes=classes\n",
    "    )\n",
    "\n",
    "def plot_model_roc_curve(\n",
    "    clf, features, true_labels, label_encoder=None, class_names=None\n",
    "):\n",
    "    ## Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    if hasattr(clf, \"classes_\"):\n",
    "        class_labels = clf.classes_\n",
    "    elif label_encoder:\n",
    "        class_labels = label_encoder.classes_\n",
    "    elif class_names:\n",
    "        class_labels = class_names\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Unable to derive prediction classes, please specify class_names!\"\n",
    "        )\n",
    "    n_classes = len(np.unique(true_labels)) # directly get the number of classes\n",
    "    y_test = label_binarize(true_labels, classes=np.unique(true_labels)) # binarize based on actual classes\n",
    "    if n_classes == 2:\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            prob = clf.predict_proba(features)\n",
    "            y_score = prob[:, prob.shape[1] - 1]\n",
    "        elif hasattr(clf, \"decision_function\"):\n",
    "            prob = clf.decision_function(features)\n",
    "            y_score = prob[:, prob.shape[1] - 1]\n",
    "        else:\n",
    "            raise AttributeError(\n",
    "                \"Estimator doesn't have a probability or confidence scoring system!\"\n",
    "            )\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(\n",
    "            fpr,\n",
    "            tpr,\n",
    "            label=\"ROC curve (area = {0:0.2f})\" \"\".format(roc_auc),\n",
    "            linewidth=2.5,\n",
    "        )\n",
    "\n",
    "    elif n_classes > 2:\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            y_score = clf.predict_proba(features)\n",
    "        elif hasattr(clf, \"decision_function\"):\n",
    "            y_score = clf.decision_function(features)\n",
    "        else:\n",
    "            raise AttributeError(\n",
    "                \"Estimator doesn't have a probability or confidence scoring system!\"\n",
    "            )\n",
    "\n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        ## Compute micro-average ROC curve and ROC area\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "        ## Compute macro-average ROC curve and ROC area\n",
    "        # First aggregate all false positive rates\n",
    "        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "        # Then interpolate all ROC curves at this points\n",
    "        mean_tpr = np.zeros_like(all_fpr)\n",
    "        for i in range(n_classes):\n",
    "            mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])  # Use numpy.interp instead of scipy.interp\n",
    "        # Finally average it and compute AUC\n",
    "        mean_tpr /= n_classes\n",
    "        fpr[\"macro\"] = all_fpr\n",
    "        tpr[\"macro\"] = mean_tpr\n",
    "        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "        ## Plot ROC curves\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.plot(\n",
    "            fpr[\"micro\"],\n",
    "            tpr[\"micro\"],\n",
    "            label=\"micro-average ROC curve (area = {0:0.2f})\" \"\".format(\n",
    "                roc_auc[\"micro\"]\n",
    "            ),\n",
    "            linewidth=3,\n",
    "        )\n",
    "\n",
    "        plt.plot(\n",
    "            fpr[\"macro\"],\n",
    "            tpr[\"macro\"],\n",
    "            label=\"macro-average ROC curve (area = {0:0.2f})\" \"\".format(\n",
    "                roc_auc[\"macro\"]\n",
    "            ),\n",
    "            linewidth=3,\n",
    "        )\n",
    "\n",
    "        for i, label in enumerate(class_labels):\n",
    "            plt.plot(\n",
    "                fpr[i],\n",
    "                tpr[i],\n",
    "                label=\"ROC curve of class {0} (area = {1:0.2f})\" \"\".format(\n",
    "                    label, roc_auc[i]\n",
    "                ),\n",
    "                linewidth=2,\n",
    "                linestyle=\":\",\n",
    "            )\n",
    "    else:\n",
    "        raise ValueError(\"Number of classes should be atleast 2 or more\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_model_decision_surface(\n",
    "    clf,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    plot_step=0.02,\n",
    "    cmap=plt.cm.RdYlBu,\n",
    "    markers=None,\n",
    "    alphas=None,\n",
    "    colors=None,\n",
    "):\n",
    "    if train_features.shape[1] != 2:\n",
    "        raise ValueError(\"X_train should have exactly 2 columnns!\")\n",
    "\n",
    "    x_min, x_max = (\n",
    "        train_features[:, 0].min() - plot_step,\n",
    "        train_features[:, 0].max() + plot_step,\n",
    "    )\n",
    "    y_min, y_max = (\n",
    "        train_features[:, 1].min() - plot_step,\n",
    "        train_features[:, 1].max() + plot_step,\n",
    "    )\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.arange(x_min, x_max, plot_step), np.arange(y_min, y_max, plot_step)\n",
    "    )\n",
    "\n",
    "    clf_est = clone(clf)\n",
    "    clf_est.fit(train_features, train_labels)\n",
    "    if hasattr(clf_est, \"predict_proba\"):\n",
    "        Z = clf_est.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "    else:\n",
    "        Z = clf_est.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=cmap)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_enc = le.fit_transform(train_labels)\n",
    "    n_classes = len(le.classes_)\n",
    "    plot_colors = \"\".join(colors) if colors else [None] * n_classes\n",
    "    label_names = le.classes_\n",
    "    markers = markers if markers else [None] * n_classes\n",
    "    alphas = alphas if alphas else [None] * n_classes\n",
    "    for i, color in zip(range(n_classes), plot_colors):\n",
    "        idx = np.where(y_enc == i)\n",
    "        plt.scatter(\n",
    "            train_features[idx, 0],\n",
    "            train_features[idx, 1],\n",
    "            c=color,\n",
    "            label=label_names[i],\n",
    "            cmap=cmap,\n",
    "            edgecolors=\"black\",\n",
    "            marker=markers[i],\n",
    "            alpha=alphas[i],\n",
    "        )\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Wine Quality\n",
    "\n",
    "We will predict the wine quality ratings based on other features.\n",
    "\n",
    "### Prepare features\n",
    "\n",
    "#### Feature selection\n",
    "\n",
    "To start with, we\n",
    "will first select our necessary features and separate out the prediction class labels and prepare train and test\n",
    "datasets. We use the prefix **wqp\\_** in our variables to easily identify them as needed, where **wqp** depicts wine\n",
    "quality prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and labels\n",
    "wqp_features = wines.iloc[:, :-3]\n",
    "wqp_class_labels = wines[\"quality_label\"]\n",
    "wqp_feature_names = list(wqp_features.columns)\n",
    "\n",
    "# Train-test split\n",
    "wqp_train_X, wqp_test_X, wqp_train_y, wqp_test_y = train_test_split(\n",
    "    wqp_features, wqp_class_labels, test_size=0.3, random_state=42, stratify=wqp_class_labels\n",
    ")\n",
    "\n",
    "print(Counter(wqp_train_y), Counter(wqp_test_y))\n",
    "print(\"Features:\", wqp_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers show us the wine samples for each class and we can also see the feature names which will\n",
    "be used in our feature set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling\n",
    "\n",
    "We will be using a standard scaler in this\n",
    "scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "wqp_ss = StandardScaler()\n",
    "wqp_train_SX = wqp_ss.fit_transform(wqp_train_X)\n",
    "wqp_test_SX = wqp_ss.transform(wqp_test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Predict & Evaluate Model using Decision Tree\n",
    "\n",
    "The main advantage of decision tree based models is model\n",
    "interpretability, since it is quite easy to understand and interpret the decision rules which led to a specific\n",
    "model prediction. Besides this, other advantages include the model’s ability to handle both categorical\n",
    "and numeric data with ease as well as multi-class classification problems. Trees can be even visualized to\n",
    "understand and interpret decision rules better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model using DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Decision Tree\n",
    "# --------------------------\n",
    "print(\"\\nTraining Decision Tree...\")\n",
    "wqp_dt = DecisionTreeClassifier(random_state=42)\n",
    "wqp_dt.fit(wqp_train_SX, wqp_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate model performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Decision Tree\n",
    "wqp_dt_predictions = wqp_dt.predict(wqp_test_SX)\n",
    "print(\"\\nDecision Tree Performance:\")\n",
    "display_model_performance_metrics(wqp_test_y, wqp_dt_predictions, wqp_dt.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an overall F1 Score and model accuracy of approximately 72%.\n",
    "\n",
    "Looking at the class based statistics; we can see the recall for the high quality\n",
    "wine samples is pretty bad since a lot of them have been misclassified into medium and low quality ratings.\n",
    "This is kind of expected since we do not have a lot of training samples for high quality wine if you remember\n",
    "our training sample sizes from earlier. Considering low and high quality rated wine samples, we should at\n",
    "least try to see if we can prevent our model from predicting a low quality wine as high and similarly prevent\n",
    "predicting a high quality wine as low.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Interpretation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize Feature Importances from Decision Tree Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wqp_dt_feature_importances = wqp_dt.feature_importances_\n",
    "wqp_dt_feature_names, wqp_dt_feature_scores = zip(\n",
    "    *sorted(zip(wqp_feature_names, wqp_dt_feature_importances), key=lambda x: x[1])\n",
    ")\n",
    "y_position = list(range(len(wqp_dt_feature_names)))\n",
    "plt.barh(y_position, wqp_dt_feature_scores, height=0.6, align=\"center\")\n",
    "plt.yticks(y_position, wqp_dt_feature_names)\n",
    "plt.xlabel(\"Relative Importance Score\")\n",
    "plt.ylabel(\"Feature\")\n",
    "t = plt.title(\"Feature Importances for Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly observe that the most important features have changed as compared to\n",
    "our previous model. _Alcohol_ and _volatile acidity_ occupy the top two ranks and _total sulfur dioxide_\n",
    "seems to be one of the most important features for classifying both wine type and quality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize the Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Decision Tree\n",
    "graph = Source(tree.export_graphviz(\n",
    "    wqp_dt,\n",
    "    out_file=None,\n",
    "    feature_names=wqp_feature_names,\n",
    "    class_names=wqp_dt.classes_,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    special_characters=True,\n",
    "    max_depth=3\n",
    "))\n",
    "png_data = graph.pipe(format='png')\n",
    "Image(png_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our decision tree model has a huge number of nodes and branches hence we visualized our tree for a\n",
    "max depth of three.\n",
    "\n",
    "You can start observing the decision rules from the tree\n",
    "in the figure where the starting split is determined by the rule of alcohol <= -0.128 and with each\n",
    "yes\\no decision branch split, we have further decision nodes as we descend into the tree at each depth level.\n",
    "The class variable is what we are trying to predict, i.e. wine quality being low, medium, or high and value\n",
    "determines the total number of samples at each class present in the current decision node at each instance.\n",
    "\n",
    "The gini parameter is basically the criterion which is used to determine and measure the quality of the split\n",
    "at each decision node. Best splits can be determined by metrics like gini impurity\\gini index or information\n",
    "gain, a metric that helps in minimizing the probability of\n",
    "misclassification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Predict & Evaluate Model using Random Forests\n",
    "\n",
    "In the random\n",
    "forest model, each base learner is a decision tree model trained on a bootstrap sample of the training data.\n",
    "Besides this, when we want to split a decision node in the tree, the split is chosen from a random subset of all\n",
    "the features instead of taking the best split from all the features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model using RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Random Forest\n",
    "# --------------------------\n",
    "print(\"\\nTraining Random Forest...\")\n",
    "wqp_rf = RandomForestClassifier(n_estimators=500, max_features=\"sqrt\", random_state=42)\n",
    "wqp_rf.fit(wqp_train_SX, wqp_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate model performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Random Forest\n",
    "wqp_rf_predictions = wqp_rf.predict(wqp_test_SX)\n",
    "print(\"\\nRandom Forest Performance:\")\n",
    "display_model_performance_metrics(wqp_test_y, wqp_rf_predictions, wqp_rf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model prediction results on the test dataset depict an overall F1 Score and model accuracy of\n",
    "approximately 80%. This is definitely an improvement of 7% from what we obtained\n",
    "with just decision trees proving that ensemble learning is working better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning with Grid Search & Cross Validation\n",
    "\n",
    "Another way to further improve on this result is model tuning. To be more specific, models have\n",
    "hyperparameters that can be tuned.\n",
    "\n",
    "Hyperparameters are also known as meta-parameters\n",
    "and are usually set before we start the model training process. These hyperparameters do not have any\n",
    "dependency on being derived from the underlying data on which the model is trained. Usually these\n",
    "hyperparameters represent some high level concepts or knobs, which can be used to tweak and tune the\n",
    "model during training to improve its performance. Our random forest model has several hyperparameters as shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wqp_rf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the best hyperparameter values using Grid Search\n",
    "\n",
    "TODO: this fit gives quite a few warnings/errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized Grid Search for Random Forest\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 500], # Removed 300\n",
    "    \"max_features\": [\"sqrt\", \"log2\"], # Removed None, often not beneficial\n",
    "    \"min_samples_split\": [2, 5, 10],   # Added regularization parameters\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "\n",
    "wqp_clf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1, verbose=1) # n_jobs for parallel processing\n",
    "wqp_clf.fit(wqp_train_SX, wqp_train_y)\n",
    "print(wqp_clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 500 estimators and auto maximum features which represents the square root of the total\n",
    "number of features to be considered during the best split operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View grid search results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = wqp_clf.cv_results_\n",
    "for param, score_mean, score_sd in zip(\n",
    "    results[\"params\"], results[\"mean_test_score\"], results[\"std_test_score\"]\n",
    "):\n",
    "    print(param, round(score_mean, 4), round(score_sd, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows the selected hyperparameter combinations and its corresponding mean\n",
    "accuracy and standard deviation values across the grid.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Predict & Evaluate Random Forest Model with tuned hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wqp_rf = RandomForestClassifier(n_estimators=500, max_features=\"sqrt\", random_state=42)\n",
    "wqp_rf.fit(wqp_train_SX, wqp_train_y)\n",
    "\n",
    "wqp_rf_predictions = wqp_rf.predict(wqp_test_SX)\n",
    "display_model_performance_metrics(\n",
    "    true_labels=wqp_test_y, predicted_labels=wqp_rf_predictions, classes=wqp_rf.classes_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model prediction results on the test dataset improved the overall F1 Score and model accuracy a little bit from the initial random forest model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Predict & Evaluate Model using Extreme Gradient Boosting\n",
    "\n",
    "Another way of modeling ensemble based methods is boosting. A very popular method is XGBoost\n",
    "which stands for Extreme Gradient Boosting. It is a variant of the Gradient Boosting Machines (GBM)\n",
    "model. This model is extremely popular in the Data Science community owing to its superior performance\n",
    "in several Data Science challenges and competitions especially on Kaggle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and set dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# XGBoost\n",
    "# --------------------------\n",
    "print(\"\\nTraining XGBoost...\")\n",
    "label_encoder = LabelEncoder()\n",
    "wqp_train_y_encoded = label_encoder.fit_transform(wqp_train_y)\n",
    "wqp_test_y_encoded = label_encoder.transform(wqp_test_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wqp_xgb = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.3,\n",
    "    random_state=42,\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "wqp_xgb.fit(wqp_train_SX, wqp_train_y_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and Evaluate Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate XGBoost\n",
    "wqp_xgb_predictions = wqp_xgb.predict(wqp_test_SX)\n",
    "wqp_xgb_predictions_decoded = label_encoder.inverse_transform(wqp_xgb_predictions)\n",
    "print(\"\\nXGBoost Performance:\")\n",
    "display_model_performance_metrics(wqp_test_y, wqp_xgb_predictions_decoded, label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning hyperparameters\n",
    "\n",
    "#### Get the best hyperparameter values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [5, 7, 10], # Removed 15\n",
    "    \"learning_rate\": [0.1, 0.3], # Added 0.1\n",
    "    \"gamma\": [0, 0.1, 0.2],       # Added regularization\n",
    "    \"subsample\": [0.8, 1.0],     # Added subsampling\n",
    "    \"colsample_bytree\": [0.8, 1.0] # Added column sampling\n",
    "}\n",
    "\n",
    "wqp_clf = GridSearchCV(xgb.XGBClassifier(seed=42, eval_metric='mlogloss'), param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1, verbose=1)\n",
    "wqp_clf.fit(wqp_train_SX, wqp_train_y_encoded)\n",
    "print(wqp_clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View grid search results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = wqp_clf.cv_results_\n",
    "for param, score_mean, score_sd in zip(\n",
    "    results[\"params\"], results[\"mean_test_score\"], results[\"std_test_score\"]\n",
    "):\n",
    "    print(param, round(score_mean, 4), round(score_sd, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Predict & Evaluate Extreme Gradient Boosted Model with tuned hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the XGBoost model with the best hyperparameters\n",
    "wqp_xgb_model = xgb.XGBClassifier(\n",
    "    seed=42, max_depth=10, learning_rate=0.3, n_estimators=100\n",
    ")\n",
    "wqp_xgb_model.fit(wqp_train_SX, wqp_train_y_encoded)  # Use encoded labels here\n",
    "\n",
    "# Predict on the test set\n",
    "wqp_xgb_predictions = wqp_xgb_model.predict(wqp_test_SX)\n",
    "\n",
    "# Decode the predictions back to string labels\n",
    "wqp_xgb_predictions_decoded = label_encoder.inverse_transform(wqp_xgb_predictions)\n",
    "\n",
    "# Display model performance metrics\n",
    "display_model_performance_metrics(\n",
    "    true_labels=wqp_test_y,\n",
    "    predicted_labels=wqp_xgb_predictions_decoded,  # Use decoded predictions\n",
    "    classes=label_encoder.classes_,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model prediction results on the test dataset depict an overall F1 Score and model accuracy of\n",
    "approximately 78%. Though random forests perform slightly better, it definitely\n",
    "performs better than a basic model like a decision tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Interpretation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparative analysis of Model Feature importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Explanations for XGBoost\n",
    "print(\"\\nGenerating SHAP explanations for XGBoost...\")\n",
    "wqp_feature_names = np.array(wqp_feature_names)  # Ensure it's a NumPy array\n",
    "\n",
    "explainer_xgb = shap.TreeExplainer(wqp_xgb)\n",
    "shap_values_xgb = explainer_xgb(wqp_train_SX)  # Use explainer directly\n",
    "\n",
    "# SHAP Summary Plot for XGBoost\n",
    "shap.summary_plot(shap_values_xgb, wqp_train_SX, feature_names=wqp_feature_names, class_names=label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Observations in the Plot\n",
    "- Fixed acidity interacts with volatile acidity and citric acid, as seen in their wider spreads. \n",
    "- Volatile acidity and citric acid have strong interactions, indicated by denser, spread-out points.\n",
    "- Color gradients suggest a non-linear relationship, meaning changes in one feature affect predictions differently based on the value of the other feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure feature names are a NumPy array\n",
    "wqp_feature_names = np.array(wqp_feature_names)\n",
    "\n",
    "# Check feature name validity\n",
    "assert \"alcohol\" in wqp_feature_names, \"Feature 'alcohol' not found in feature names!\"\n",
    "\n",
    "# If multi-class classification, select a specific class index (e.g., class 0)\n",
    "if len(shap_values_xgb.values.shape) == 3:  # Multi-class case\n",
    "    shap_values_xgb_class = shap_values_xgb.values[..., 0]  # Select one class\n",
    "else:\n",
    "    shap_values_xgb_class = shap_values_xgb.values  # Single output case\n",
    "\n",
    "# SHAP Dependence Plot (Fixed)\n",
    "shap.dependence_plot(\"alcohol\", shap_values_xgb_class, wqp_train_SX, feature_names=wqp_feature_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Observations in the Plot\n",
    "- Clear Positive Relationship\n",
    "    - As alcohol increases, its SHAP value increases.\n",
    "    - This suggests the model associates higher alcohol with higher predictions (e.g., better wine quality).\n",
    "- Grouped & Stepped Pattern\n",
    "    - Some areas show distinct clusters, possibly due to how the data is encoded or specific decision splits in the model.\n",
    "- Interaction with Total Sulfur Dioxide\n",
    "    - At lower alcohol values, high sulfur dioxide (red points) leads to lower SHAP values.\n",
    "    - At higher alcohol values, high sulfur dioxide slightly increases SHAP values.\n",
    "    - This suggests sulfur dioxide modifies the impact of alcohol on predictions.\n",
    "### Conclusion\n",
    "- Alcohol is a strong predictor in your model.\n",
    "- The interaction with total sulfur dioxide matters, especially at lower alcohol levels.\n",
    "- If you want to explore further, consider plotting SHAP interaction values specifically for alcohol & sulfur dioxide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Model ROC Curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_roc_curve(wqp_rf, wqp_test_SX, wqp_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC is pretty good based on what we see. The dotted lines indicate the per-class ROC curves and\n",
    "the lines in bold are the macro and micro-average ROC curves.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Model Decision Surface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_indices = [\n",
    "    i\n",
    "    for i, feature in enumerate(wqp_feature_names)\n",
    "    if feature in [\"alcohol\", \"volatile acidity\"]\n",
    "]\n",
    "plot_model_decision_surface(\n",
    "    clf=wqp_rf,\n",
    "    train_features=wqp_train_SX[:, feature_indices],\n",
    "    train_labels=wqp_train_y,\n",
    "    plot_step=0.02,\n",
    "    cmap=plt.cm.RdYlBu,\n",
    "    markers=[\",\", \"d\", \"+\"],\n",
    "    alphas=[1.0, 0.8, 0.5],\n",
    "    colors=[\"r\", \"b\", \"y\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting Model Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# LIME Explanations\n",
    "# --------------------------\n",
    "print(\"\\nGenerating LIME explanations...\")\n",
    "lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    training_data=wqp_train_SX,\n",
    "    feature_names=wqp_feature_names,\n",
    "    class_names=label_encoder.classes_,\n",
    "    discretize_continuous=True,\n",
    "    verbose=True,\n",
    "    mode='classification'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain instance for Random Forest\n",
    "def explain_instance_rf(instance_index):\n",
    "    exp = lime_explainer.explain_instance(\n",
    "        wqp_test_SX[instance_index],\n",
    "        wqp_rf.predict_proba,\n",
    "        num_features=5,\n",
    "        top_labels=1\n",
    "    )\n",
    "    return exp.show_in_notebook()\n",
    "# Explain instance for XGBoost\n",
    "def explain_instance_xgb(instance_index):\n",
    "    exp = lime_explainer.explain_instance(\n",
    "        wqp_test_SX[instance_index],\n",
    "        wqp_xgb.predict_proba,\n",
    "        num_features=5,\n",
    "        top_labels=1\n",
    "    )\n",
    "    return exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain sample predictions\n",
    "print(\"\\nLIME Explanation for Random Forest (Low Quality Wine):\")\n",
    "explain_instance_rf(10)   # Low quality wine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prediction Probabilities (Left)\n",
    "- The model predicted this wine sample as medium quality with a probability of 0.82 (82%).\n",
    "- The probabilities for other classes:\n",
    "    - Low quality: 18%\n",
    "    - High quality: 1%\n",
    "- This suggests that the model is fairly confident in predicting this sample as \"medium.\"\n",
    "\n",
    "\n",
    "2. Feature Contributions (Middle)\n",
    "- The bar chart in the middle explains which features influenced the prediction.\n",
    "- Green bars (right side): Features that support the prediction (i.e., medium quality).\n",
    "- Cyan bar (left side): Features that contradict the prediction.\n",
    "\n",
    "  Breakdown of Feature Contributions\n",
    "    - Alcohol (-0.58) → Negative contribution: Since alcohol is low, the model sees it as evidence against \"medium quality.\"\n",
    "    - Sulphates (0.54) → Positive contribution: Higher sulphate levels push the prediction towards \"medium quality.\"\n",
    "    - Volatile Acidity (-0.48) → Positive contribution: A moderate value of volatile acidity helps predict \"medium quality.\"\n",
    "    - Free Sulfur Dioxide (1.62) → Positive contribution:  A high level supports \"medium quality.\"\n",
    "    - pH (-0.84) → Negative contribution: A lower pH slightly contradicts the \"medium\" classification.\n",
    "\n",
    "Conclusion\n",
    "- The model predicts medium quality wine with high confidence.\n",
    "- Key factors supporting \"medium\" prediction:\n",
    "    - Higher sulphates\n",
    "    - Higher free sulfur dioxide\n",
    "    - Moderate volatile acidity\n",
    "Key factor against \"medium\" prediction:\n",
    "    - Low alcohol content\n",
    "      \n",
    "If you want to further validate these insights, you could compare this with SHAP values to see if both methods agree on important features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLIME Explanation for XGBoost (High Quality Wine):\")\n",
    "explain_instance_xgb(747)  # High quality wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prediction Probabilities (Left)\n",
    "- The model is 99% confident that this wine is medium quality (green bar).\n",
    "- The probabilities for other classes:\n",
    "    - Low quality: 1%\n",
    "    - High quality: 0%\n",
    "- Despite analyzing a high-quality wine, the model strongly favors the \"medium\" classification.\n",
    "\n",
    "2. Feature Contributions (Middle)\n",
    "- The bar chart explains which features influenced the prediction.\n",
    "- Green bars (right side): Features that support the \"medium quality\" prediction.\n",
    "- Blue bars (left side): Features that contradict \"medium quality\" and could suggest another classification.\n",
    "\n",
    "  Breakdown of Feature Contributions\n",
    "    - Alcohol (1.26) → Positive contribution (0.32): A higher alcohol content increases the likelihood of being classified as medium quality.\n",
    "    - Residual Sugar (1.96) → Positive contribution (0.10): More residual sugar also supports the \"medium\" prediction.\n",
    "    - Chlorides (-0.96) → Positive contribution (0.08): A low chloride level pushes the prediction toward medium quality.\n",
    "    - Volatile Acidity (0.79) → Negative contribution (0.26): Higher volatile acidity contradicts \"medium\" and leans toward another classification (possibly low quality).\n",
    "    - Density (0.17) → Negative contribution (0.08): A moderate density is not fully aligned with the \"medium\" classification.\n",
    "\n",
    "Conclusion\n",
    "- The model strongly predicts medium quality despite the wine being labeled as high quality.\n",
    "- Key factors supporting \"medium\" prediction:\n",
    "    - High alcohol\n",
    "    - High residual sugar\n",
    "    - Low chlorides\n",
    "- Key factors contradicting \"medium\" prediction:\n",
    "    - High volatile acidity\n",
    "    - Moderate density\n",
    "      \n",
    "This suggests the model may be biased toward predicting medium quality, even for wines that should be high quality. You might want to analyze SHAP values or retrain the model with different feature weighting to improve its ability to distinguish high-quality wines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Through this module, we covered:\n",
    "\n",
    "- Building and evaluating multiple classification models\n",
    "- Applying different machine learning algorithms and comparing their performance\n",
    "- Using model interpretation techniques including:\n",
    "  - Feature importance analysis\n",
    "  - ROC curves and performance metrics\n",
    "  - Decision surface visualization\n",
    "  - Partial dependence plots\n",
    "- Understanding how different features influence model predictions\n",
    "\n",
    "## Clean up\n",
    "\n",
    "Remember to shut down your Jupyter Notebook environment and delete any unnecessary files or resources once you've completed the tutorial.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
