{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Drug Activity for Androgen Receptor\n",
    "\n",
    "Adapted from Tomasz K. Piskorz. [Predict Drug activity for androgen receptor](https://github.com/tkpiskorz/cheminformatics_notebooks/blob/master/AR/Androgen%20receptor.ipynb).\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial provides a step-by-step guide on leveraging machine learning algorithms to predict drug activity for the androgen receptor using Quantitative Structure–Property Relationship (QSPR) descriptors. The analysis is based on the Tox21 dataset, which contains chemical compounds and their biological activities. To build predictive models, we calculate molecular descriptors using the mordred package, a powerful tool for generating a wide range of molecular features. These descriptors capture essential chemical properties, enabling the development of robust models that can predict whether a compound will activate or inhibit the androgen receptor. By following this tutorial, you’ll gain insights into how machine learning can be applied to drug discovery and chemical informatics, bridging the gap between molecular structure and biological activity.\n",
    "\n",
    "This tutorial uses a couple of packages we have not yet seen. You can learn more about them here:\n",
    "\n",
    "- RDKit: a Python [Open-Source Cheminformatics Software](https://www.rdkit.org/).\n",
    "- mordred: a python [molecular descriptor calculator](https://github.com/mordred-descriptor/mordred) package.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Learn how to work with chemical structure data using RDKit and `mordred`\n",
    "- Understand how to calculate and use molecular descriptors for drug activity prediction\n",
    "- Build and evaluate machine learning models for drug activity classification\n",
    "- Interpret model performance using ROC AUC scores and accuracy metrics\n",
    "\n",
    "### Tasks to complete\n",
    "\n",
    "Load and preprocess Tox21 dataset\n",
    "Calculate molecular descriptors using mordred\n",
    "Train and evaluate Random Forest model\n",
    "Train and evaluate Neural Network model\n",
    "Compare model performances\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- A working Python environment and familiarity with Python\n",
    "- Basic understanding of machine learning concepts\n",
    "- Familiarity with pandas and numpy libraries\n",
    "- Knowledge of basic statistical concepts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Started\n",
    "\n",
    "- Please select kernel \"conda_tensorflow2_p310\" from SageMaker notebook instance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries\n",
    "\n",
    "\\*Note: You may get a deprecation warning regarding `IPython.core.display`. This shouldn't affect the results of the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the mordredcommunity library version 2.0.6 using pip package manager.\n",
    "%pip install mordredcommunity==2.0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the NumPy library for numerical operations, often used for array manipulation and mathematical functions.\n",
    "import numpy as np\n",
    "\n",
    "# Import the Pandas library for data manipulation and analysis, particularly for working with DataFrames.\n",
    "import pandas as pd\n",
    "\n",
    "# Import the display function from IPython.display to enable rich outputs like DataFrames in notebooks.\n",
    "from IPython.display import display\n",
    "\n",
    "# Import the Calculator class and the descriptors module from the mordred library. Mordred is used for molecular descriptor calculation.\n",
    "from mordred import Calculator, descriptors\n",
    "\n",
    "# Import the Missing class from mordred.error to handle missing descriptor values.\n",
    "from mordred.error import Missing\n",
    "\n",
    "# Import the Chem module from RDKit, which is the core module for chemical informatics tasks like molecule handling.\n",
    "from rdkit import Chem\n",
    "\n",
    "# Import PandasTools from rdkit.Chem. This module enhances Pandas DataFrames to work seamlessly with RDKit molecules.\n",
    "# It allows you to store and manipulate RDKit molecules directly within DataFrame columns.\n",
    "from rdkit.Chem import PandasTools\n",
    "\n",
    "# Import IPythonConsole from rdkit.Chem.Draw to enable the display of molecule images directly in IPython environments like Jupyter notebooks.\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "# Import the RandomForestClassifier from sklearn.ensemble. This is a machine learning model used for classification tasks.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Import the roc_auc_score function from sklearn.metrics to evaluate the performance of classification models, specifically using the Area Under the ROC Curve metric.\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Import the train_test_split function from sklearn.model_selection to split datasets into training and testing sets for model evaluation.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import the MLPClassifier from sklearn.neural_network. This is a Multi-layer Perceptron classifier, a type of neural network used for classification.\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Toxicology in the 21st Century_ (Tox21) Dataset\n",
    "\n",
    "The _Toxicology in the 21st Century_ (Tox21) initiative created a public database measuring toxicity of compounds, which has been used in the 2014 Tox21 Data Challenge. This dataset contains qualitative toxicity measurements for 8k compounds on 12 different targets, including nuclear receptors and stress response pathways.\n",
    "\n",
    "The data file contains a csv table, in which columns below are used:\n",
    "\n",
    "- \"smiles\" - SMILES representation of the molecular structure\n",
    "- \"NR-XXX\" - Nuclear receptor signaling bioassays results\n",
    "  - [AR](https://pubchem.ncbi.nlm.nih.gov/bioassay/743040): qHTS assay to identify small molecule agonists of the androgen receptor (AR) signaling pathway using the MDA cell line.\n",
    "  - [AhR](https://pubchem.ncbi.nlm.nih.gov/bioassay/743122): qHTS assay to identify small molecule that activate the aryl hydrocarbon receptor (AhR) signaling pathway.\n",
    "  - [AR-LBD](https://pubchem.ncbi.nlm.nih.gov/bioassay/74353): qHTS assay to identify small molecule agonists of the androgen receptor (AR) signaling pathway.\n",
    "- [ER](https://pubchem.ncbi.nlm.nih.gov/bioassay/743079): qHTS assay to identify small molecule agonists of the estrogen receptor alpha (ER-alpha) signaling pathway using the BG1 cell line.\n",
    "- [ER-LBD](https://pubchem.ncbi.nlm.nih.gov/bioassay/743077): qHTS assay to identify small molecule agonists of the estrogen receptor alpha (ER-alpha) signaling pathway.\n",
    "- [aromatase](https://pubchem.ncbi.nlm.nih.gov/bioassay/743139): qHTS assay to identify aromatase inhibitors.\n",
    "- [PPAR-gamma](https://pubchem.ncbi.nlm.nih.gov/bioassay/743140): qHTS assay to identify small molecule agonists of the peroxisome proliferator-activated receptor gamma (PPARg) signaling pathway.\n",
    "\n",
    "- \"SR-XXX\" - Stress response bioassays results\n",
    "  - [ARE](https://pubchem.ncbi.nlm.nih.gov/bioassay/743219): qHTS assay for small molecule agonists of the antioxidant response element (ARE) signaling pathway.\n",
    "  - [ATAD5](https://pubchem.ncbi.nlm.nih.gov/bioassay/720516): qHTS assay for small molecules that induce genotoxicity in human embryonic kidney cells expressing luciferase-tagged ATAD5.\n",
    "  - [HSE](https://pubchem.ncbi.nlm.nih.gov/bioassay/743228): qHTS assay for small molecule activators of the heat shock response signaling pathway.\n",
    "  - [MMP](https://pubchem.ncbi.nlm.nih.gov/bioassay/720637): qHTS assay for small molecule disruptors of the mitochondrial membrane potential.\n",
    "  - [p53](https://pubchem.ncbi.nlm.nih.gov/bioassay/720552): qHTS assay for small molecule agonists of the p53 signaling pathway.\n",
    "\n",
    "Please refer to the links at https://tripod.nih.gov/tox21/challenge/data.jsp for details.\n",
    "\n",
    "### References\n",
    "\n",
    "Tox21 Challenge. https://tripod.nih.gov/tox21/challenge/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tox21 dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the tox21.csv file from the \"../../Data/\" directory into a pandas DataFrame called 'df'.\n",
    "df = pd.read_csv(\"../../Data/tox21.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 10 rows of the DataFrame 'df' to get a quick overview of the data.\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show descriptive summary statistics for the DataFrame 'df'.\n",
    "# This will include count, mean, std, min, 25%, 50%, 75%, max for numerical columns.\n",
    "# For categorical columns, it will include count, unique, top, and freq.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column names of the DataFrame 'df' and convert them to a list.\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects only the columns 'NR-AR' and 'smiles' from the DataFrame 'df'.\n",
    "df = df[[\"NR-AR\", \"smiles\"]]\n",
    "\n",
    "# Displays the first few rows of the DataFrame 'df' with the selected columns.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shape of the DataFrame 'df' (number of rows and columns).\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the molecules contained in the column \"smilesCol\" to RDKit molecule objects and adds them to the DataFrame \"df\".\n",
    "# This function also allows for the optional computation and storage of molecular fingerprints to speed up substructure searching.\n",
    "from rdkit import RDLogger\n",
    "\n",
    "# Suppress RDKit warnings to keep the output cleaner.\n",
    "RDLogger.DisableLog(\"rdApp.warning\")  # Disables RDKit warning messages.\n",
    "RDLogger.DisableLog(\n",
    "    \"rdApp.error\"\n",
    ")  # Disables RDKit error messages as well (optional, but good for cleaner output).\n",
    "\n",
    "# Uses PandasTools to add a new column of RDKit molecule objects to the DataFrame 'df'. \n",
    "# The molecules are created from the SMILES strings in the column named \"smiles\".\n",
    "PandasTools.AddMoleculeColumnToFrame(\n",
    "    df, smilesCol=\"smiles\"\n",
    ")\n",
    "\n",
    "# Displays the first few rows of the DataFrame 'df' to show the newly added molecule column.\n",
    "df.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows from the DataFrame 'df' where the 'ROMol' column contains missing values (NaN).\n",
    "df = df[~df[\"ROMol\"].isnull()]\n",
    "\n",
    "# Remove rows from the DataFrame 'df' where the 'NR-AR' column contains missing values (NaN).\n",
    "df = df[~df[\"NR-AR\"].isnull()]\n",
    "\n",
    "# Print the shape (number of rows and columns) of the DataFrame 'df' after removing rows with missing values.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see 566 rows with missing values (NaN) are removed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use RDKit PandasTools to generate a grid image of molecules from a Pandas DataFrame.\n",
    "display(\n",
    "    PandasTools.FrameToGridImage(\n",
    "        # Filter the DataFrame 'df' to select rows where the 'NR-AR' column is equal to 1.\n",
    "        df[df[\"NR-AR\"] == 1].head(5),\n",
    "        \n",
    "        # Specify that the 'NR-AR' column should be used to generate legends for each molecule in the grid.\n",
    "        legendsCol=\"NR-AR\",\n",
    "        \n",
    "        # Set the number of molecules to be displayed in each row of the grid to 5.\n",
    "        molsPerRow=5,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a grid image of molecules from a Pandas DataFrame where the 'NR-AR' column is equal to 0.\n",
    "display(\n",
    "    PandasTools.FrameToGridImage(\n",
    "        # Filter the DataFrame 'df' to include only rows where the 'NR-AR' column is 0.\n",
    "        df[df[\"NR-AR\"] == 0].head(5),\n",
    "        \n",
    "        # Specify that the 'NR-AR' column should be used for legends in the grid image.\n",
    "        legendsCol=\"NR-AR\",\n",
    "        \n",
    "        # Set the number of molecules to display per row in the grid to 5.\n",
    "        molsPerRow=5,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique values from the 'NR-AR' column of the DataFrame 'df'. This effectively counts the number of distinct elements in that column.\n",
    "df[\"NR-AR\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts the number of non-missing values in the 'NR-AR' column of the DataFrame 'df'.\n",
    "df[\"NR-AR\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and return the sum of the values in the 'NR-AR' column of the DataFrame 'df'.\n",
    "df[\"NR-AR\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a molecular descriptor?\n",
    "\n",
    "Molecular descriptors are mathematical representations of a molecule's properties, generated through algorithmic calculations. These descriptors translate the physical and chemical characteristics of molecules into numerical values, providing a quantitative way to describe their structure and behavior. By capturing essential information about molecular features, such as size, shape, polarity, and electronic properties, molecular descriptors serve as powerful tools for predicting various outcomes, including biological activity, toxicity, and other properties derived from the chemical structure of compounds. They play a critical role in fields like drug discovery, chemical informatics, and environmental science, enabling researchers to link molecular structure to function in a systematic and data-driven manner.\n",
    "\n",
    "(All together, the code in this section may take up to 20 minutes to complete.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a descriptor calculator object named 'calc' that will compute all descriptors listed in the 'descriptors' variable.\n",
    "# The argument 'ignore_3D=True' specifies that 3D descriptors should be excluded from the calculation.\n",
    "calc = Calculator(descriptors, ignore_3D=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accesses the first element of the 'ROMol' column in the DataFrame 'df'.\n",
    "mol = df[\"ROMol\"][0]\n",
    "\n",
    "# Displays the 'mol' object, which likely represents a molecule loaded by RDKit.\n",
    "mol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The following step may take up to 40 minutes to complete.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses the 'pandas' method from the 'calc' object to calculate molecular properties for multiple molecules in the 'ROMol' column of DataFrame 'df'. Returns the results as a pandas DataFrame named 'df2'.\n",
    "df2 = calc.pandas(df[\"ROMol\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the DataFrame 'df2' (by default, it shows the first 5 rows).\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shape of the DataFrame df2 (number of rows and columns).\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list called 'missing' to store column names with missing values.\n",
    "missing = []\n",
    "\n",
    "# Iterate through each column name in the DataFrame 'df2'.\n",
    "for column in df2.columns:\n",
    "    # Check if any value in the current 'column' is of type 'Missing'.\n",
    "    # 'df2[column].apply(lambda x: type(x) == Missing)' applies a function to each element in the column.\n",
    "    # The lambda function checks if the type of the element 'x' is equal to the type 'Missing'.\n",
    "    # '.any()' returns True if at least one element in the Series is True (i.e., if at least one value is of type 'Missing').\n",
    "    if (df2[column].apply(lambda x: type(x) == Missing)).any():\n",
    "        \n",
    "        # If the condition in the 'if' statement is True (meaning the column contains at least one 'Missing' value),\n",
    "        # append the name of the 'column' to the 'missing' list.\n",
    "        missing.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with known errored value from the DataFrame 'df2' and assign the result to 'df_new'.\n",
    "df_new = df2.drop(missing, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the DataFrame 'df_new' to inspect the data.\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the shape of the DataFrame 'df_new' as a tuple (number of rows, number of columns).\n",
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigns the 'NR-AR' column from the DataFrame 'df' to the variable 'y' as the target variable.\n",
    "y = df[\"NR-AR\"]\n",
    "\n",
    "# Assigns the DataFrame 'df_new' to the variable 'X' to be used as the feature matrix (molecular descriptors).\n",
    "X = df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into 75% training and 25% test sets\n",
    "# X_train: Features for the training dataset (75% of X).\n",
    "# X_test: Features for the test dataset (25% of X).\n",
    "# y_train: Labels for the training dataset (75% of y).\n",
    "# y_test: Labels for the test dataset (25% of y).\n",
    "# train_test_split: Function used to split the dataset into training and testing sets.\n",
    "# X: Features data to be split.\n",
    "# y: Labels data to be split.\n",
    "# By default, test_size is 0.25 if not specified, meaning 25% of the data will be used for testing, and 75% for training.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest\n",
    "\n",
    "A **random forest** is an ensemble learning method that functions as a **meta-estimator**. It works by training multiple **decision tree classifiers** on different sub-samples of the dataset, typically drawn with replacement (bootstrapping). Each tree is trained independently, and the final prediction is obtained by averaging the predictions of all the individual trees (for regression tasks) or through majority voting (for classification tasks). This approach not only enhances the model's **predictive accuracy** but also helps to **control over-fitting** by reducing the variance that can occur with individual decision trees. By combining the strengths of many trees, random forests create a robust and reliable model that performs well on a wide range of datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestClassifier class from scikit-learn's ensemble module.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a RandomForestClassifier object with 100 trees (n_estimators=100) and train it using the training data (X_train, y_train).\n",
    "clf = RandomForestClassifier(n_estimators=100).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receiver Operating Characteristic Curve (ROC AUC)\n",
    "\n",
    "The **Area Under the Receiver Operating Characteristic Curve (ROC AUC)** is a performance metric used to evaluate the effectiveness of a classification model. It measures the model's ability to distinguish between classes by plotting the **True Positive Rate (TPR)** against the **False Positive Rate (FPR)** at various threshold settings. A higher ROC AUC score indicates better model performance, with a score of 1 representing perfect classification and 0.5 indicating random guessing.\n",
    "\n",
    "In the context of a **random forest classifier**, the predicted class probabilities for an input sample are calculated as the **mean predicted class probabilities** across all the trees in the forest. For a single decision tree, the class probability is determined by the fraction of samples belonging to the same class in a given leaf node. By averaging these probabilities across all trees, the random forest provides a robust estimate of the likelihood that a sample belongs to a particular class. This approach enhances the model's reliability and accuracy, making ROC AUC a valuable metric for assessing its performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Area Under the Receiver Operating Characteristic Curve (ROC AUC) score.\n",
    "# The roc_auc_score function is used to evaluate the model's performance by comparing\n",
    "# the true labels (y_test) with the predicted probabilities for the positive class.\n",
    "\n",
    "# clf.predict_proba(X_test)[:, 1] extracts the predicted probabilities for the positive class (class 1)\n",
    "# from the test dataset (X_test). The [:, 1] indexing selects the second column of the probability\n",
    "# array, which corresponds to the positive class.\n",
    "\n",
    "roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean accuracy of training data using the classifier 'clf' and training features 'X_train' and labels 'y_train'.\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean accuracy of the classifier (clf) on the test data (X_test, y_test).\n",
    "# This method calculates the accuracy by comparing the classifier's predictions for X_test\n",
    "# against the true labels y_test and returning the mean accuracy score.\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer Perceptron classifier\n",
    "\n",
    "The **Multi-layer Perceptron (MLP) classifier** is a type of artificial neural network designed for supervised learning tasks, particularly classification. This model optimizes the log-loss function (also known as cross-entropy loss) to minimize the difference between predicted probabilities and actual labels. The optimization process can be performed using one of two methods:\n",
    "\n",
    "- **LBFGS (Limited-memory Broyden–Fletcher–Goldfarb–Shanno)**: A quasi-Newton optimization algorithm that approximates the Hessian matrix to efficiently find the minimum of the loss function. It is well-suited for smaller datasets due to its memory efficiency.\n",
    "\n",
    "- **Stochastic Gradient Descent (SGD)**: An iterative optimization method that updates model parameters using small random subsets (batches) of the data. SGD is more scalable and commonly used for larger datasets.\n",
    "\n",
    "The MLP classifier consists of multiple layers of interconnected nodes (neurons), including an input layer, one or more hidden layers, and an output layer. Each neuron applies a non-linear activation function (e.g., ReLU or sigmoid) to its inputs, enabling the network to learn complex patterns and relationships in the data. This flexibility makes the MLP classifier a powerful tool for solving a wide range of classification problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the original DataFrame X_train, including rows with missing values (NaN).\n",
    "print(X_train)\n",
    "\n",
    "# Print a new DataFrame that is created by removing rows with any missing values (NaN) from X_train.\n",
    "# This will show X_train with only complete rows, where no values are missing.\n",
    "print(X_train.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The following cell should take about three minutes to complete.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Multi-layer Perceptron classifier instance\n",
    "# with 6 hidden layers.\n",
    "# The number of neurons in each hidden layer are specified as a list: [1000, 500, 250, 100, 50, 20].\n",
    "# Layer 1: 1000 neurons\n",
    "# Layer 2: 500 neurons\n",
    "# Layer 3: 250 neurons\n",
    "# Layer 4: 100 neurons\n",
    "# Layer 5: 50 neurons\n",
    "# Layer 6: 20 neurons\n",
    "clf = MLPClassifier(hidden_layer_sizes=[1000, 500, 250, 100, 50, 20])\n",
    "\n",
    "# Train the Multi-layer Perceptron classifier model\n",
    "# using the training data (X_train features and y_train labels).\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receiver Operating Characteristic Curve (ROC AUC)\n",
    "\n",
    "Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from predicted class probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Area Under the Receiver Operating Characteristic Curve (ROC AUC score).\n",
    "# This metric evaluates the performance of the classifier by measuring the area under the ROC curve.\n",
    "# It uses the true labels (y_test) and the predicted probabilities of the positive class (class '1')\n",
    "# from the classifier (clf) on the test data (X_test).\n",
    "roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean accuracy of the classifier 'clf' on the training data (X_train, y_train).\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean accuracy of the classifier on the test data (X_test, y_test).\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This tutorial demonstrated how to:\n",
    "\n",
    "- Work with chemical structure data using RDKit\n",
    "- Calculate molecular descriptors using `mordred`\n",
    "- Build and evaluate machine learning models for predicting drug activity\n",
    "- Use different model architectures (Random Forest and Neural Networks) for classification tasks\n",
    "- Assess model performance using ROC AUC scores and accuracy metrics\n",
    "\n",
    "## Clean up\n",
    "\n",
    "Remember to shut down your Jupyter Notebook environment and delete any unnecessary files or resources once you've completed the tutorial.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
