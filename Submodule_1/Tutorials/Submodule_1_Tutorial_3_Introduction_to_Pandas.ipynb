{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas\n",
    "\n",
    "## Overview\n",
    "\n",
    "This module introduces Pandas, a powerful data manipulation library for Python. It covers basic operations, data structures, and common data analysis tasks using Pandas, including analyzing, cleaning, exploring, and manipulating data.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "* Understand Pandas data structures: Series and DataFrame\n",
    "* Learn to create, read, and manipulate DataFrames\n",
    "* Perform basic data analysis operations using Pandas\n",
    "* Handle missing data in Pandas\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Basic Python knowledge (For a refresher, see the [Python tutorial](https://docs.python.org/tutorial/).)\n",
    "- Familiarity with NumPy is helpful but not required\n",
    "\n",
    "## Get Started\n",
    "\n",
    "Install pandas and import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the 'numpy' package using pip (Python's package installer)\n",
    "# The '%pip' magic command is used in Jupyter notebooks to install packages directly from the notebook\n",
    "%pip install numpy\n",
    "\n",
    "# Install the pandas library to work with data structures like DataFrames\n",
    "!pip install pandas\n",
    "\n",
    "# Install the tables library to read and write HDF5 files, typically used for large datasets\n",
    "!pip install tables\n",
    "\n",
    "# Install the openpyxl library to read and write Excel files (.xlsx)\n",
    "!pip install openpyxl\n",
    "\n",
    "# Import pandas library, used for data manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Import numpy library, used for numerical operations and working with arrays\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object creation\n",
    "\n",
    "See the [introduction to data structures](https://pandas.pydata.org/docs/user_guide/dsintro.html#dsintro) section of Pandas documentation for details.\n",
    "\n",
    "You can create a [Series](https://pandas.pydata.org/docs/reference/api/pandas.Series.html#pandas.Series) (One-dimensional ndarray with axis labels, including time series) by passing a list of values, letting pandas create a default integer index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas Series with some integer values and a NaN (Not a Number) value\n",
    "# The NaN value represents missing data or undefined values in the series\n",
    "s = pd.Series([1, 3, 5, np.nan, 6, 8])\n",
    "\n",
    "# Display the Series to view its contents\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html#pandas.DataFrame) (Two-dimensional, size-mutable, potentially heterogeneous tabular data) by passing a NumPy array, with a datetime index and labeled columns:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a range of equally spaced time points (dates)\n",
    "# \"20220306\" is the starting date (March 6, 2022)\n",
    "# `periods=6` specifies that the range will contain 6 equally spaced dates\n",
    "dates = pd.date_range(\"20220306\", periods=6)\n",
    "\n",
    "# Displays the generated date range\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with random values from a standard normal distribution\n",
    "# The shape of the DataFrame is (6, 4), i.e., 6 rows and 4 columns\n",
    "# The index is set to the `dates` variable (which should be a list, array, or pandas DateTimeIndex)\n",
    "# The column labels are set to the list ['A', 'B', 'C', 'D']\n",
    "df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list(\"ABCD\"))\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create a DataFrame by passing a dictionary of objects that can be converted into a series-like structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame named df2 with various types of data for each column\n",
    "df2 = pd.DataFrame(\n",
    "    {\n",
    "        # Column 'A' with a constant value of 1.0 for all rows\n",
    "        \"A\": 1.0,\n",
    "\n",
    "        # Column 'B' with a single timestamp (2013-01-02) for all rows\n",
    "        \"B\": pd.Timestamp(\"20130102\"),\n",
    "\n",
    "        # Column 'C' with a pandas Series of length 4 filled with 1's, dtype is float32\n",
    "        \"C\": pd.Series(1, index=list(range(4)), dtype=\"float32\"),\n",
    "\n",
    "        # Column 'D' with a NumPy array of integers (3 repeated 4 times), dtype is int32\n",
    "        \"D\": np.array([3] * 4, dtype=\"int32\"),\n",
    "\n",
    "        # Column 'E' with a categorical variable containing 'test' and 'train'\n",
    "        \"E\": pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n",
    "\n",
    "        # Column 'F' with a string constant \"foo\" for all rows\n",
    "        \"F\": \"foo\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Display the DataFrame df2\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of the resulting DataFrame have different `dtypes`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the data types of each column in the DataFrame `df2`\n",
    "# This allows us to check the type of data stored in each column (e.g., int, float, object, etc.)\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing data\n",
    "\n",
    "See [Essential basic functionality](https://pandas.pydata.org/docs/user_guide/basics.html#basics) section of Pandas documentation for details.\n",
    "\n",
    "You can view the top and bottom rows of the frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3) # first three rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(2) # last two rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can display the indexes and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**describe**() shows a quick statistic summary of your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposing your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Sorting](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_index.html) by axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The axis along which to sort. The value 0 identifies the rows, and 1 identifies the columns.\n",
    "df.sort_index(axis=1, ascending=False) # Sort based on column label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Sorting](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html#pandas.DataFrame.sort_values) by values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"C\") # Sort by 'C' column ascending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection\n",
    "\n",
    "See [Indexing and Selecting Data](https://pandas.pydata.org/docs/user_guide/indexing.html#indexing) section of Pandas documentation for details.\n",
    "\n",
    "Selecting a single column, which yields a Series, equivalent to df.A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"A\"] # Select 'A' column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting via [], which slices the rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:4] # Select first 4 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"20220306\":\"20220310\"] # Get \"2022-03-06\" through \"2022-03-10\" rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection by label\n",
    "\n",
    "**loc** selects rows and columns with specific labels. **iloc** selects rows and columns at specific integer positions.\n",
    "\n",
    "Getting a cross section using a label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[dates[0]] # Get row indexed by '2022-03-06'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting on a multi-axis by label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, [\"A\", \"B\"]] # Get 'A' and 'B' columns for all rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing label slicing, both endpoints are included:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"20220307\":\"20220309\", [\"A\", \"B\"]] # # Get 'A' and 'B' columns for rows indexed by '2022-03-07' through '2022-03-09'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduction in the dimensions of the returned object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"20220308\", [\"A\", \"B\"]] # Get 'A' and 'B' columns of '2022-03-08' row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a scalar value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[dates[0], \"A\"] # Get value at dates[0] row and 'A' column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting fast access to a scalar (equivalent to the prior method):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[dates[0], \"A\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection by position\n",
    "Selecting via the position of the passed integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2] # Get all values of third row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By integer slices, similar to NumPy/Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3:5, 0:2] # Get values of 4 and 5 rows, 'A', 'B' columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By lists of integer position locations, similar to the NumPy/Python style:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[1, 2, 4], [0, 2]] # Get values of 2, 3, 5 rows, 'A', 'C' columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing rows explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1:3, :] # Get values of 2 and 3 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing columns explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, 1:3] # Get values of 2 and 3 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Getting a value explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1, 1] # Get value at 2nd row and 2nd columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting fast access to a scalar (equivalent to the prior method):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iat[1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean indexing\n",
    "\n",
    "Using a single columnâ€™s values to select data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"A\"] > 0] # Get rows where 'A' columns is greater than 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the isin() method for filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2[\"E\"] = [\"one\", \"one\", \"two\", \"three\", \"four\", \"three\"] # Add new column 'E'\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2[\"E\"].isin([\"two\", \"four\"])] # Get rows where the values in column 'E' is either \"two\" or \"four\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting\n",
    "\n",
    "Setting a new column automatically aligns the data by the indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series([1, 2, 3, 4, 5, 6], index=pd.date_range(\"20220306\", periods=6))\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"F\"] = s1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting values by label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[dates[0], \"A\"] = 0 # Set the value at dates[0] and 'A' column to be 0\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting values by position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iat[0, 1] = 0 # Set the value at first row, second column to be 0\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting by assigning with a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, \"D\"] = np.array([5] * len(df)) # Set the values at 'D' columns to be 5\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data\n",
    "\n",
    "See [Missing Data](https://pandas.pydata.org/docs/user_guide/missing_data.html#missing-data) section of Pandas documentation for details.\n",
    "\n",
    "Pandas primarily uses the value `np.nan` to represent missing data. It is by default not included in computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindexing allows you to change/add/delete the index on a specified axis. This returns a copy of the data:\n",
    "df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + [\"E\"])\n",
    "# Add a new column \"E\" and set the first two rows of \"E\" to be \"1\"\n",
    "df1.loc[dates[0] : dates[1], \"E\"] = 1\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To drop any rows that have missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any missing (NaN) values\n",
    "# The 'how=\"any\"' parameter specifies that if any column in a row has a NaN value, that row will be dropped\n",
    "df1.dropna(how=\"any\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing (NaN) values in the DataFrame `df1` with the specified value (5)\n",
    "df1.fillna(value=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the boolean mask where values are *NaN*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing (NaN) values in the DataFrame 'df1'\n",
    "# pd.isna(df1) returns a DataFrame of the same shape as 'df1' with True for NaN values and False for non-NaN values\n",
    "pd.isna(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations\n",
    "\n",
    "See the [Flexible binary operations](https://pandas.pydata.org/docs/user_guide/basics.html#basics-binop) section of Pandas documentation for details.\n",
    "\n",
    "### Stats\n",
    "\n",
    "Operations in general exclude missing data.\n",
    "\n",
    "Performing a descriptive statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.max(axis=0) # Get max of all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same operation on the other axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.max(axis=1) # Get max of all rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply\n",
    "\n",
    "Applying functions to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda x: x.max() - x.min(), axis=1) # Get the max-min differences of columns\n",
    "# def test(x):\n",
    "#   result = x.max() - x.min()\n",
    "#   return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Methods\n",
    "\n",
    "Series is equipped with a set of string processing methods in the `str` attribute that make it easy to operate on each element of the array, as in the code snippet below. Note that pattern-matching in `str` generally uses regular expressions by default (and in some cases always uses them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas Series with a mix of strings and a NaN value\n",
    "s = pd.Series([\"A\", \"B\", \"C\", \"Aaba\", \"Baca\", np.nan, \"CABA\", \"dog\", \"cat\"])\n",
    "\n",
    "# Apply the `str.lower()` function to convert all string elements in the Series to lowercase\n",
    "# This function works element-wise, meaning it will convert each string in the Series to lowercase\n",
    "s.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data in/out\n",
    "\n",
    "### CSV\n",
    "\n",
    "Writing to a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame `df` to a CSV file named \"foo.csv\"\n",
    "# The `to_csv` method writes the data from the DataFrame into a CSV file\n",
    "df.to_csv(\"foo.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to read a CSV file and load its contents into a DataFrame\n",
    "df = pd.read_csv(\"foo.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5\n",
    "\n",
    "HDF5 is a unique technology suite that makes possible the management of extremely large and complex data collections. If you want to know more about HDF5 format, please see [What is HDF5](https://support.hdfgroup.org/HDF5/whatishdf5.html) for details.\n",
    "\n",
    "Reading and writing to HDFStores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame 'df' to a HDF5 file named 'foo.h5', with the data stored under the key \"df\"\n",
    "df.to_hdf(\"foo.h5\", \"df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from a HDF5 Store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to read an HDF5 file (\"foo.h5\") and load the data from the \"df\" dataset\n",
    "df = pd.read_hdf(\"foo.h5\", \"df\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel\n",
    "\n",
    "Reading and writing to MS Excel.\n",
    "\n",
    "Writing to an excel file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe 'df' to an Excel file with the name 'foo.xlsx'\n",
    "# The data will be written to the sheet named 'Sheet1'\n",
    "df.to_excel(\"foo.xlsx\", sheet_name=\"Sheet1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from an excel file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read an Excel file and load the data from \"Sheet1\"\n",
    "# - \"foo.xlsx\" is the path to the Excel file.\n",
    "# - \"Sheet1\" specifies the sheet name to be read.\n",
    "# - index_col=None ensures that no column is used as the index.\n",
    "# - na_values=[\"NA\"] specifies that any \"NA\" values in the data should be treated as NaN (Not a Number).\n",
    "df = pd.read_excel(\"foo.xlsx\", \"Sheet1\", index_col=None, na_values=[\"NA\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this module, we've learned about Understand Pandas data structures: Series and DataFrame. We also learn to create, read, and manipulate DataFrames, perform basic data analysis operations using Pandas, and handle missing data in Pandas\n",
    "\n",
    "## Clean up\n",
    "\n",
    "Remember to shut down your Jupyter Notebook instance when you're done to avoid unnecessary charges. You can do this by stopping the notebook instance from the Amazon SageMaker console."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
