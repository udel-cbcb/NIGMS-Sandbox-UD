{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas\n",
    "\n",
    "## Overview\n",
    "\n",
    "This module introduces Pandas, a powerful data manipulation library for Python. It covers basic operations, data structures, and common data analysis tasks using Pandas, including analyzing, cleaning, exploring, and manipulating data.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Understand Pandas data structures: Series and DataFrame\n",
    "- Learn to create, read, and manipulate DataFrames\n",
    "- Perform basic data analysis operations using Pandas\n",
    "- Handle missing data in Pandas\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Basic Python knowledge (For a refresher, see the [Python tutorial](https://docs.python.org/tutorial/).)\n",
    "- Familiarity with NumPy is helpful but not required\n",
    "\n",
    "## Get Started\n",
    "\n",
    "Install pandas and import the required libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the tables library to read and write HDF5 files, typically used for large datasets\n",
    "%pip install tables\n",
    "\n",
    "# Install the openpyxl library to read and write Excel files (.xlsx)\n",
    "%pip install openpyxl\n",
    "\n",
    "# Import pandas library, used for data manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Import numpy library, used for numerical operations and working with arrays\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object creation\n",
    "\n",
    "See the [introduction to data structures](https://pandas.pydata.org/docs/user_guide/dsintro.html#dsintro) section of Pandas documentation for details.\n",
    "\n",
    "You can create a [Series](https://pandas.pydata.org/docs/reference/api/pandas.Series.html#pandas.Series) (One-dimensional ndarray with axis labels, including time series) by passing a list of values, letting pandas create a default integer index:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas Series with some integer values and a NaN (Not a Number) value\n",
    "# The NaN value represents missing data or undefined values in the series\n",
    "s = pd.Series([1, 3, 5, np.nan, 6, 8])\n",
    "\n",
    "# Display the Series to view its contents\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas Series with hourly energy consumption values (in kWh) for a day\n",
    "# The index represents hours (0 to 23), and the values are sample energy readings\n",
    "energy = pd.Series(\n",
    "    [2.5, 2.7, 2.3, 2.1, 2.0, 2.4, 2.8, 3.0, 3.5, 3.2, 3.1, 2.9, 2.8, 2.6, 2.5, 2.7, 3.0, 3.4, 3.6, 3.2, 2.9, 2.5, 2.3, 2.1],\n",
    "    index=range(24)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the entire Series to view its contents\n",
    "print(\"Full Series:\")\n",
    "print(energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the `energy` Series to extract elements from index 2 to 15 (exclusive) with a step of 3\n",
    "# This means selecting every third element starting from index 2 up to (but not including) index 15\n",
    "# Corresponds to hours 2, 5, 8, 11, 14\n",
    "print(\"\\nSlice from index 2 to 15 with step 3:\")\n",
    "print(energy[2:15:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html#pandas.DataFrame) (Two-dimensional, size-mutable, potentially heterogeneous tabular data) by passing a NumPy array, with a datetime index and labeled columns:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a range of equally spaced time points (dates)\n",
    "# \"20220306\" is the starting date (March 6, 2022)\n",
    "# `periods=6` specifies that the range will contain 6 equally spaced dates\n",
    "dates = pd.date_range(\"20220306\", periods=6)\n",
    "\n",
    "# Displays the generated date range\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with random values from a standard normal distribution\n",
    "# The shape of the DataFrame is (6, 4), i.e., 6 rows and 4 columns\n",
    "# The index is set to the `dates` variable (which should be a list, array, or pandas DateTimeIndex)\n",
    "# The column labels are set to the list ['A', 'B', 'C', 'D']\n",
    "df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list(\"ABCD\"))\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create a DataFrame by passing a dictionary of objects that can be converted into a series-like structure:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame named df2 with various types of data for each column\n",
    "df2 = pd.DataFrame(\n",
    "    {\n",
    "        # Column 'A' with a constant value of 1.0 for all rows\n",
    "        \"A\": 1.0,\n",
    "        # Column 'B' with a single timestamp (2013-01-02) for all rows\n",
    "        \"B\": pd.Timestamp(\"20130102\"),\n",
    "        # Column 'C' with a pandas Series of length 4 filled with 1's, dtype is float32\n",
    "        \"C\": pd.Series(1, index=list(range(4)), dtype=\"float32\"),\n",
    "        # Column 'D' with a NumPy array of integers (3 repeated 4 times), dtype is int32\n",
    "        \"D\": np.array([3] * 4, dtype=\"int32\"),\n",
    "        # Column 'E' with a categorical variable containing 'test' and 'train'\n",
    "        \"E\": pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n",
    "        # Column 'F' with a string constant \"foo\" for all rows\n",
    "        \"F\": \"foo\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Display the DataFrame df2\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of the resulting DataFrame have different `dtypes`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the data types of each column in the DataFrame `df2`\n",
    "# This allows us to check the type of data stored in each column (e.g., int, float, object, etc.)\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing data\n",
    "\n",
    "See [Essential basic functionality](https://pandas.pydata.org/docs/user_guide/basics.html#basics) section of Pandas documentation for details.\n",
    "\n",
    "You can view the top and bottom rows of the frame:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)  # first three rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(2)  # last two rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can display the indexes and columns:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**describe**() shows a quick statistic summary of your data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposing your data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Sorting](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_index.html) by axis:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The axis along which to sort. The value 0 identifies the rows, and 1 identifies the columns.\n",
    "df.sort_index(axis=1, ascending=False)  # Sort based on column label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Sorting](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html#pandas.DataFrame.sort_values) by values:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"C\")  # Sort by 'C' column ascending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection\n",
    "\n",
    "See [Indexing and Selecting Data](https://pandas.pydata.org/docs/user_guide/indexing.html#indexing) section of Pandas documentation for details.\n",
    "\n",
    "Selecting a single column, which yields a Series, equivalent to df.A:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"A\"]  # Select 'A' column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting via [], which slices the rows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:4]  # Select first 4 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"20220306\":\"20220310\"]  # Get \"2022-03-06\" through \"2022-03-10\" rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection by label\n",
    "\n",
    "- **loc** selects rows and columns with specific labels.\n",
    "- **at** selects a single value for a row/column pair with specific labels (faster than `loc` when you only need a single value)\n",
    "\n",
    "Getting a cross section using a label:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[dates[0]]  # Get row indexed by '2022-03-06'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting on a multi-axis by label:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, [\"A\", \"B\"]]  # Get 'A' and 'B' columns for all rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing label slicing, both endpoints are included:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\n",
    "    \"20220307\":\"20220309\", [\"A\", \"B\"]\n",
    "]  # # Get 'A' and 'B' columns for rows indexed by '2022-03-07' through '2022-03-09'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduction in the dimensions of the returned object:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"20220308\", [\"A\", \"B\"]]  # Get 'A' and 'B' columns of '2022-03-08' row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a scalar value:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[dates[0], \"A\"]  # Get value at dates[0] row and 'A' column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting fast access to a scalar (equivalent to the prior method):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[dates[0], \"A\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection by position\n",
    "\n",
    "- **iloc** selects rows and columns at specific integer positions.\n",
    "- **iat** selects a single value for a row/column pair at specific integer positions (faster than `iloc` when you only need a single value)\n",
    "\n",
    "Selecting via the position of the passed integers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2]  # Get all values of third row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By integer slices, similar to NumPy/Python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3:5, 0:2]  # Get values of 4 and 5 rows, 'A', 'B' columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By lists of integer position locations, similar to the NumPy/Python style:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[1, 2, 4], [0, 2]]  # Get values of 2, 3, 5 rows, 'A', 'C' columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing rows explicitly:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1:3, :]  # Get values of 2 and 3 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing columns explicitly:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, 1:3]  # Get values of 2 and 3 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a value explicitly:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1, 1]  # Get value at 2nd row and 2nd columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting fast access to a scalar (equivalent to the prior method):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iat[1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean indexing\n",
    "\n",
    "Using a single column’s values to select data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"A\"] > 0]  # Get rows where 'A' columns is greater than 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the isin() method for filtering:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2[\"E\"] = [\"one\", \"one\", \"two\", \"three\", \"four\", \"three\"]  # Add new column 'E'\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\n",
    "    df2[\"E\"].isin([\"two\", \"four\"])\n",
    "]  # Get rows where the values in column 'E' is either \"two\" or \"four\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting\n",
    "\n",
    "Setting a new column automatically aligns the data by the indexes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series([1, 2, 3, 4, 5, 6], index=pd.date_range(\"20220306\", periods=6))\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"F\"] = s1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting values by label:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[dates[0], \"A\"] = 0  # Set the value at dates[0] and 'A' column to be 0\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting values by position:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iat[0, 1] = 0  # Set the value at first row, second column to be 0\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting by assigning with a NumPy array:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.columns[3]] = np.array([5] * len(df)) # Index-Based Assignment\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data\n",
    "\n",
    "See [Missing Data](https://pandas.pydata.org/docs/user_guide/missing_data.html#missing-data) section of Pandas documentation for details.\n",
    "\n",
    "Pandas primarily uses the value `np.nan` to represent missing data. It is by default not included in computations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindexing allows you to change/add/delete the index on a specified axis. This returns a copy of the data:\n",
    "df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + [\"E\"])\n",
    "# Add a new column \"E\" and set the first two rows of \"E\" to be \"1\"\n",
    "df1.loc[dates[0] : dates[1], \"E\"] = 1\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To drop any rows that have missing data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any missing (NaN) values\n",
    "# The 'how=\"any\"' parameter specifies that if any column in a row has a NaN value, that row will be dropped\n",
    "df1.dropna(how=\"any\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling missing data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing (NaN) values in the DataFrame `df1` with the specified value (5)\n",
    "df1.fillna(value=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the boolean mask where values are _NaN_:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing (NaN) values in the DataFrame 'df1'\n",
    "# df1.isna() returns a DataFrame of the same shape as 'df1' with True for NaN values and False for non-NaN values\n",
    "\n",
    "df1.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations\n",
    "\n",
    "See the [Flexible binary operations](https://pandas.pydata.org/docs/user_guide/basics.html#basics-binop) section of Pandas documentation for details.\n",
    "\n",
    "### Stats\n",
    "\n",
    "Operations in general exclude missing data.\n",
    "\n",
    "Performing a descriptive statistic:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.max(axis=0)  # Get max of all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same operation on the other axis:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.max(axis=1)  # Get max of all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame with employee performance metrics for three departments\n",
    "# The DataFrame includes some missing values (NaN) to demonstrate handling of incomplete data\n",
    "data = {\n",
    "    'Employee': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank'],\n",
    "    'Sales': [12000, 15000, None, 10000, 18000, 13000],\n",
    "    'Productivity': [85, 90, 78, 82, 95, None],\n",
    "    'Customer_Rating': [4.5, None, 4.0, 3.8, 4.8, 4.2]\n",
    "}\n",
    "df_emp = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the full DataFrame to view its contents\n",
    "print(\"Full DataFrame:\")\n",
    "print(df_emp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute descriptive statistics for all numerical columns using describe()\n",
    "# This provides count, mean, std, min, 25% (Q1), 50% (median), 75% (Q3), and max\n",
    "print(\"\\nDescriptive Statistics (describe()):\")\n",
    "print(df_emp.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute specific quantiles (10th, 25th, 75th, 90th percentiles) for each numerical column\n",
    "# quantile() accepts a single value or list of values between 0 and 1\n",
    "print(\"\\nCustom Quantiles (10th, 25th, 75th, 90th percentiles):\")\n",
    "print(df_emp[['Sales', 'Productivity', 'Customer_Rating']].quantile([0.1, 0.25, 0.75, 0.9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean for each metric\n",
    "print(\"\\nMean Values per Metric:\")\n",
    "print(df_emp[['Sales', 'Productivity', 'Customer_Rating']].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the median (50th percentile) for each metric\n",
    "print(\"\\nMedian Values per Metric:\")\n",
    "print(df_emp[['Sales', 'Productivity', 'Customer_Rating']].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the standard deviation for each metric\n",
    "print(\"\\nStandard Deviation per Metric:\")\n",
    "print(df_emp[['Sales', 'Productivity', 'Customer_Rating']].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count non-missing values for each metric\n",
    "print(\"\\nCount of Non-Missing Values per Metric:\")\n",
    "print(df_emp[['Sales', 'Productivity', 'Customer_Rating']].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the minimum value across all metrics for each employee\n",
    "# Use min() along axis=1 to find the lowest value per row (excluding 'Employee' column)\n",
    "print(\"\\nMinimum Value per Employee (across metrics):\")\n",
    "print(df_emp[['Sales', 'Productivity', 'Customer_Rating']].min(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply\n",
    "\n",
    "Applying functions to the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda x: x.max() - x.min(), axis=1)  # Get the max-min differences of columns\n",
    "# def test(x):\n",
    "#   result = x.max() - x.min()\n",
    "#   return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Methods\n",
    "\n",
    "Series is equipped with a set of string processing methods in the `str` attribute that make it easy to operate on each element of the array, as in the code snippet below. Note that pattern-matching in `str` generally uses regular expressions by default (and in some cases always uses them).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas Series with a mix of strings and a NaN value\n",
    "s = pd.Series([\"A\", \"B\", \"C\", \"Aaba\", \"Baca\", np.nan, \"CABA\", \"dog\", \"cat\"])\n",
    "\n",
    "# Apply the `str.lower()` function to convert all string elements in the Series to lowercase\n",
    "# This function works element-wise, meaning it will convert each string in the Series to lowercase\n",
    "s.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame with data about animal species\n",
    "# Columns include species name, weight, lifespan, population size, and predation risk\n",
    "data = {\n",
    "    'species': ['Tiger', 'Elephant', 'Blue Whale', 'Bald Eagle'],\n",
    "    'weight_kg': [250, 5000, 150000, 6],\n",
    "    'lifespan_years': [15, 60, 90, 20],\n",
    "    'population': [3900, 40000, 25000, 100000],\n",
    "    'predation_risk': [0.3, 0.1, 0.05, 0.2]\n",
    "}\n",
    "animal_data = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the full DataFrame to view its contents\n",
    "print(\"Full DataFrame:\")\n",
    "print(animal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the `animal_data` DataFrame to include animals with a weight greater than 1000 kg\n",
    "# The condition animal_data[\"weight_kg\"] > 1000 selects rows where the weight exceeds 1000 kg\n",
    "# Then, select only the columns whose names start with \"p\"\n",
    "# This is achieved using the str.startswith(\"p\") function on the column names\n",
    "filtered_data = animal_data[animal_data[\"weight_kg\"] > 1000][\n",
    "    animal_data.columns[pd.Series(animal_data.columns).str.startswith(\"p\")]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the filtered DataFrame\n",
    "print(\"\\nFiltered DataFrame (weight > 1000 kg, columns starting with 'p'):\")\n",
    "print(filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data in/out\n",
    "\n",
    "### CSV\n",
    "\n",
    "Writing to a csv file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame `df` to a CSV file named \"foo.csv\"\n",
    "# The `to_csv` method writes the data from the DataFrame into a CSV file\n",
    "df.to_csv(\"foo.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from a csv file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to read a CSV file and load its contents into a DataFrame\n",
    "df = pd.read_csv(\"foo.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5\n",
    "\n",
    "HDF5 is a unique technology suite that makes possible the management of extremely large and complex data collections. If you want to know more about HDF5 format, please see [Introduction to HDF5](https://support.hdfgroup.org/documentation/hdf5/latest/_intro_h_d_f5.html) for details.\n",
    "\n",
    "Reading and writing to HDFStores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame 'df' to a HDF5 file named 'foo.h5', with the data stored under the key \"df\"\n",
    "df.to_hdf(\"foo.h5\", key=\"df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from a HDF5 Store:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to read an HDF5 file (\"foo.h5\") and load the data from the \"df\" dataset\n",
    "df = pd.read_hdf(\"foo.h5\", \"df\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace specific cells with NaN using loc\n",
    "df.loc[1, 'A'] = np.nan  # Row index 1, PageRank column\n",
    "df.loc[2, 'D'] = np.nan    # Row index 2, Degree column\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel\n",
    "\n",
    "Reading and writing to MS Excel.\n",
    "\n",
    "Writing to an excel file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe 'df' to an Excel file with the name 'foo.xlsx'\n",
    "# The data will be written to the sheet named 'Sheet1'\n",
    "df.to_excel(\"foo.xlsx\", sheet_name=\"Sheet1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from an excel file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read an Excel file and load the data from \"Sheet1\"\n",
    "# - \"foo.xlsx\" is the path to the Excel file.\n",
    "# - \"Sheet1\" specifies the sheet name to be read.\n",
    "# - index_col=None ensures that no column is used as the index.\n",
    "# - na_values=[\"NA\"] specifies that any \"NA\" values in the data should be treated as NaN (Not a Number).\n",
    "df = pd.read_excel(\"foo.xlsx\", \"Sheet1\", index_col=None, na_values=[\"NA\"])\n",
    "new_columns = ['id', 'date'] + df.columns[2:].tolist()\n",
    "df.columns = new_columns\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this module, we've learned about understanding Pandas data structures: Series and DataFrame. We also learned to create, read, and manipulate DataFrames, performed basic data analysis operations using Pandas, and handled missing data in Pandas.\n",
    "\n",
    "## Clean up\n",
    "\n",
    "Remember to shut down your Jupyter Notebook instance when you're done to avoid unnecessary charges. You can do this by stopping the notebook instance from the Amazon SageMaker console.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
