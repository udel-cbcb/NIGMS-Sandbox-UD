{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submodule 2 - Data Science Life Cycles, FAIR Data Principles, Data-Centric AI/ML, and Responsible AI/ML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This submodule will cover Data Science life cycle, FAIR principles for responsible data management, systematically engineering the data used to build an AI/ML system, and understand fairness, transparency, and accountability in AI/ML development and deployment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "At the end of this module, you should be able to:\n",
    "\n",
    "- Understand the data science life cycle\n",
    "- FAIR data principles and metrics to measure the FAIRness of a digital resource\n",
    "- The discipline of systematically engineering the data used to build an AI/ML system\n",
    "- The development and deployment of AI/ML systems that are ethical, fair, transparent, and accountable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- An AWS account with access to Amazon SageMaker\n",
    "- Basic understanding of Python programming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Started\n",
    "\n",
    "- Watch the Lecture Videos.\n",
    "- Complete the Quizzes to solidify your understanding.\n",
    "- Enhance your programming skills with Tutorials.\n",
    "- Challenge yourself with the Exercises.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Science Life Cycle\n",
    "\n",
    "Data Science has deep roots in the world of business analytics where decades of work has leveraged customer databases, financial data, and other metrics to optimize and predict the success of business models. Many of the same concepts that apply in business are relevant to all applications of data science. In this lecture we will examine the data science lifecycle and generalize it to a concept that can easily be applied to any scientific data analysis.\n",
    "\n",
    "The data science lifecycle is a structured process for analyzing data to extract valuable insights. While there are variations, most projects follow a similar set of steps. This process originated in the business world for predictive modeling but can be applied in other fields and for various analytical tasks.\n",
    "\n",
    "The lifecycle starts with clearly defining the problem you're trying to solve. This includes specifying the scope of your questions and the types of data you'll need. Next comes data gathering, which might involve collecting existing data, generating new data, or a combination of both. It's crucial to collect metadata alongside the data itself.\n",
    "\n",
    "Data cleaning follows, where you ensure consistency in format, merge elements with conflicting names, and remove low-quality data. This prepares the data for exploration, where you perform preliminary analysis to identify relevant and irrelevant data types. This stage might also involve generating hypotheses about the data.\n",
    "\n",
    "The next step involves selecting the most relevant data. Removing incomplete, inconsistent, or irrelevant data is crucial for accurate analysis. For models, data is split into training and testing sets. Otherwise, validated \"gold standard\" and control data might be chosen.\n",
    "\n",
    "Modeling or analysis is where the data is put to work. Models are trained and applied, other analyses are conducted, and new methods might be compared with known outcomes for validation purposes.\n",
    "\n",
    "Once the analysis is complete, data visualization and interpretation become crucial. Visualizations help summarize the data and make it understandable. You'll need to interpret the results and compare them with existing knowledge to draw meaningful conclusions.\n",
    "\n",
    "The final step is to maintain and disseminate the data. Following the FAIR principles (Findable, Accessible, Interoperable, Reusable), data and metadata are formatted and stored in accessible repositories. This might involve internal corporate databases or broader dissemination through global repositories and publications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture Video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "# Youtube\n",
    "YouTubeVideo(id=\"data_science_life_cycles\", height=200, width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture Slides\n",
    "\n",
    "Download the lecture slides [Data Science Life Cycle](Submodule_2/Lectures/Submodule_2_Lecture_1_Data_Science_Life_Cycle.pptx).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quizzes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install jupyterquiz\n",
    "\n",
    "from jupyterquiz import display_quiz\n",
    "\n",
    "display_quiz(\"Submodule_2/Quizzes/Submodule_2_Quiz_1_Data_Science_Life_Cycle.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. FAIR Data Principles and FAIRness Metrics\n",
    "\n",
    "This section covers the principles of FAIR data analysis. As data has become more and more prevalent and our ability to analyze and reanalyze data has increased, there has been a growing need for standards to make sure that data produced today will still be accessible and usable tomorrow. The FAIR data principles are a set of guidelines for how to achieve this. Funding agencies including the NIH and NSF are increasingly asking (or requiring) their funded research to comply to these standards.\n",
    "\n",
    "The FAIR Data Principles stand for Findable, Accessible, Interoperable, and Reusable. Introduced in 2016, these principles aim to improve the discoverability, accessibility, and ultimately, the reusability of research data.\n",
    "\n",
    "FAIR data benefits both the research community and individual researchers. By making data more openly available and usable, FAIR principles can lead to:\n",
    "\n",
    "Increased collaboration and knowledge sharing\n",
    "More efficient research by allowing others to reuse existing data\n",
    "More citations for your work, as your data becomes a valuable resource for others\n",
    "Let's break down the FAIR acronym:\n",
    "\n",
    "**Findable:** This means your data and its descriptive information (metadata) are easily discoverable by others. Key aspects include assigning unique identifiers, using rich and detailed metadata, and registering your data in searchable resources.\n",
    "\n",
    "**Accessible:** Once your data is found, it should be readily accessible to those who need it. This involves storing data in open and free repositories or using appropriate protocols for sensitive data. Importantly, even if the primary data becomes unavailable, the metadata should remain accessible.\n",
    "\n",
    "**Interoperable:** Your data and metadata should be understandable and usable across different software and platforms. This means using standard formats, controlled vocabularies, and clear descriptions to make your data interpretable by both humans and computers.\n",
    "\n",
    "**Reusable:** To maximize its value, your data needs to be reusable by other researchers. This requires providing detailed information about the data, including usage licenses, provenance (data origin), and using common and expected data formats.\n",
    "\n",
    "Following FAIR principles can be challenging. There's no universal search engine for all data, and long-term data storage can be expensive. Proprietary software formats can also limit accessibility, and incomplete metadata hinders reusability. However, by following these guidelines, researchers can significantly increase the impact and reach of their work.\n",
    "\n",
    "Measuring the FAIRness of data is essential for ensuring its long-term value and impact. Various metrics have been developed to assess adherence to FAIR principles. These metrics focus on factors such as the existence and uniqueness of identifiers, the richness and accuracy of metadata, the accessibility of data through standardized protocols, the use of interoperable formats and vocabularies, and the clarity of data usage licenses and provenance information. By applying these metrics, researchers and institutions can evaluate the FAIRness of their data management practices and identify areas for improvement, ultimately enhancing data discoverability, reusability, and scientific impact.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture Video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "# Youtube\n",
    "YouTubeVideo(id=\"fair_data_principles_fairness_metrics\", height=200, width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture Slides\n",
    "\n",
    "Download the lecture slides [FAIR Data Principles and FAIRness Metrics](Submodule_2/Lectures/Submodule_2_Lecture_2_FAIR_Data_Principles_and_FAIRness_Metrics.pptx).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quizzes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterquiz import display_quiz\n",
    "\n",
    "display_quiz(\n",
    "    \"Submodule_2/Quizzes/Submodule_2_Quiz_2_FAIR_Data_Principles_and_FAIRness_Metrics.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Centric AI/ML\n",
    "\n",
    "In this section we will introduce the difference between Model-Centric AI/ML and Data-Centric AI/ML, the principles of Data-Centric AI/ML, and the Data-Centric AI/ML approaches.\n",
    "\n",
    "The field of AI/ML has traditionally focused on model-centric approaches, where the primary emphasis is on optimizing the model architecture and training process. This involves selecting the right model architecture, tuning hyperparameters, and employing advanced techniques like feature engineering. While model-centric approaches have yielded significant advancements, they often rely on large, high-quality datasets, which can be challenging to obtain and curate.\n",
    "\n",
    "In recent years, a paradigm shift has emerged towards data-centric AI/ML. This approach prioritizes the quality and quantity of data, recognizing that high-quality data can significantly improve model performance, even with simpler model architectures. Key aspects of data-centric AI/ML include data quality, quantity, diversity, labeling, augmentation, cleaning, and management. By focusing on these factors, practitioners can develop more robust and accurate AI models.\n",
    "\n",
    "Data-centric AI/ML principles emphasize a systematic approach to improving data quality and its impact on model performance. These principles include:\n",
    "\n",
    "**Systematic Improvement of Data Fit:** Techniques like data augmentation, cleaning, and addressing bias can enhance data fit for the model.\n",
    "\n",
    "**Systematic Improvement of Data Consistency:** Using automation, inter-annotator reliability assessment, and standardized guidelines ensure consistent data quality.\n",
    "\n",
    "**Mutual Improvement of Model and Data through Iteration:** Analyze errors, refine data through augmentation, employ continuous learning, and monitor model performance to create a feedback loop for improvement.\n",
    "\n",
    "**Human-Centeredness of Data Work:** Recognize the human element in data collection, cleaning, labeling, and curation, addressing bias, and considering context.\n",
    "\n",
    "**AI as a Sociotechnical System:** Design AI systems with human needs, ethics, user experience, explainability, and collaboration in mind.\n",
    "\n",
    "**Continuous and Substantive Interactions between AI and Domain Experts:** Domain expertise is crucial for providing insights into specific contexts and ensuring data relevance.\n",
    "\n",
    "By adopting data-centric AI/ML principles and leveraging appropriate tools and techniques, organizations can build more effective and reliable AI systems. In practice, while data-centric AI/ML focuses on improving data quality, model-centric AI/ML focuses on improving the model itself. In practice, a successful AI/ML project often involves a combination of both approaches, iteratively improving both the data and the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lecture Video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "# Youtube\n",
    "YouTubeVideo(id=\"data_centric_ai_ml\", height=200, width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture Slides\n",
    "\n",
    "Download the lecture slides [Data Centric AI/ML](Submodule_2/Lectures/Submodule_2_Lecture_3_Data_Centric_AL_ML.pptx).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quizzes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterquiz import display_quiz\n",
    "\n",
    "display_quiz(\"Submodule_2/Quizzes/Submodule_2_Quiz_3_Data_Centric_AI_ML.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Responsible AI/ML\n",
    "\n",
    "In this section we will introduce responsible AI/ML, common biases in AI/ML datasets, fairness in machine learning life cycle, how to measure fairness, how to do bias mitigation and finally some responsible AI/ML tools.\n",
    "\n",
    "Responsible AI/ML: A Comprehensive Guide\n",
    "Responsible AI/ML is a field focused on developing and using AI systems in a fair, unbiased, transparent, and accountable manner. The goal is to ensure that AI systems are used ethically and beneficially for society.\n",
    "\n",
    "One of the core principles of responsible AI is fairness. AI systems should not discriminate against individuals based on factors they cannot control, such as race, gender, or age. It's crucial to train models on diverse datasets to avoid biases and ensure that the system treats all users fairly.\n",
    "\n",
    "Another important aspect is transparency. AI systems should be explainable, meaning that their decision-making processes should be understandable to humans. This helps build trust and allows for accountability. Additionally, users should be informed about how the system works and how their data is being used.\n",
    "\n",
    "Robustness is another key consideration. AI systems should be resistant to manipulation and adversarial attacks. This involves techniques like adversarial training, which exposes the model to adversarial examples to improve its robustness.\n",
    "\n",
    "Privacy and security are also critical. Data used to train and operate AI systems should be handled responsibly, ensuring it is protected from unauthorized access and used in accordance with privacy regulations.\n",
    "\n",
    "To achieve these goals, various fairness metrics can be used to evaluate AI systems. These metrics measure the fairness of a system based on different criteria, such as demographic parity, equalized odds, and predictive parity. By using these metrics, developers can identify and mitigate biases in their models.\n",
    "\n",
    "Several techniques can be employed to mitigate bias in AI systems. These include data augmentation, reweighting, and fair learning algorithms. Data augmentation involves creating synthetic data to increase the diversity of the training data. Reweighting assigns different weights to different data points to reduce the impact of biased samples. Fair learning algorithms are specifically designed to minimize bias in the learning process.\n",
    "\n",
    "Tools and frameworks are available to support the development of responsible AI systems. These tools provide metrics for assessing fairness, techniques for mitigating bias, and best practices for responsible AI development. By leveraging these tools, developers can create AI systems that are fair, transparent, and accountable.\n",
    "\n",
    "In conclusion, responsible AI/ML is essential for ensuring that AI technology is used ethically and beneficially. By understanding the principles of fairness, transparency, robustness, and privacy, and by using appropriate tools and techniques, we can develop AI systems that benefit society as a whole.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lecture Video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "# Youtube\n",
    "YouTubeVideo(id=\"responsible_ai_ml\", height=200, width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture Slides\n",
    "\n",
    "Download the lecture slides [Responsible AI/ML](Submodule_2/Lectures/Submodule_2_Lecture_4_Responsible_AL_ML.pptx).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quizzes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterquiz import display_quiz\n",
    "\n",
    "display_quiz(\"Submodule_2/Quizzes/Submodule_2_Quiz_3_Data_Centric_AI_ML.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tutorials\n",
    "\n",
    "- [Data Centric AI/ML: Diabetes Dataset Example](Submodule_2/Tutorials/Submodule_2_Tutorial_1_Data_Centric_AI_ML.ipynb)\n",
    "- [Responsible AI/ML: Ensuring Transparency, Fairness, and Privacy in Machine Learning](Submodule_2/Tutorials/Submodule_2_Tutorial_2_Responsible_AI_ML.ipynb)\n",
    "\n",
    "## 6. Exercises\n",
    "\n",
    "- [Data-Centric AI: A Practical Comparison of Poorly-Prepared vs Well-Prepared Data](Submodule_2/Exercises/Submodule_2_Exercise_1_Data_Centric_AI_ML.ipynb)([Solution](Submodule_2/Exercises/Submodule_2_Exercise_1_Data_Centric_AI_ML_Solution.ipynb))\n",
    "- [Responsible AI/ML: Diabetes Prediction with Fairness and Transparency](Submodule_2/Exercises/Submodule_2_Exercise_2_Responsible_AI_ML.ipynb)([Solution](Submodule_2/Exercises/Submodule_2_Exercise_2_Responsible_AI_ML_Solution.ipynb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "The field of data science and AI/ML is rapidly evolving, with a strong emphasis on responsible and ethical practices. The data science lifecycle provides a structured approach to analyzing data, from problem definition to data dissemination. FAIR Data Principles (Findable, Accessible, Interoperable, and Reusable) are essential for ensuring data's long-term value and impact. Data-centric AI/ML shifts the focus from model optimization to data quality, recognizing that high-quality data can significantly improve model performance. Responsible AI/ML aims to develop and use AI systems in a fair, unbiased, transparent, and accountable manner. By adhering to these principles and leveraging advanced tools and techniques, we can harness the power of AI to solve complex problems while ensuring ethical and responsible use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "A reminder to shutdown VM and delete any relevant resources. <br><br>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
