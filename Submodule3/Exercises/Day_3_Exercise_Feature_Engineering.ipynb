{"cells":[{"cell_type":"markdown","source":["#**Feature Engineering Exercise**\n","\n","Data processing and feature\n","engineering is often described to be the toughest task or step in building any Machine Learning system by\n","data scientists. With the need of both domain knowledge as well as mathematical transformations, feature\n","engineering is often said to be both an art as well as a science. The obvious complexities involve dealing\n","with diverse types of data and variables. Besides this, each Machine Learning problem or task needs\n","specific features and there is no one solution fits all in the case of feature engineering. This makes feature\n","engineering all the more difficult and complex.\n","\n","Adapted from Dipanjan Sarkar et al. 2018. [Practical Machine Learning with Python](https://link.springer.com/book/10.1007/978-1-4842-3207-1)."],"metadata":{"id":"q10Gm8LMWmwx"}},{"cell_type":"markdown","source":["# Feature Engineering on Numeric Data\n","\n"],"metadata":{"id":"ljoVikY9cnth"}},{"cell_type":"markdown","source":["Even though numeric data can be directly fed into Machine Learning models, you would still need to\n","engineer features that are relevant to the scenario, problem, and domain before building a model. Hence\n","the need for feature engineering remains. Important aspects of numeric features include feature scale and\n","distribution. In some scenarios,\n","we need to apply specific transformations to change the scale of numeric values and in other scenarios we\n","need to change the overall distribution of the numeric values, like transforming a skewed distribution to a\n","normal distribution."],"metadata":{"id":"3Tzu8xuseIh3"}},{"cell_type":"code","source":["# Import necessary dependencies and settings\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","import numpy as np\n","import scipy.stats as spstats\n","\n","%matplotlib inline\n","mpl.style.reload_library()\n","mpl.style.use('classic')\n","mpl.rcParams['figure.facecolor'] = (1, 1, 1, 0)\n","mpl.rcParams['figure.figsize'] = [6.0, 4.0]\n","mpl.rcParams['figure.dpi'] = 100"],"metadata":{"id":"DNpmWCUzeMuS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Raw Measures\n","\n","Raw measures typically\n","indicated using numeric variables directly as features without any form of transformation or engineering.\n","Typically these features can indicate values or counts."],"metadata":{"id":"E2hIPKWJelMX"}},{"cell_type":"markdown","source":["###Values\n","\n","Usually, scalar values in its raw form indicate a specific measurement, metric, or observation belonging to\n","a specific variable or field. The semantics of this field is usually obtained from the field name itself or a data\n","dictionary if present."],"metadata":{"id":"rJsnZtOUfnsY"}},{"cell_type":"markdown","source":["###Ecoli Dataset\n","\n","Ecoli dataset is for predicting Protein Localization Sites in Ecoli. \n","```\n","Number of Instances:  336 \n","Number of Attributes: 8 ( 7 predictive, 1 name )\n","Attribute Information.\n","  1. Sequence Name: Accession number for the SWISS-PROT database\n","  2. mcg: McGeoch's method for signal sequence recognition.\n","  3. gvh: von Heijne's method for signal sequence recognition.\n","  4. lip: von Heijne's Signal Peptidase II consensus sequence score (Binary attribute).\n","  5. chg: Presence of charge on N-terminus of predicted lipoproteins (Binary attribute).\n","  6. aac: score of discriminant analysis of the amino acid content of outer membrane and periplasmic proteins.\n","  7. alm1: score of the ALOM membrane spanning region prediction program.\n","  8. alm2: score of ALOM program after excluding putative cleavable signal regions from the sequence.\n","Missing Attribute Values: None.\n","Class Distribution. The class is the localization site.\n","  cp  (cytoplasm)                                    143\n","  im  (inner membrane without signal sequence)        77               \n","  pp  (perisplasm)                                    52\n","  imU (inner membrane, uncleavable signal sequence)   35\n","  om  (outer membrane)                                20\n","  omL (outer membrane lipoprotein)                     5\n","  imL (inner membrane lipoprotein)                     2\n","  imS (inner membrane, cleavable signal sequence)      2\n","```\n","You can learn more about the dataset here:\n","* Ecoli Dataset ([ecoli.csv](https://raw.githubusercontent.com/jbrownlee/Datasets/master/ecoli.data))\n","* Ecoli Dataset Description ([ecoli.names](https://raw.githubusercontent.com/jbrownlee/Datasets/master/ecoli.names))\n"],"metadata":{"id":"stGKzhBo7s30"}},{"cell_type":"code","source":["# Download Ecoli dataset\n","!pip install wget\n","!python -m wget -O ecoli.csv \"https://raw.githubusercontent.com/udel-cbcb/al_ml_workshop/main/data/ecoli.csv\"\n","\n","ecoli_df = pd.read_csv('ecoli.csv')\n","ecoli_df.head(10)"],"metadata":{"id":"7T8aEKeGhK_6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Show some of features\n","ecoli_df[['mcg', 'gvh', 'chg']].head()"],"metadata":{"id":"Ut1AtWw3h7yr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compute basic statistical measures on the fields of 'mcg', 'gvh', 'chg'\n","\n","# Your code goes here"],"metadata":{"id":"Yd8BnMBtiGwJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Counts\n","Raw numeric measures can also indicate counts, frequencies and occurrences of specific attributes."],"metadata":{"id":"GHnA8AqBiK0i"}},{"cell_type":"markdown","source":["###Diabetes Dataset\n","The dataset classifies patient data as\n","either an onset of diabetes within five years or not. \n","\n","```\n","Number of Instances: 768\n","Number of Attributes: 8 plus class \n","For Each Attribute: (all numeric-valued)\n","   1. Number of times pregnant\n","   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n","   3. Diastolic blood pressure (mm Hg)\n","   4. Triceps skin fold thickness (mm)\n","   5. 2-Hour serum insulin (mu U/ml)\n","   6. Body mass index (weight in kg/(height in m)^2)\n","   7. Diabetes pedigree function\n","   8. Age (years)\n","   9. Class variable (0 or 1)\n","Missing Attribute Values: Yes\n","Class Distribution: (class value 1 is interpreted as \"tested positive for\n","   diabetes\")\n","   Class Value  Number of instances\n","   0            500\n","   1            268\n","```\n","\n","You can learn more about the dataset here:\n","\n","* Diabetes Dataset File ([pima-indians-diabetes.csv](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv))\n","* Diabetes Dataset Details ([pima-indians-diabetes.names](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names))"],"metadata":{"id":"slXEDf3KAL6Q"}},{"cell_type":"code","source":["# Download Diabetes dataset\n","!python -m wget -o pima-indians-diabetes.csv \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv\""],"metadata":{"id":"1FIMax2mio1k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["diabetes_df = pd.read_csv('pima-indians-diabetes.csv', header=None)\n","diabetes_df.columns=['pregnancy', 'glucose', 'bp', 'triceps', 'insulin', 'bmi', 'pedigree', 'age', 'diabetes']\n","diabetes_df.head(10)"],"metadata":{"id":"Fvo_wUbOixzw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["diabetes_df.describe()"],"metadata":{"id":"uvyxFjgGCciF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Binarization\n","\n","If you are more concerned about the various songs he/she has listened to. In this case, a binary\n","feature is preferred as opposed to a count based feature."],"metadata":{"id":"lHjF4M3ejBwP"}},{"cell_type":"code","source":["# Binarize 'age' field manually\n","age = np.array(diabetes_df['age']) \n","old = np.array(diabetes_df['age']) \n","old[age > 50] = 1\n","old[age <= 50] = 0\n","diabetes_df['old'] = old\n","\n","diabetes_df.head(10)"],"metadata":{"id":"mWoFsQ7DjRFG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Binarize 'age' field using Binarizer\n","from sklearn.preprocessing import Binarizer\n","\n","# Binarize data (set feature values to 0 or 1) according to a threshold.\n","# Values greater than the threshold map to 1, while values less than\n","# or equal to the threshold map to 0. With the default threshold of 0,\n","# only positive values map to 1.\n","\n","bn = # Your code goes here\n","\n","bn_old = bn.transform([diabetes_df['age']])[0]\n","diabetes_df['bn_old'] = bn_old\n","diabetes_df.head(10)"],"metadata":{"id":"mfa2ddzdjdu6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Rounding\n","Often when dealing with numeric attributes like proportions or percentages, we may not need values with a\n","high amount of precision. Hence it makes sense to round off these high precision percentages into numeric\n","integers. These integers can then be directly used as raw numeric values or even as categorical (discreteclass\n","based) features."],"metadata":{"id":"jY8yf-IMj7Ic"}},{"cell_type":"code","source":["# Creare a column 'pedigree_scale_10' and rounding off the 'pedigree' by 10\n","diabetes_df['pedigree_scale_10'] = np.array(np.round((diabetes_df['pedigree'] * 10)), dtype='int')\n","# Creare a column 'popularity_scale_100' and rounding off the 'pop_percent' by 100\n","diabetes_df['pedigree_scale_100'] = # Your code goes here\n","diabetes_df"],"metadata":{"id":"4aSnd2fZkfR4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Interactions\n","Often in real-world datasets and scenarios, it makes sense to also try to capture the\n","interactions between these feature variables as a part of the input feature set."],"metadata":{"id":"zkx70OOrlYYX"}},{"cell_type":"code","source":["gvh_lip = ecoli_df[['gvh','lip']]\n","gvh_lip.head()"],"metadata":{"id":"dY2-kCc7l3eN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import PolynomialFeatures\n","# build features up to the second degree using the PolynomialFeatures class from scikit-learn's API.\n","\n","pf = # Your code goes here\n","res = pf.fit_transform(gvh_lip)\n","res"],"metadata":{"id":"jFl1Fi-3l4RJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We have a total of five features including the new interaction\n","features."],"metadata":{"id":"D4BzfeE2mEzB"}},{"cell_type":"markdown","source":["We can see the degree of each feature in the matrix."],"metadata":{"id":"ykSdZdy-mLSB"}},{"cell_type":"code","source":["pd.DataFrame(pf.powers_, columns=['gvh_degree', 'lip_degree'])"],"metadata":{"id":"5q6_AeDPmKtW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now that we know what each feature actually represented from the degrees depicted, we can assign a\n","name to each feature as follows to get the updated feature set."],"metadata":{"id":"4UrZWgqSmVl9"}},{"cell_type":"code","source":["intr_features = pd.DataFrame(res, columns=['gvh', 'lip', 'gvh^2', 'gvh x lip', 'lip^2'])\n","intr_features.head(5)  "],"metadata":{"id":"99JnS71JmX3j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Transforming new data in the future (during predictions)"],"metadata":{"id":"ZUoEjXIGmuwB"}},{"cell_type":"code","source":["# take some sample new observations for Pok mon attack and defense features and try to transform\n","# them using this same mechanism.\n","new_df = pd.DataFrame([[0.35, 0.49],[0.46, 0.38], [0.25, 0.48]], \n","                      columns=['gvh', 'lip'])\n","new_df"],"metadata":{"id":"ihcFMlhIm2wf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# use the pf object that we created earlier and transform these input features to give us the\n","# interaction features\n","new_res = pf.transform(new_df)\n","new_intr_features = # Your code goes here\n","new_intr_features"],"metadata":{"id":"Qr-i5KxHm5E-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Feature Engineering on Categorical Data\n","\n","Any attribute or feature that is categorical in nature represents discrete values that belong to a specific\n","finite set of categories or classes. Category or class labels can be text or numeric in nature. Usually there are\n","two types of categorical variables—nominal and ordinal.\n"],"metadata":{"id":"DJMGsfZVQ18k"}},{"cell_type":"code","source":["# Import necessary dependencies and settings\n","import pandas as pd\n","import numpy as np"],"metadata":{"id":"maQ7yB2RRrVf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Transforming Nominal Features\n","\n","Nominal features or attributes are categorical variables that usually have a finite set of distinct discrete\n","values. Often these values are in string or text format and Machine Learning algorithms cannot understand\n","them directly. Hence usually you might need to transform these features into a more representative numeric\n","format."],"metadata":{"id":"KwfCaxaSRiQX"}},{"cell_type":"code","source":["ecoli_df.head(11)"],"metadata":{"id":"wosRK7QBSPgH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The dataset depicted in this dataframe shows us various attributes pertaining to video games. Features\n","like Platform, Genre, and Publisher are nominal categorical variables."],"metadata":{"id":"zOY26WmmSgGR"}},{"cell_type":"code","source":["sites = np.unique(ecoli_df['site'])\n","sites"],"metadata":{"id":"fUbEKpa8T4pC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This output tells us we have 8 distinct sites in Ecoli dataset. "],"metadata":{"id":"z03Cc3zUS5od"}},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","\n","# Let’s transform this feature now using a mapping scheme of 'site'\n","sle = # Your code goes here\n","site_labels = # Your code goes here\n","site_mappings = {index: label for index, label in enumerate(sle.classes_)}\n","site_mappings"],"metadata":{"id":"uctBbCv8URBq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A mapping scheme has been generated where each site value is\n","mapped to a number with the help of the LabelEncoder object sle. The transformed labels are stored in the\n","site_labels value."],"metadata":{"id":"sSlxCwDiT_8v"}},{"cell_type":"code","source":["ecoli_df['siteLabel'] = site_labels\n","ecoli_df.head(11)"],"metadata":{"id":"JNHQcvdGUGns"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The SiteLabel field shows the mapped numeric labels for each of the site labels and we can clearly\n","see that this adheres to the mappings that we generated earlier."],"metadata":{"id":"BmZ6bpqTULa1"}},{"cell_type":"markdown","source":["##Transforming Ordinal Features\n","\n","Ordinal features are similar to nominal features except that order matters and is an inherent property with\n","which we can interpret the values of these features. Like nominal features, even ordinal features might be\n","present in text form and you need to map and transform them into their numeric representation."],"metadata":{"id":"04p7_uzMURbi"}},{"cell_type":"markdown","source":["###Create Generation based on 'age'"],"metadata":{"id":"26lhIudr_tj8"}},{"cell_type":"code","source":["age = np.array(diabetes_df['age']) \n","\n","diabetes_df['Generation'] = diabetes_df['age'].apply(lambda value: 'Gen Z' \n","                                                          if value <= 25 else 'Millennials' \n","                                                              if value <= 41 else 'Gen X'\n","                                                                  if value <= 57 else 'Boomers II'\n","                                                                     if value <= 67 else 'Boomers I'\n","                                                                        if value <= 76 else 'Post WWII'\n","                                                                            if value <= 94 else 'WWII'\n","                                                              )\n","\n","diabetes_df[['age', 'Generation']].head(10)"],"metadata":{"id":"p5_NbXRZ5L3-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.unique(diabetes_df['Generation'])"],"metadata":{"id":"arsCBNHF64oS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["From this output we can see that there are a total of six generations of people. This attribute is definitely ordinal and they have a sense of order among them.\n","\n","However, there is no generic module or function to map and transform these features into numeric representations. Hence we need to hand-craft this using our own logic, which is depicted in the following code snippet."],"metadata":{"id":"2zie_wq67B14"}},{"cell_type":"code","source":["gen_ord_map = {'Gen Z': 1, 'Millennials': 2, 'Gen X': 3, \n","               'Boomers II': 4, 'Boomers I': 5, 'Post WWII': 6}\n","\n","diabetes_df['GenerationLabel'] = diabetes_df['Generation'].map(gen_ord_map)\n","diabetes_df[['age', 'Generation', 'GenerationLabel']].iloc[4:10]"],"metadata":{"id":"Yp9OAZrM7gRh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Create BML Class based on 'bmi'"],"metadata":{"id":"59FxtlRq_5HK"}},{"cell_type":"code","source":["bmi = np.array(diabetes_df['bmi']) \n","\n","diabetes_df['BMI'] = diabetes_df['bmi'].apply(lambda value: 'Underweight' \n","                                                          if value <= 18.5 else 'Normal' \n","                                                              if value <= 22.9 else 'Pre-obese'\n","                                                                  if value <= 24.9 else 'Class I obesity'\n","                                                                     if value <= 29.9 else 'Class II obesity'\n","                                                                        if value <= 34.9 else 'Class II obesity'\n","                                                              )\n","\n","diabetes_df[['bmi', 'BMI']].head(10)"],"metadata":{"id":"Reyk3Bn4-Izz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.unique(diabetes_df['BMI'])"],"metadata":{"id":"wYvQMY-O_h0C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["From this output we can see that there are a total of five BML classes. This attribute is definitely ordinal and they have a sense of order among them.\n","\n","However, there is no generic module or function to map and transform these features into numeric representations. Hence we need to hand-craft this using our own logic, which is depicted in the following code snippet."],"metadata":{"id":"r7JVJU5z_-nS"}},{"cell_type":"code","source":["bmi_ord_map = # Your code goes here\n","\n","diabetes_df['BMILabel'] = # Your code goes here\n","diabetes_df[['bmi', 'BMI', 'BMILabel']].iloc[4:10]"],"metadata":{"id":"6ADlMSRcAIHe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["From this output we can see that there are a total of six\n","generations of Pok mon. This attribute is definitely ordinal because Pok mon belonging to Generation 1\n","were introduced earlier in the video games and the television shows than Generation 2 and so on. Hence\n","they have a sense of order among them. \n","\n","However, there is no generic module or function to map and transform these features\n","into numeric representations. Hence we need to hand-craft this using our own logic, which is depicted in the\n","following code snippet."],"metadata":{"id":"EoGoGOr8VjCf"}},{"cell_type":"markdown","source":["##Encoding Categorical Features\n","\n","If we directly fed these transformed numeric\n","representations of categorical features into any algorithm, the model will essentially try to interpret these as\n","raw numeric features and hence the notion of magnitude will be wrongly introduced in the system.\n","\n","Hence models built using these features directly would\n","be sub-optimal and incorrect models. There are several schemes and strategies where dummy features are\n","created for each unique value or label out of all the distinct categories in any feature. In the subsequent\n","sections, we will discuss some of these schemes including one hot encoding, dummy coding, effect coding,\n","and feature hashing schemes."],"metadata":{"id":"B9wVdl1NV2sd"}},{"cell_type":"markdown","source":["###One Hot Encoding Scheme\n","Considering we have numeric representation of any categorical feature with m labels, the one hot encoding\n","scheme, encodes or transforms the feature into m binary features, which can only contain a value of 1 or 0. Each observation in the categorical feature is thus converted into a vector of size m with only one of the\n","values as 1 (indicating it as active)."],"metadata":{"id":"96MgHqfnW6ga"}},{"cell_type":"code","source":["diabetes_df[['diabetes', 'Generation', 'BMI']].iloc[4:10]"],"metadata":{"id":"6POdtaXZXKJ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n","\n","# transform and map diabetes generations\n","gen_le = LabelEncoder()\n","gen_labels = gen_le.fit_transform(diabetes_df['Generation'])\n","diabetes_df['Gen_Label'] = gen_labels\n","\n","# transform and map diabetes bmi status\n","bmi_le = # Your code goes here\n","bmi_labels = # Your code goes here\n","diabetes_df['BMI_Label'] = # Your code goes here\n","\n","diabetes_df_sub = diabetes_df[['diabetes', 'Generation', 'Gen_Label', 'BMI', 'BMI_Label']]\n","diabetes_df_sub.iloc[4:10]"],"metadata":{"id":"BrIUUocFXSk3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# encode generation labels using one-hot encoding scheme\n","gen_ohe = OneHotEncoder()\n","gen_feature_arr = gen_ohe.fit_transform(diabetes_df[['Gen_Label']]).toarray()\n","gen_feature_labels = list(gen_le.classes_)\n","gen_features = pd.DataFrame(gen_feature_arr, columns=gen_feature_labels)\n","\n","# encode bmi labels using one-hot encoding scheme\n","bmi_ohe = # Your code goes here\n","bmi_feature_arr = # Your code goes here\n","bmi_feature_labels = ['BMI_'+str(cls_label) for cls_label in bmi_le.classes_]\n","bmi_features = pd.DataFrame(bmi_feature_arr, columns=bmi_feature_labels)"],"metadata":{"id":"JO2ifBzYXZOD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let’s now concatenate these feature frames and see the final result.\n","diabetes_df_ohe = pd.concat([diabetes_df_sub, gen_features, bmi_features], axis=1)\n","columns = sum([['diabetes', 'Generation', 'Gen_Label'],gen_feature_labels,\n","              ['BMI', 'BMI_Label'],bmi_feature_labels], [])\n","diabetes_df_ohe[columns].iloc[4:10]"],"metadata":{"id":"thN4GA8iXiAd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can clearly see the new one hot encoded features\n","for Gen_Label and BMI_Label. Each of these one hot encoded features is binary in nature and if they\n","contain the value 1, it means that feature is active for the corresponding observation."],"metadata":{"id":"4cZwMQb4X0KA"}},{"cell_type":"code","source":["# The following code shows us two dummy data points pertaining to new Pokemon.\n","new_diabetes_df = pd.DataFrame([['1', 'Gen X', 'Pre-obese'], \n","                           ['0', 'Boomers II', 'Class I obesity']],\n","                           columns=['diabetes', 'Generation', 'BMI'])\n","new_diabetes_df"],"metadata":{"id":"Z7giTVDnX7dR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# converting the text categories into numeric representations using our previously built LabelEncoder objects\n","new_gen_labels = gen_le.transform(new_diabetes_df['Generation'])\n","new_diabetes_df['Gen_Label'] = new_gen_labels\n","\n","new_bmi_labels = # Your code goes here\n","new_diabetes_df['BMI_Label'] = # Your code goes here\n","\n","new_diabetes_df[['diabetes', 'Generation', 'Gen_Label', 'BMI', 'BMI_Label']]"],"metadata":{"id":"LPoELMloYKnV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# use our previously built LabelEncoder objects and perform one hot encoding on these new data observations\n","new_gen_feature_arr = gen_ohe.transform(new_diabetes_df[['Gen_Label']]).toarray()\n","new_gen_features = pd.DataFrame(new_gen_feature_arr, columns=gen_feature_labels)\n","\n","new_bmi_feature_arr = # Your code goes here\n","new_bmi_features = # Your code goes here\n","\n","new_diabetes_ohe = pd.concat([new_diabetes_df, new_gen_features, new_bmi_features], axis=1)\n","columns = sum([['diabetes', 'Generation', 'Gen_Label'], gen_feature_labels,\n","               ['BMI', 'BMI_Label'], bmi_feature_labels], [])\n","new_diabetes_ohe[columns]"],"metadata":{"id":"AEqKn-aLYVTM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Pandas provides to_dummies() function that can help us easily perform one hot encoding\n","gen_onehot_features = # Your code goes here\n","pd.concat([diabetes_df[['diabetes', 'Generation']], gen_onehot_features], axis=1).iloc[4:10]"],"metadata":{"id":"d-fRkcFeYne8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Dummy Coding Scheme\n","The dummy coding scheme is similar to the one hot encoding scheme, except in the case of dummy coding\n","scheme, when applied on a categorical feature with m distinct labels, we get m-1 binary features. Thus each\n","value of the categorical variable gets converted into a vector of size m-1. The extra feature is completely\n","disregarded and thus if the category values range from {0, 1, ..., m-1} the 0th or the m-1th feature is usually\n","represented by a vector of all zeros (0)."],"metadata":{"id":"n7efnGoLY7Gp"}},{"cell_type":"code","source":["# Create dummy coding scheme on diabetes Generation by dropping the first level binary encoded feature (Boomers I).\n","gen_dummy_features = # Your code goes here\n","pd.concat([diabetes_df[['diabetes', 'Generation']], gen_dummy_features], axis=1).iloc[4:10]"],"metadata":{"id":"PTPdc0RCZGYC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# choose to drop the last level binary encoded feature (Post WWII)\n","gen_onehot_features = # Your code goes here\n","gen_dummy_features = gen_onehot_features.iloc[:,:-1]\n","pd.concat([diabetes_df[['diabetes', 'Generation']], gen_dummy_features], axis=1).iloc[4:10]"],"metadata":{"id":"w4ZBALP6ZVLG"},"execution_count":null,"outputs":[]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python [conda root]","language":"python","name":"conda-root-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"Day_3_Exercise_Feature_Engineering.ipynb","provenance":[{"file_id":"https://github.com/dipanjanS/practical-machine-learning-with-python/blob/master/notebooks/Ch04_Feature_Engineering_and_Selection/Feature%20Scaling.ipynb","timestamp":1647108977736}],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}