{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Responsible AI for Heart Disease Prediction\n",
    "\n",
    "## Overview\n",
    "This tutorial demonstrates how to implement Responsible AI principles in a machine learning workflow for heart disease prediction. Using the UCI Heart Disease dataset, we cover:\n",
    "- Data loading and preprocessing\n",
    "- Bias detection and fairness analysis\n",
    "- Privacy protection with differential privacy\n",
    "- Model training with fairness considerations\n",
    "- Model explainability through feature importance\n",
    "\n",
    "The tutorial provides a comprehensive example of building an AI system that considers ethical implications alongside predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "By completing this tutorial, you will learn to:\n",
    "- Load and preprocess medical data for machine learning\n",
    "- Detect potential biases in datasets using statistical tests and visualizations\n",
    "- Implement differential privacy techniques to protect sensitive data\n",
    "- Train machine learning models while monitoring fairness across demographic groups\n",
    "- Interpret model decisions through feature importance analysis\n",
    "- Generate visual reports to communicate model behavior and potential biases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "To follow this tutorial, you should have:\n",
    "- Basic knowledge of Python programming\n",
    "- Familiarity with pandas and numpy for data manipulation\n",
    "- Understanding of machine learning concepts (classification, train-test split)\n",
    "- Basic statistics knowledge (t-tests, distributions)\n",
    "- These Python packages installed: pandas,  numpy, scikit-learn, matplotlib, seaborn, scipy\n",
    "\n",
    "## Get Started\n",
    "Let’s begin by loading the dataset and performing the following workflow. \n",
    "- Load and preprocess the heart disease dataset\n",
    "- Generate visualizations of age and sex distributions\n",
    "- Print statistical tests for bias detection\n",
    "- Train a Random Forest classifier with privacy protection\n",
    "- Evaluate model fairness across demographic groups\n",
    "- Create feature importance plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UCI Heart Disease Dataset\n",
    "\n",
    "**Source**: [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/45/heart+disease)  \n",
    "**Primary Use**: Classification tasks in health and medicine  \n",
    "\n",
    "## Overview\n",
    "\n",
    "- **Datasets Included**: Four datasets from Cleveland, Hungary, Switzerland, and the VA Long Beach\n",
    "- **Instances**: 303\n",
    "- **Total Attributes**: 76, with 14 commonly used in research\n",
    "- **Missing Values**: Yes\n",
    "- **Target Variable**: `num` (0: no presence of heart disease; 1–4: increasing levels of presence)\n",
    "\n",
    "## Commonly Used Features (14)\n",
    "\n",
    "| Feature      | Description                                                                 |\n",
    "|--------------|-----------------------------------------------------------------------------|\n",
    "| `age`        | Age in years                                                                |\n",
    "| `sex`        | Sex (1 = male; 0 = female)                                                  |\n",
    "| `cp`         | Chest pain type (1 = typical angina; 2 = atypical angina; 3 = non-anginal pain; 4 = asymptomatic) |\n",
    "| `trestbps`   | Resting blood pressure (in mm Hg)                                           |\n",
    "| `chol`       | Serum cholesterol (in mg/dl)                                                |\n",
    "| `fbs`        | Fasting blood sugar > 120 mg/dl (1 = true; 0 = false)                       |\n",
    "| `restecg`    | Resting electrocardiographic results (0 = normal; 1 = ST-T wave abnormality; 2 = left ventricular hypertrophy) |\n",
    "| `thalach`    | Maximum heart rate achieved                                                 |\n",
    "| `exang`      | Exercise-induced angina (1 = yes; 0 = no)                                   |\n",
    "| `oldpeak`    | ST depression induced by exercise relative to rest                          |\n",
    "| `slope`      | Slope of the peak exercise ST segment (1 = upsloping; 2 = flat; 3 = downsloping) |\n",
    "| `ca`         | Number of major vessels (0–3) colored by fluoroscopy                        |\n",
    "| `thal`       | Thalassemia (3 = normal; 6 = fixed defect; 7 = reversible defect)           |\n",
    "| `num`        | Diagnosis of heart disease (0 = absence; 1–4 = presence)                    |\n",
    "\n",
    "## Notes\n",
    "\n",
    "- While the dataset contains 76 attributes, most studies focus on the 14 listed above, particularly from the Cleveland dataset.\n",
    "- The `num` field is often converted to a binary classification: 0 (no heart disease) and 1 (presence of heart disease).\n",
    "\n",
    "For more detailed information and access to the dataset, visit the [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/45/heart+disease).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Numerical computing\n",
    "import numpy as np   \n",
    "\n",
    "# Splitting data into train/test sets\n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "# Random Forest classification algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "\n",
    "# Model evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report  \n",
    "\n",
    "# Feature scaling/normalization\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "# Enhanced data visualization (built on matplotlib)\n",
    "import seaborn as sns  \n",
    "\n",
    "# Statistical hypothesis testing (t-tests)\n",
    "from scipy.stats import ttest_ind  \n",
    "\n",
    "# Suppress FutureWarnings to keep output clean\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Enable Jupyter Notebook to display matplotlib plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_heart_disease_data():\n",
    "    \"\"\"\n",
    "    Loads and preprocesses the Cleveland Heart Disease dataset from UCI Machine Learning Repository.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned dataframe with:\n",
    "            - Missing values removed\n",
    "            - Binary target variable (0=no disease, 1=disease)\n",
    "            - Proper column names\n",
    "    \"\"\"\n",
    "    \n",
    "    # Dataset URL from UCI Machine Learning Repository\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "    \n",
    "    # Column names for the dataset (original data doesn't include headers)\n",
    "    columns = [\n",
    "        'age',        # Age in years\n",
    "        'sex',        # Sex (1 = male; 0 = female)\n",
    "        'cp',         # Chest pain type (1-4)\n",
    "        'trestbps',   # Resting blood pressure (mm Hg)\n",
    "        'chol',       # Serum cholesterol (mg/dl)\n",
    "        'fbs',        # Fasting blood sugar > 120 mg/dl (1 = true; 0 = false)\n",
    "        'restecg',    # Resting electrocardiographic results (0-2)\n",
    "        'thalach',    # Maximum heart rate achieved\n",
    "        'exang',      # Exercise induced angina (1 = yes; 0 = no)\n",
    "        'oldpeak',    # ST depression induced by exercise relative to rest\n",
    "        'slope',      # Slope of the peak exercise ST segment\n",
    "        'ca',         # Number of major vessels (0-3) colored by fluoroscopy\n",
    "        'thal',       # Thalassemia (3 = normal; 6 = fixed defect; 7 = reversible defect)\n",
    "        'target'      # Diagnosis of heart disease (0-4)\n",
    "    ]\n",
    "    \n",
    "    # Load raw data with:\n",
    "    # - Specified column names\n",
    "    # - '?' treated as missing values\n",
    "    df = pd.read_csv(url, names=columns, na_values='?')\n",
    "    \n",
    "    # Data Cleaning:\n",
    "    # Remove rows with any missing values (original dataset uses '?' for missing)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Convert target to binary classification:\n",
    "    # Original values: 0 = no disease, 1-4 = varying degrees of disease\n",
    "    # New values: 0 = no disease, 1 = any presence of disease\n",
    "    df['target'] = df['target'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute data loading function to get the processed heart disease dataset\n",
    "# This calls our previously defined load_heart_disease_data() function which:\n",
    "# 1. Downloads the Cleveland dataset from UCI\n",
    "# 2. Cleans missing values\n",
    "# 3. Converts target to binary classification\n",
    "df = load_heart_disease_data()\n",
    "\n",
    "# Print dataset metadata for verification\n",
    "# Shape shows (number_of_rows, number_of_columns)\n",
    "print(\"Dataset loaded. Shape:\", df.shape)\n",
    "# This helps confirm we successfully loaded the expected amount of data\n",
    "\n",
    "# Display first 5 rows of the DataFrame\n",
    "# This serves multiple purposes:\n",
    "# 1. Visual verification that data loaded correctly\n",
    "# 2. Quick check of feature values and distributions\n",
    "# 3. Verification of the binary target conversion\n",
    "# 4. Inspection of column headers and data types\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fairness Check: Analyze potential biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_bias(df):\n",
    "    \"\"\"\n",
    "    Analyzes potential biases in the heart disease dataset by:\n",
    "    - Visualizing distributions of age and sex across disease status\n",
    "    - Conducting statistical tests for significant differences\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Processed heart disease dataframe with binary 'target' column\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if significant bias detected (p-value < 0.05 for either age or sex), False otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    # =============================================\n",
    "    # Age Distribution Analysis\n",
    "    # =============================================\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    # Stacked histogram showing age distribution split by disease status\n",
    "    # Helps visualize if certain age groups are overrepresented in disease cases\n",
    "    sns.histplot(\n",
    "        data=df,\n",
    "        x='age',          # Analyze age distribution\n",
    "        hue='target',     # Color by disease status (0=healthy, 1=disease)\n",
    "        multiple='stack'  # Stack bars for better comparison\n",
    "    )\n",
    "    plt.title('Age Distribution by Heart Disease Status')\n",
    "    plt.show()\n",
    "    \n",
    "    # =============================================\n",
    "    # Sex Distribution Analysis  \n",
    "    # =============================================\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    # Countplot showing sex representation in disease vs healthy groups\n",
    "    # Helps identify gender disparities in the dataset\n",
    "    sns.countplot(\n",
    "        data=df,\n",
    "        x='sex',      # Analyze sex distribution (0=female, 1=male)\n",
    "        hue='target'   # Split by disease status\n",
    "    )\n",
    "    plt.title('Sex Distribution by Heart Disease Status')\n",
    "    plt.show()\n",
    "    \n",
    "    # =============================================\n",
    "    # Statistical Tests for Bias\n",
    "    # =============================================\n",
    "    \n",
    "    # Age Bias Test - Independent t-test\n",
    "    # Compares mean age between disease and healthy groups\n",
    "    age_disease = df[df['target'] == 1]['age']      # Ages of patients with disease\n",
    "    age_no_disease = df[df['target'] == 0]['age']   # Ages of healthy patients\n",
    "    t_stat, p_val_age = ttest_ind(age_disease, age_no_disease)\n",
    "    print(f\"Age bias t-test p-value: {p_val_age:.4f}\")  # Significant if p < 0.05\n",
    "    \n",
    "    # Sex Bias Test - Independent t-test\n",
    "    # Compares sex proportion between disease and healthy groups\n",
    "    # Note: T-test on binary sex variable (0/1) effectively tests proportion differences\n",
    "    sex_disease = df[df['target'] == 1]['sex']      # Sex of patients with disease  \n",
    "    sex_no_disease = df[df['target'] == 0]['sex']   # Sex of healthy patients\n",
    "    t_stat, p_val_sex = ttest_ind(sex_disease, sex_no_disease)\n",
    "    print(f\"Sex bias t-test p-value: {p_val_sex:.4f}\")  # Significant if p < 0.05\n",
    "    \n",
    "    # Return True if either age or sex shows statistically significant bias\n",
    "    return p_val_age < 0.05 or p_val_sex < 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the data bias checking function on our heart disease DataFrame\n",
    "# This will:\n",
    "# 1. Generate visualizations of age and sex distributions by disease status\n",
    "# 2. Perform statistical tests for significant differences\n",
    "# 3. Return True if significant bias is found (p-value < 0.05 for either age or sex)\n",
    "has_bias = check_data_bias(df)\n",
    "\n",
    "# Evaluate and report the results of the bias check\n",
    "if has_bias:\n",
    "    # If bias was detected (function returned True)\n",
    "    print(\"Warning: Potential bias detected in age or sex distribution\")\n",
    "else:\n",
    "    # If no significant bias was found (function returned False)\n",
    "    print(\"No significant bias detected in age or sex distribution\")\n",
    "    # Note: This doesn't guarantee absence of all biases, just those we tested for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's understand potential biases in the UCI Heart Disease dataset regarding age and sex distributions.\n",
    "\n",
    "#### Age Distribution by Heart Disease Status (First Plot)\n",
    "The histogram shows the distribution of ages for patients with and without heart disease:\n",
    "- **Blue (target = 0)**: Patients without heart disease.\n",
    "- **Orange (target = 1**): Patients with heart disease.\n",
    "- **Observation**:\n",
    "    - The age distribution for those without heart disease (blue) has a wider spread, with a noticeable presence in younger age groups (around 30–50 years).\n",
    "    - The distribution for those with heart disease (orange) is more concentrated in older age groups, particularly between 50–70 years.\n",
    "    - There is a clear shift: older individuals are more likely to have heart disease, while younger individuals are more likely to be free of it.\n",
    "- **Implication**:\n",
    "    - This suggests a potential age-related bias in the dataset. Heart disease appears more prevalent in older age groups, which aligns with medical knowledge but could bias a model to overpredict heart disease in older patients and underpredict in younger ones if not handled carefully.\n",
    " \n",
    "#### Sex Distribution by Heart Disease Status (Second Plot)\n",
    "The count plot shows the distribution of sexes (0 = Female, 1 = Male) for patients with and without heart disease:\n",
    "- **Blue (target = 0)**: Patients without heart disease.\n",
    "- **Orange (target = 1)**: Patients with heart disease.\n",
    "- **Observation**:\n",
    "    - For females (sex = 0), there are more individuals without heart disease (blue) than with heart disease (orange).\n",
    "    - For males (sex = 1), the number of individuals with heart disease (orange) is significantly higher than those without (blue).\n",
    "    - The dataset has more males than females overall, and males are disproportionately more likely to have heart disease.\n",
    "- **Implication**:\n",
    "    - This indicates a potential sex-related bias. A model trained on this data might overpredict heart disease in males and underpredict in females, reflecting the skewed representation in the dataset rather than true population trends.\n",
    " \n",
    "#### Statistical Tests (T-Tests)\n",
    "The t-tests assess whether the differences in age and sex distributions between the two groups (with and without heart disease) are statistically significant:\n",
    "- **Age Bias T-Test**:\n",
    "    - **P-value**: 0.0001\n",
    "    - **Interpretation**: A p-value of 0.0001 is well below the common significance threshold of 0.05, indicating a statistically significant difference in age between those with and without heart disease. This confirms the visual observation from the histogram: age is a significant factor in heart disease prevalence in this dataset.\n",
    "- **Sex Bias T-Test**:\n",
    "    - **P-value**: 0.0000\n",
    "    - **Interpretation**: A p-value of 0.0000 (essentially 0) is also far below 0.05, indicating a highly significant difference in sex distribution between the two groups. This aligns with the count plot, confirming that sex distribution differs significantly between those with and without heart disease.\n",
    "- **Warning**: The code outputs \"Warning: Potential bias detected in age or sex distribution\" because both p-values are below 0.05, indicating significant differences in both age and sex distributions.\n",
    "\n",
    "#### Overall Interpretation of Bias\n",
    "- **Age Bias**: The dataset shows that older individuals are more likely to have heart disease, which is medically plausible since age is a known risk factor for heart disease. However, this strong correlation could lead a model to over-rely on age as a predictor, potentially ignoring other factors or misclassifying younger patients who might still be at risk due to other variables.\n",
    "- **Sex Bias**: The dataset has a higher proportion of males, and males are more likely to have heart disease in this sample. This imbalance could bias a model to predict heart disease more frequently in males, even in cases where females might have similar risk profiles. This reflects a sampling bias in the dataset, as the proportion of males and females might not match the general population.\n",
    "- **Impact on Model Fairness**: These biases suggest that a model trained on this dataset might unfairly discriminate based on age and sex. For example, it might underpredict heart disease in younger patients or females, leading to potential disparities in diagnosis or treatment recommendations.\n",
    "\n",
    "#### Recommendations to Mitigate Bias\n",
    "- **Stratified Sampling**: Ensure that training and testing sets are balanced with respect to age and sex to prevent the model from learning these biases.\n",
    "- **Feature Engineering**: Consider techniques like age normalization or creating age-sex interaction terms to reduce the model’s over-reliance on these features.\n",
    "- **Fairness Constraints**: Apply fairness constraints during model training to ensure equal performance across age groups and sexes (e.g., equalized odds or demographic parity).\n",
    "- **Bias Auditing**: Continuously audit the model’s predictions on different demographic groups to identify and address disparities.\n",
    "\n",
    "The bias check reveals significant differences in age and sex distributions between patients with and without heart disease, highlighting potential fairness concerns that need to be addressed to ensure the model generalizes well across all groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Privacy Protection: Differential Privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_differential_privacy(data, epsilon=1.0, seed=None):\n",
    "    \"\"\"\n",
    "    Adds differential privacy protection to data by injecting Laplace noise.\n",
    "    \n",
    "    Differential privacy ensures that the inclusion/exclusion of any single \n",
    "    individual in the dataset cannot be determined from the output.\n",
    "    \n",
    "    Args:\n",
    "        data (np.ndarray or pd.DataFrame): Input data to privatize\n",
    "        epsilon (float): Privacy budget parameter (default: 1.0)\n",
    "            - Smaller values = stronger privacy protection\n",
    "            - Larger values = weaker privacy protection\n",
    "        seed (int, optional): Random seed for reproducible results\n",
    "    \n",
    "    Returns:\n",
    "        Privatized data with same shape as input\n",
    "        \n",
    "    Example:\n",
    "        >>> private_data = add_differential_privacy(sensitive_data, epsilon=0.5)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set seed for reproducibility if provided\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)  # Ensures same noise values if same seed is used\n",
    "    \n",
    "    # Generate Laplace noise for differential privacy\n",
    "    # Laplace distribution is used because it satisfies (ε,0)-differential privacy\n",
    "    # Scale parameter (1/epsilon) controls noise magnitude:\n",
    "    # - As epsilon → 0, noise → ∞ (complete privacy)\n",
    "    # - As epsilon → ∞, noise → 0 (no privacy)\n",
    "    noise = np.random.laplace(\n",
    "        loc=0,           # Mean of the Laplace distribution\n",
    "        scale=1/epsilon, # Scale parameter (Δf/ε)\n",
    "        size=data.shape  # Noise array matching input dimensions\n",
    "    )\n",
    "    \n",
    "    # Apply noise to original data\n",
    "    privatized_data = data + noise\n",
    "    \n",
    "    return privatized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Training without Responsible AI Principles\n",
    "\n",
    "#### RandomForestClassifier in scikit-learn\n",
    "\n",
    "A **RandomForestClassifier** is an ensemble machine learning method that:\n",
    "- Builds multiple decision trees during training  \n",
    "- Outputs the mode (classification) or mean prediction (regression) of individual trees  \n",
    "- Introduces randomness through:  \n",
    "  - Bootstrap sampling (training on random subsets of data)  \n",
    "  - Random feature selection at each split  \n",
    "- Reduces overfitting compared to single decision trees  \n",
    "\n",
    "##### Key Features:\n",
    "- Supports both classification and regression tasks  \n",
    "- Handles high-dimensional data well  \n",
    "- Provides feature importance scores  \n",
    "- Built-in cross-validation via out-of-bag samples  \n",
    "\n",
    "##### Common Hyperparameters:\n",
    "- **`n_estimators`**: Number of trees in the forest (default=100)  \n",
    "- **`max_depth`**: Maximum depth of each tree (default=None, grows until leaves are pure)  \n",
    "- **`criterion`**: Splitting metric (`\"gini\"` or `\"entropy\"` for classification)  \n",
    "- **`max_features`**: Features considered for splits (`\"auto\"`, `\"sqrt\"`, or int/float)  \n",
    "- **`min_samples_split`**: Minimum samples required to split a node (default=2)  \n",
    "- **`min_samples_leaf`**: Minimum samples required at each leaf (default=1)  \n",
    "- **`bootstrap`**: Whether to use bootstrap sampling (default=True)  \n",
    "- **`random_state`**: Seed for reproducibility (optional)  \n",
    "\n",
    "📖 **Official Documentation**:  \n",
    "[scikit-learn RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)  \n",
    "\n",
    "💡 **Tip**: Start with `n_estimators=100` and tune `max_depth` to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_standard_model(df):\n",
    "    \"\"\"\n",
    "    Trains a standard Random Forest classifier on heart disease data without privacy protection.\n",
    "    \n",
    "    Performs complete machine learning pipeline:\n",
    "    - Feature/target separation\n",
    "    - Train-test split\n",
    "    - Feature scaling\n",
    "    - Model training\n",
    "    - Performance evaluation\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Processed heart disease dataframe containing both features and target\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (trained_model, scaler_object, feature_names) for use in production\n",
    "    \"\"\"\n",
    "    \n",
    "    # =============================================\n",
    "    # Feature Engineering\n",
    "    # =============================================\n",
    "    # Select all columns except 'target' as features\n",
    "    features = [col for col in df.columns if col != 'target']\n",
    "    \n",
    "    # Separate features (X) and target variable (y)\n",
    "    X = df[features]  # Feature matrix\n",
    "    y = df['target']  # Target vector (0=no disease, 1=disease)\n",
    "\n",
    "    # =============================================\n",
    "    # Data Splitting\n",
    "    # =============================================\n",
    "    # Split into training (80%) and test sets (20%)\n",
    "    # random_state ensures reproducible splits\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.2, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # =============================================\n",
    "    # Feature Scaling\n",
    "    # =============================================\n",
    "    # Initialize StandardScaler to normalize features (mean=0, std=1)\n",
    "    # Important for distance-based algorithms (though RF is somewhat scale-invariant)\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fit scaler on training data and transform both sets\n",
    "    X_train_scaled = scaler.fit_transform(X_train)  # Fit and transform train\n",
    "    X_test_scaled = scaler.transform(X_test)        # Transform test (no fit)\n",
    "\n",
    "    # =============================================\n",
    "    # Model Training\n",
    "    # =============================================\n",
    "    # Initialize Random Forest classifier:\n",
    "    # - 100 decision trees (good default)\n",
    "    # - Fixed random state for reproducibility\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train model on scaled training data\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # =============================================\n",
    "    # Model Evaluation\n",
    "    # =============================================\n",
    "    # Generate predictions on test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Print comprehensive classification metrics\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Return key artifacts needed for production use:\n",
    "    # - Trained model\n",
    "    # - Fitted scaler (for new data preprocessing)\n",
    "    # - Feature names (for interpretability)\n",
    "    return model, scaler, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute model training without responsible AI principles\n",
    "model, scaler, features = train_standard_model(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Training with Responsible AI Principles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_responsible_model(df, ensure_fairness=True, dp_seed=42):\n",
    "    \"\"\"\n",
    "    Trains a heart disease prediction model with responsible AI considerations including:\n",
    "    - Differential privacy for training data protection\n",
    "    - Fairness evaluation across demographic groups\n",
    "    - Standard ML pipeline with evaluation metrics\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Processed heart disease data with features and target\n",
    "        ensure_fairness (bool): Whether to perform fairness evaluation (default: True)\n",
    "        dp_seed (int): Random seed for differential privacy noise (default: 42)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (trained_model, scaler_object, feature_names)\n",
    "    \"\"\"\n",
    "    \n",
    "    # =============================================\n",
    "    # Data Preparation\n",
    "    # =============================================\n",
    "    # Select all columns except target as features\n",
    "    features = [col for col in df.columns if col != 'target']\n",
    "    X = df[features]  # Feature matrix\n",
    "    y = df['target']  # Target vector (0=healthy, 1=disease)\n",
    "    \n",
    "    # Split into train (80%) and test (20%) sets with fixed random state\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.2, \n",
    "        random_state=42  # Ensures reproducible splits\n",
    "    )\n",
    "    \n",
    "    # =============================================\n",
    "    # Privacy Protection\n",
    "    # =============================================\n",
    "    # Apply differential privacy to training data\n",
    "    # - Uses Laplace noise with epsilon=1.0 (moderate privacy)\n",
    "    # - Seed ensures reproducible noise addition\n",
    "    X_train_private = add_differential_privacy(\n",
    "        X_train.values, \n",
    "        epsilon=1.0, \n",
    "        seed=dp_seed\n",
    "    )\n",
    "    # Convert back to DataFrame with original column names\n",
    "    X_train_private = pd.DataFrame(X_train_private, columns=features)\n",
    "    \n",
    "    # =============================================\n",
    "    # Feature Scaling\n",
    "    # =============================================\n",
    "    # Standardize features (mean=0, std=1) for better model performance\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_private)  # Fit on private data\n",
    "    X_test_scaled = scaler.transform(X_test)  # Apply same scaling to test\n",
    "    \n",
    "    # =============================================\n",
    "    # Model Training\n",
    "    # =============================================\n",
    "    # Initialize Random Forest with 100 trees\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100, \n",
    "        random_state=42  # Ensures reproducible training\n",
    "    )\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # =============================================\n",
    "    # Model Evaluation\n",
    "    # =============================================\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # =============================================\n",
    "    # Fairness Evaluation (Optional)\n",
    "    # =============================================\n",
    "    if ensure_fairness:\n",
    "        # Create age groups for fairness analysis\n",
    "        X_test['age_group'] = pd.cut(\n",
    "            X_test['age'], \n",
    "            bins=[0, 40, 60, 100], \n",
    "            labels=['Young', 'Middle', 'Senior']\n",
    "        )\n",
    "        X_test['prediction'] = y_pred  # Store predictions\n",
    "        \n",
    "        # --- Age Group Analysis ---\n",
    "        fairness_age = X_test.groupby('age_group')['prediction'].mean()\n",
    "        counts_age = X_test.groupby('age_group')['prediction'].sum()  # Positive predictions\n",
    "        total_age = X_test.groupby('age_group')['prediction'].count()  # Group sizes\n",
    "        \n",
    "        print(\"\\nPrediction rates by age group:\")\n",
    "        for age_group in fairness_age.index:\n",
    "            print(f\"{age_group}: {fairness_age[age_group]*100:.2f}% \"\n",
    "                  f\"({int(counts_age[age_group])}/{total_age[age_group]})\")\n",
    "        \n",
    "        # Visualize age fairness\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        fairness_age.plot(kind='bar')\n",
    "        plt.title('Prediction Rates by Age Group')\n",
    "        plt.ylabel('Prediction Rate')\n",
    "        plt.show()\n",
    "        \n",
    "        # --- Sex Analysis ---\n",
    "        fairness_sex = X_test.groupby('sex')['prediction'].mean()\n",
    "        counts_sex = X_test.groupby('sex')['prediction'].sum()  # Positive predictions\n",
    "        total_sex = X_test.groupby('sex')['prediction'].count()  # Group sizes\n",
    "        \n",
    "        print(\"\\nPrediction rates by sex (0=Female, 1=Male):\")\n",
    "        for sex in fairness_sex.index:\n",
    "            print(f\"{sex}: {fairness_sex[sex]*100:.2f}% \"\n",
    "                  f\"({int(counts_sex[sex])}/{total_sex[sex]})\")\n",
    "        \n",
    "        # Visualize sex fairness\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        fairness_sex.plot(kind='bar')\n",
    "        plt.title('Prediction Rates by Sex')\n",
    "        plt.ylabel('Prediction Rate')\n",
    "        plt.show()\n",
    "    \n",
    "    return model, scaler, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute model training with responsible AI principles\n",
    "model, scaler, features = train_responsible_model(df, ensure_fairness=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s compare the standard model and the model trained with responsible AI principles based on their performance metrics and fairness considerations. The responsible AI model includes differential privacy (which adds noise to the training data) and fairness evaluation (prediction rates by age and sex), while the standard model does not.\n",
    "\n",
    "#### Model Accuracy Comparison\n",
    "- **Standard Model Accuracy**: 0.8833 (88.33%)\n",
    "- **Responsible Model Accuracy**: 0.8667 (86.67%)\n",
    "- **Difference**: The standard model is slightly more accurate by 0.0166.\n",
    "- **Interpretation**: The standard model performs better in terms of overall accuracy. This is expected because the responsible model adds noise to the training data via differential privacy, which can obscure patterns and make learning more difficult. The standard model, using unperturbed data, can better capture the underlying relationships in the dataset.\n",
    "- \n",
    "#### Classification Report Comparison\n",
    "The classification report provides detailed metrics for each class (0 = no heart disease, 1 = heart disease).\n",
    "\n",
    "**Class 0 (No Heart Disease)**\n",
    "- **Standard Model**: Precision: 0.91, Recall: 0.89, F1-Score: 0.90\n",
    "- **Responsible Model**: Precision: 0.85, Recall: 0.94, F1-Score: 0.89\n",
    "- **Comparison**:\n",
    "    - *Precision*: The standard model has higher precision (0.91 vs. 0.85), meaning it is more accurate when predicting no heart disease.\n",
    "    - *Recall*: The responsible model has higher recall (0.94 vs. 0.89), meaning it identifies a higher proportion of true no heart disease cases, reducing false positives.\n",
    "    - *F1-Score*: The F1-score is slightly higher for the standard model (0.90 vs. 0.89), indicating a better balance of precision and recall, though the difference is small.\n",
    "      \n",
    "**Class 1 (Heart Disease)**\n",
    "- **Standard Model**: Precision: 0.84, Recall: 0.88, F1-Score: 0.86\n",
    "- **Responsible Model**: Precision: 0.90, Recall: 0.75, F1-Score: 0.82\n",
    "- **Comparison**:\n",
    "    - *Precision*: The responsible model has higher precision (0.90 vs. 0.84), meaning it is more accurate when predicting heart disease.\n",
    "    - *Recall*: The standard model has significantly higher recall (0.88 vs. 0.75), meaning it identifies more true heart disease cases. In a medical context, higher recall for class 1 is critical to avoid missing cases (false negatives).\n",
    "    - *F1-Score*: The standard model has a higher F1-score (0.86 vs. 0.82), reflecting a better balance of precision and recall for heart disease prediction.\n",
    "\n",
    "**Overall Metrics**\n",
    "- **Macro Average (unweighted average across classes)**:\n",
    "    - *Standard Model*: Precision 0.88, Recall 0.88, F1-Score 0.88\n",
    "    - *Responsible Model*: Precision 0.88, Recall 0.85, F1-Score 0.86\n",
    "    - *Comparison*: The standard model has a slightly better macro recall (0.88 vs. 0.85) and F1-score (0.88 vs. 0.86), while precision is the same. This indicates the standard model performs more consistently across both classes.\n",
    "- **Weighted Average (weighted by support)**:\n",
    "    - *Standard Model*: Precision 0.88, Recall 0.88, F1-Score 0.88\n",
    "    - *Responsible Model*: Precision 0.87, Recall 0.87, F1-Score 0.86\n",
    "    - *Comparison*: The standard model shows slight improvements across all weighted metrics, reflecting its better overall performance.\n",
    "\n",
    "#### Fairness Evaluation (Responsible Model)\n",
    "The responsible model includes fairness evaluation, showing prediction rates for heart disease across age groups and sexes:\n",
    "\n",
    "- **Prediction Rates by Age Group**:\n",
    "    - *Young (0–40 years)*: 0.00% (0/7)\n",
    "    - *Middle (40–60 years)*: 33.33% (13/39)\n",
    "    - *Senior (60–100 years)*: 50.00% (7/14)\n",
    "\n",
    "- **Prediction Rates by Sex**:\n",
    "    - *Female (0)*: 20.00% (5/25)\n",
    "    - *Male (1)*: 42.86% (15/35)\n",
    "    - *Interpretation*:\n",
    "        - The model predicts heart disease more frequently in older age groups, with no predictions for the young group, 33.33% for the middle group, and 50% for the senior group. This aligns with the dataset’s bias (older patients are more likely to have heart disease) but suggests potential underprediction in younger patients.\n",
    "        - The model predicts heart disease more often in males (42.86%) than females (20.00%), reflecting the dataset’s sex bias (more males have heart disease). This disparity could lead to underdiagnosis in females.\n",
    "    \n",
    "#### Fairness in the Standard Model (Theoretical Analysis)\n",
    "Since the standard model doesn’t include fairness evaluation, we can infer potential outcomes based on the responsible model’s results and the fact that the standard model uses unperturbed data:\n",
    "- **Age Bias**: The standard model, learning from cleaner data, might amplify the dataset’s age bias even more. It could predict heart disease even more frequently in older patients and less frequently in younger ones, potentially worsening the 0% prediction rate for the young group.\n",
    "- **Sex Bias**: Similarly, the standard model might predict heart disease more often in males than the responsible model’s 42.86%, further widening the gap with females (20.00%). This is because the standard model can more effectively learn the dataset’s sex imbalance without noise interference.\n",
    "- **Overall Fairness**: The standard model is likely less fair, as it doesn’t account for or mitigate biases in the data, potentially leading to greater disparities in predictions across demographic groups.\n",
    "\n",
    "\n",
    "#### Trade-Offs: Performance vs. Responsible AI Principles\n",
    "- **Standard Model (Better Performance)**\n",
    "    - **Advantages**:\n",
    "        - Higher accuracy (88.33% vs. 86.67%).\n",
    "        - Better recall for heart disease (0.88 vs. 0.75), reducing false negatives, which is critical in a medical context.\n",
    "        - Higher F1-scores for both classes, indicating a better balance of precision and recall.\n",
    "    - **Disadvantages**:\n",
    "        - No privacy protection (no differential privacy), posing risks in a medical context where patient data privacy is crucial.\n",
    "        - No fairness evaluation, so biases in the data (e.g., overpredicting for males and older patients) are likely amplified, potentially leading to unfair predictions.\n",
    "        - May overfit to biases in the dataset, reducing generalizability to a broader population.\n",
    "- **Responsible Model (Better Fairness and Privacy)**\n",
    "    - **Advantages**:\n",
    "        - Differential privacy adds noise to protect patient data, reducing the risk of re-identification.\n",
    "        - Fairness evaluation highlights biases (e.g., low prediction rates for young patients and females), allowing for potential mitigation strategies.\n",
    "        - More ethically aligned for real-world medical applications where privacy and fairness are critical.\n",
    "    - **Disadvantages**:\n",
    "        - Lower accuracy (86.67% vs. 88.33%) due to noise from differential privacy.\n",
    "        - Lower recall for heart disease (0.75 vs. 0.88), meaning more false negatives (missed heart disease cases), which is a significant concern in a medical context.\n",
    "        - Still exhibits fairness issues (e.g., 0% prediction rate for young patients), though it at least identifies them for further action.\n",
    "\n",
    "#### Medical Context Considerations\n",
    "- **False Negatives**: In a medical setting, missing a heart disease case (false negative) is more dangerous than a false positive. The standard model’s higher recall for class 1 (0.88 vs. 0.75) makes it better at identifying heart disease cases, reducing the risk of missing patients who need treatment.\n",
    "- **Fairness**: The responsible model’s fairness evaluation reveals significant disparities (e.g., no predictions for young patients, lower predictions for females). The standard model likely worsens these disparities, which could lead to systematic underdiagnosis in certain groups (e.g., young patients, females).\n",
    "- **Privacy**: The standard model’s lack of differential privacy could violate privacy regulations (e.g., HIPAA in the U.S.) in a real-world deployment, while the responsible model offers some protection.\n",
    "  \n",
    "#### Recommendations\n",
    "- **Hybrid Approach**:\n",
    "    - Tune the epsilon parameter in add_differential_privacy to reduce noise (higher epsilon = less noise) while retaining some privacy protection. This might improve the responsible model’s performance closer to the standard model’s.\n",
    "    - Add fairness evaluation to the standard model to quantify its biases, then apply mitigation strategies (e.g., reweighting samples, fairness constraints) to reduce disparities.\n",
    "\n",
    "- **Prioritize Based on Use Case**:\n",
    "    - If raw performance is the priority and privacy/fairness are less critical (e.g., research setting with anonymized data), the standard model is preferable.\n",
    "    - If privacy and fairness are essential (e.g., real-world medical application), the responsible model is a better starting point, but its recall for heart disease needs improvement.\n",
    "\n",
    "- **Further Analysis**:\n",
    "    - Calculate fairness metrics (e.g., equalized odds, disparate impact) for both models to quantify bias more rigorously.\n",
    "    - Test both models on an external dataset to assess generalizability and fairness in a more representative population.\n",
    "\n",
    "In conclusion, the standard model outperforms the responsible model in terms of accuracy (88.33% vs. 86.67%) and recall for heart disease (0.88 vs. 0.75), making it better at identifying heart disease cases. However, it likely amplifies biases in the data and lacks privacy protections, which are critical in a medical context. The responsible model, while slightly less accurate, offers privacy protection and fairness evaluation, making it more ethically aligned but at the cost of missing more heart disease cases. A hybrid approach that balances performance, privacy, and fairness would be ideal for real-world deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Explainability: Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_model(model, features):\n",
    "    \"\"\"\n",
    "    Visualizes feature importance scores from a trained machine learning model.\n",
    "    \n",
    "    Creates a horizontal bar plot showing the relative importance of each feature\n",
    "    in the model's decision making process, sorted from high to low importance.\n",
    "    This helps with model interpretability and feature selection.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained scikit-learn model with feature_importances_ attribute\n",
    "        features (list): List of feature names corresponding to model inputs\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract feature importance scores from the trained model\n",
    "    # For RandomForest, this shows how much each feature decreases impurity on average\n",
    "    importance = model.feature_importances_\n",
    "    \n",
    "    # Sort importance and features in descending order\n",
    "    indices = np.argsort(importance)[::-1]\n",
    "    sorted_importance = importance[indices]\n",
    "    sorted_features = [features[i] for i in indices]\n",
    "    \n",
    "    # Create visualization figure with proper dimensions\n",
    "    plt.figure(figsize=(10, 6))  # Width=10\", Height=6\"\n",
    "    \n",
    "    # Create horizontal bar plot of feature importances\n",
    "    sns.barplot(\n",
    "        x=sorted_importance,  # Sorted importance scores (bar lengths)\n",
    "        y=sorted_features,    # Sorted feature names (y-axis labels)\n",
    "        palette=\"Blues_d\"     # Blue color gradient\n",
    "    )\n",
    "    \n",
    "    # Add chart title and formatting\n",
    "    plt.title('Feature Importance in Heart Disease Prediction', pad=20)\n",
    "    plt.xlabel('Relative Importance Score')\n",
    "    plt.ylabel('Features')\n",
    "    plt.tight_layout()  # Prevent label cutoff\n",
    "    \n",
    "    # Display the plot (commented out save option available)\n",
    "    plt.show()\n",
    "    # Uncomment below to save to file:\n",
    "    # plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute model explanation\n",
    "explain_model(model, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Explainability: Feature Importance in Heart Disease Prediction\n",
    "\n",
    "The bar chart shows the **feature importance** for a Random Forest model predicting heart disease, based on the `explain_model` function in the code. Feature importance reflects how much each feature contributes to the model’s predictions, with higher values indicating greater influence. \n",
    "\n",
    "#### What Feature Importance Represents\n",
    "- The chart uses the feature importance scores from the Random Forest model, derived from `model.feature_importances_`. These scores are based on how much each feature reduces impurity (e.g., Gini impurity) across all trees in the forest.\n",
    "- The x-axis shows the importance score (ranging from 0 to 0.14), and the y-axis lists the features: `thal`, `thalach`, `ca`, `age`, `oldpeak`, `cp`, `chol`,`trestbps`, `sex`, `slope`, `exang`, `fbs`, and `restecg`.\n",
    "- The length of each bar indicates the relative contribution of that feature to the model’s predictions.\n",
    "\n",
    "#### Key Observations from the Chart\n",
    "- **Top Features**:\n",
    "  - **`thal` (Thallium Stress Test Result)**: The longest bar, with an importance score around 0.14, making it the most influential feature. This suggests that the result of the thallium stress test (likely indicating blood flow to the heart) is critical for the model’s decision-making.\n",
    "  - **`thalach` (Maximum Heart Rate Achieved)**: Another high contributor, with a score around 0.13, suggesting that exercise-induced heart rate is a key predictor.\n",
    "  - **`ca` (Number of Major Vessels Colored by Fluoroscopy)**: Scores around 0.11, indicating the number of blocked vessels is also highly important.\n",
    "  - **`age`**: with a score around 0.09, indicating that patient age significantly impacts the prediction, likely reflecting its known association with heart disease risk.\n",
    "\n",
    "- **Moderate Contributors**:\n",
    "  - **`oldpeak` (ST Depression Induced by Exercise)**: Around 0.08–0.09, showing that exercise-induced changes in the ECG are relevant.\n",
    "  - **`cp` (Chest Pain Type)**: Around 0.08, suggesting different types of chest pain (e.g., typical angina) play a role.\n",
    "  - **`chol` (Serum cholesterol)**: Around 0.06, indicating Serum cholesterol level affects predictions.\n",
    "\n",
    "- **Lower Contributors**:\n",
    "  - **`trestbps` (Resting Blood Pressure)**, `sex`, `slope` (Slope of the Peak Exercise ST Segment), `exang` (Exercise-Induced Angina), `fbs` (Fasting Blood Sugar), and `restecg` (Resting ECG Results) : These have scores ranging from about 0.04 to 0.06, meaning they have less influence compared to the top features.\n",
    "\n",
    "#### Interpretation\n",
    "- **Dominance of Clinical Tests**: Features like `thal`, `thalach`, and `ca`—which are derived from advanced diagnostic tests (thallium stress test, maximum heart rate, vessel count)—are the most important. This suggests the model relies heavily on detailed cardiac test results, which are likely strong indicators of heart disease.\n",
    "- **Demographic and Symptom Influence**: `age` and `cp` (chest pain type) also rank high, reflecting the role of demographic factors (age) and patient-reported symptoms (chest pain) in the model’s decisions.\n",
    "- **Less Impactful Features**: Features like `sex`, `fbs`, and `restecg` have lower importance, possibly because their predictive power is overshadowed by more specific clinical data or because they are less variable in the dataset.\n",
    "\n",
    "#### Implications\n",
    "- **Model Reliability**: The high importance of `thal` and `thalach` suggests the model is well-tuned to clinical data, which is good for accuracy but might miss cases where these tests aren’t available or reliable.\n",
    "- **Fairness Consideration**: The moderate importance of `age` (0.09) aligns with the bias we saw earlier, where older patients had higher prediction rates (e.g., 50% for seniors). This could mean the model over-relies on age, potentially underpredicting for younger patients.\n",
    "- **Feature Engineering**: Features with low importance (e.g., `fbs`, `restecg`) might benefit from transformation or combination with others to boost their relevance, or they could be dropped to simplify the model.\n",
    "\n",
    "#### Next Steps\n",
    "- **Validate with SHAP**: To get a deeper dive, you could use SHAP values to see how individual instances are affected by these features, especially for edge cases.\n",
    "- **Fairness Check**: Given the age bias we’ve discussed, you might want to re-run the fairness evaluation with these importance scores in mind to see if adjusting feature weights could balance predictions.\n",
    "- **Domain Expert Input**: Consulting a cardiologist could confirm if `thal` and `thalach` being top predictors makes sense clinically or if the model is overfitting to these variables.\n",
    "\n",
    "This chart gives a clear picture of what drives the model’s heart disease predictions, with clinical test results leading the way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This pipeline exemplifies responsible AI by proactively addressing biases, protecting privacy, and ensuring interpretability. Future improvements could include bias mitigation, privacy-accuracy optimization, and validation on diverse datasets. The approach promotes ethical AI development, fostering trust and fairness in healthcare predictive modeling.\n",
    "\n",
    "## Clean up\n",
    "\n",
    "Remember to shut down your Jupyter Notebook environment and delete any unnecessary files or resources once you've completed the tutorial.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
