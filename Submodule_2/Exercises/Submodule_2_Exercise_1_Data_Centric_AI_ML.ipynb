{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-Centric AI: A Practical Comparison of Poorly-Prepared vs Well-Prepared Data\n",
    "\n",
    "## Overview\n",
    "\n",
    "This exercise demonstrates the importance of **data-centric AI principles** by comparing the performance of a machine learning model trained on **poorly-prepared data** (ignoring data-centric practices) versus **well-prepared data** (following data-centric practices). Using the Pima Indians Diabetes dataset, we showcase how feature engineering, handling class imbalance, data augmentation, and other data-centric steps significantly improve model performance. The comparison is evaluated using the **F1 score**, a metric that balances precision and recall.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this exercise, you will:\n",
    "\n",
    "- Understand the key principles of **data-centric AI** and their impact on model performance.\n",
    "- Learn how to perform **automated feature engineering** using Featuretools.\n",
    "- Address class imbalance using **SMOTE** (Synthetic Minority Oversampling Technique).\n",
    "- Generate synthetic data for **data augmentation** to improve model generalization.\n",
    "- Validate data labels based on **domain-specific rules**.\n",
    "- Standardize data using **StandardScaler** for better model training.\n",
    "- Compare the performance of models trained on poorly-prepared and well-prepared data.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "To follow along with this exercise, you should have:\n",
    "\n",
    "- Basic knowledge of **Python** and **Pandas** for data manipulation.\n",
    "- Familiarity with **scikit-learn** for machine learning tasks.\n",
    "- Understanding of **classification metrics** like F1 score.\n",
    "- Installation of the following Python libraries: pandas numpy scikit-learn imbalanced-learn featuretools\n",
    "\n",
    "## Get Started\n",
    "\n",
    "Letâ€™s begin by loading the dataset and performing a data-centric workflow. The workflow includes:\n",
    "- Load the Dataset\n",
    "- Poorly-Prepared Data\n",
    "- Well-Prepared Data\n",
    "- Performance Comparision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries using pip\n",
    "# pandas: For data manipulation and analysis, especially with DataFrames.\n",
    "# numpy: For numerical operations and handling multi-dimensional arrays.\n",
    "# scikit-learn: A comprehensive machine learning library for preprocessing, modeling, and evaluation.\n",
    "# imbalanced-learn: Provides tools to handle imbalanced datasets, such as oversampling and undersampling techniques.\n",
    "# featuretools: An automated feature engineering library that helps create new features from existing data.\n",
    "\n",
    "%pip install pandas numpy scikit-learn imbalanced-learn featuretools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd  # For data manipulation and analysis using DataFrames\n",
    "import numpy as np  # For numerical operations and array handling\n",
    "\n",
    "# Scikit-learn modules for model building and evaluation\n",
    "from sklearn.model_selection import train_test_split  # For splitting data into training and testing sets\n",
    "from sklearn.preprocessing import StandardScaler  # For standardizing features by removing the mean and scaling to unit variance\n",
    "from sklearn.ensemble import RandomForestClassifier  # Random Forest model for classification tasks\n",
    "from sklearn.metrics import f1_score  # F1 score metric to evaluate model performance\n",
    "\n",
    "# Imbalanced-learn module for handling imbalanced datasets\n",
    "from imblearn.over_sampling import SMOTE  # Synthetic Minority Over-sampling Technique to balance class distribution\n",
    "\n",
    "# Featuretools for automated feature engineering\n",
    "import featuretools as ft  \n",
    "\n",
    "# Suppress warnings to keep the output clean\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)  # Ignore all warnings during execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load biomedical dataset (Pima Indians Diabetes Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load biomedical dataset (Pima Indians Diabetes Dataset)\n",
    "\n",
    "# Define the path to the dataset and the column names for the dataset\n",
    "diabetes_data = '../../Data/pima-indians-diabetes.csv'\n",
    "columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI',\n",
    "           'DiabetesPedigreeFunction', 'Age', 'Outcome']  # Define column names for the dataset\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "# - header=None: Specifies no header in the CSV file (columns are provided manually)\n",
    "# - names=columns: Assigns custom column names defined above\n",
    "# - na_values='?': Specifies that '?' represents missing values in the dataset\n",
    "# - sep=',': Specifies comma as the delimiter\n",
    "data = pd.read_csv(diabetes_data, header=None, names=columns, na_values='?', sep=',')\n",
    "\n",
    "# Print the shape of the dataset (number of rows and columns)\n",
    "print('Dataset Shape:', data.shape)\n",
    "\n",
    "# Print the number of missing values in each column\n",
    "print('Initial Missing Values:', data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate Poorly-Prepared Data (Ignoring Data-Centric Principles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Poorly-Prepared Data (Ignoring Data-Centric Principles)\n",
    "# --------------------------\n",
    "\n",
    "# 1. Skip Data Cleaning: Use raw data (no missing values to handle)\n",
    "\n",
    "# Separate the features (X) and the target variable (y) from the dataset\n",
    "# X_poor: Contains all the feature columns (drop the 'Outcome' column)\n",
    "X_poor = data.drop('Outcome', axis=1)\n",
    "\n",
    "# y_poor: Contains only the target variable 'Outcome'\n",
    "y_poor = data['Outcome']\n",
    "\n",
    "\n",
    "# 2. Skip Feature Engineering: Use raw data without feature engineering\n",
    "# (No Featuretools or other feature engineering applied)\n",
    "\n",
    "# 3. Skip Handling Class Imbalance: Use original imbalanced data\n",
    "# (No SMOTE or other balancing techniques)\n",
    "\n",
    "# 4. Skip Data Augmentation: Do not generate synthetic data\n",
    "# (No augmentation applied)\n",
    "\n",
    "# 5. Skip Data Labeling Quality Check: Do not validate labels\n",
    "# (Assume labels are correct)\n",
    "\n",
    "# 6. Skip Data Standardization: Use raw data without scaling\n",
    "# (No scaling applied)\n",
    "\n",
    "# Split poorly-prepared data into training and testing sets\n",
    "\n",
    "# X_train_poor: Features for training the model\n",
    "# X_test_poor: Features for testing the model\n",
    "# y_train_poor: Labels for training the model\n",
    "# y_test_poor: Labels for testing the model\n",
    "\n",
    "# Using train_test_split to divide the data into training (80%) and testing (20%) sets\n",
    "X_train_poor, X_test_poor, y_train_poor, y_test_poor = train_test_split(X_poor, y_poor, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Train a Random Forest classifier on poorly-prepared data\n",
    "\n",
    "# Initialize the Random Forest model with 100 trees and a fixed random seed (for reproducibility)\n",
    "model_poorly_prepared = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model on the training data (X_train_poor and y_train_poor)\n",
    "# This step trains the model to learn patterns in the data\n",
    "model_poorly_prepared.fit(X_train_poor, y_train_poor)\n",
    "\n",
    "\n",
    "# Evaluate poorly-prepared model\n",
    "\n",
    "# Predict the labels for the test data (X_test_poor) using the trained model\n",
    "preds_poorly_prepared = model_poorly_prepared.predict(X_test_poor)\n",
    "\n",
    "# Calculate the F1 score, a measure of the model's performance considering both precision and recall\n",
    "# The F1 score is especially useful for imbalanced datasets\n",
    "f1_poorly_prepared = f1_score(y_test_poor, preds_poorly_prepared)\n",
    "\n",
    "# Print the F1 score with a precision of 4 decimal places\n",
    "print(f\"F1 Score (Poorly-Prepared Data): {f1_poorly_prepared:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate Well-Prepared Data (Following Data-Centric Principles)\n",
    "#### 1. Data Quality Assessment\n",
    "- **What it does**: Checks for missing values in the dataset.\n",
    "- **Data-centric aspect**: Ensures the dataset is clean and complete before proceeding. Poor data quality (e.g., missing values) can lead to unreliable models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Quality Assessment\n",
    "\n",
    "# Display a header for the analysis of missing values in the dataset\n",
    "print(\"\\nWell-Prepared Data: Missing Values Analysis:\")\n",
    "\n",
    "# Calculate and print the total number of missing values in each column of the dataset\n",
    "\n",
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Data Cleaning\n",
    "- **What it does**: Uses KNN imputation to fill in missing values.\n",
    "- **Data-centric aspect**: Ensures the dataset is complete and ready for analysis. Imputation is a data-centric technique to handle missing data without discarding valuable information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Skip Data Cleaning: No missing values to handle\n",
    "# (No KNN imputation or other cleaning applied)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Feature Engineering\n",
    "- **What it does**: Automatically generates new features from the dataset using Featuretools.\n",
    "- **Data-centric aspect**: Feature engineering is a core part of data-centric AI. It transforms raw data into meaningful features that improve model performance. Automated feature engineering ensures that the data is represented in a way that captures important patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Feature Engineering: Automated feature engineering using Featuretools\n",
    "\n",
    "# Create an empty EntitySet for the dataset\n",
    "es = ft.EntitySet(id='diabetes')  # 'id' is a name for the entity set, useful for organizing multiple datasets\n",
    "\n",
    "# Add the data DataFrame to the EntitySet\n",
    "es = es.add_dataframe(\n",
    "    dataframe=data,              # The DataFrame containing the original dataset\n",
    "    dataframe_name='data',       # Name of the DataFrame within the EntitySet\n",
    "    index='index'                # Column to use as a unique identifier for each row (must be an index column)\n",
    ")\n",
    "\n",
    "# Generate new features using Deep Feature Synthesis (DFS) in Featuretools\n",
    "features, feature_defs = ft.dfs(\n",
    "    entityset=es,                # The EntitySet containing the data\n",
    "    target_dataframe_name='data',# The name of the DataFrame to generate features for\n",
    "    max_depth=2,                 # The maximum depth of feature generation (higher values = more complex features)\n",
    "    verbose=1                    # Displays progress information during feature generation\n",
    ")\n",
    "\n",
    "# 'features' is a DataFrame containing the new features for the model\n",
    "# 'feature_defs' is a list of the generated feature definitions (metadata about the features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Handling Class Imbalance\n",
    "- **What it does**: Uses SMOTE (Synthetic Minority Oversampling Technique) to balance the dataset by generating synthetic samples for the minority class.\n",
    "- **Data-centric aspect**: Addresses the issue of imbalanced data, which can bias the model toward the majority class. By balancing the data, the model can learn better from all classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Handle Class Imbalance: Use SMOTE to balance the dataset\n",
    "\n",
    "# Separate features and target variable from the generated feature set\n",
    "X = features.drop('Outcome', axis=1)  # Features (all columns except 'Outcome')\n",
    "y = features['Outcome']  # Target variable ('Outcome' column)\n",
    "\n",
    "# Initialize SMOTE for oversampling the minority class\n",
    "\n",
    "smote = # Your code goes here\n",
    "\n",
    "# Apply SMOTE to generate synthetic samples for the minority class\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "# 'X_res' contains the balanced feature set with synthetic samples added\n",
    "# 'y_res' is the corresponding balanced target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Data Augmentation\n",
    "- **What it does**: Generates synthetic data by adding small amounts of noise to the existing data.\n",
    "- **Data-centric aspect**: Data augmentation increases the size and diversity of the dataset, which helps the model generalize better. This is especially useful in domains like healthcare where data may be limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Data Augmentation: Generate synthetic data to enhance model generalization\n",
    "\n",
    "def medical_augmentation(X, y, multiplier=1):\n",
    "    \"\"\"\n",
    "    Generates synthetic data by adding Gaussian noise to the original features.\n",
    "    \n",
    "    Parameters:\n",
    "    - X (numpy array or DataFrame): The input feature set.\n",
    "    - y (numpy array or Series): The target variable.\n",
    "    - multiplier (int): The number of synthetic datasets to generate.\n",
    "    \n",
    "    Returns:\n",
    "    - Augmented feature set (numpy array)\n",
    "    - Corresponding augmented target variable (numpy array)\n",
    "    \"\"\"\n",
    "    augmented = []  # List to store augmented feature sets\n",
    "    for _ in range(multiplier):\n",
    "        # Generate random Gaussian noise with mean 0 and standard deviation 0.01\n",
    "        noise = np.random.normal(0, 0.01, X.shape)\n",
    "        \n",
    "        # Add noise to the original features to create synthetic samples\n",
    "        augmented.append(X + noise)\n",
    "    \n",
    "    # Combine augmented datasets vertically and replicate target labels accordingly\n",
    "    return np.vstack(augmented), np.concatenate([y] * multiplier)\n",
    "\n",
    "# Apply data augmentation with a multiplier of 2 (doubling the dataset size)\n",
    "X_aug, y_aug = medical_augmentation(X_res, y_res, multiplier=2)\n",
    "\n",
    "# 'X_aug' contains the augmented features\n",
    "# 'y_aug' contains the corresponding target labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Data Labeling Quality Check\n",
    "- **What it does**: Identifies and removes invalid labels based on domain-specific rules (e.g., a glucose level < 40 is unlikely to be labeled as diabetic).\n",
    "- **Data-centric aspect**: Ensures the labels are accurate and consistent with domain knowledge. Poor labeling can lead to incorrect model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Data Labeling Quality Check: Validate labels based on domain-specific rules\n",
    "\n",
    "def validate_labels(X_df, y_labels):\n",
    "    \"\"\"\n",
    "    Identifies invalid labels based on domain knowledge rules.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_df (DataFrame): Feature set as a pandas DataFrame.\n",
    "    - y_labels (array-like): Corresponding target labels.\n",
    "    \n",
    "    Returns:\n",
    "    - invalid_indices (list): Indices of samples with invalid labels.\n",
    "    \"\"\"\n",
    "    invalid_indices = []  # List to store indices of invalid samples\n",
    "    \n",
    "    # Iterate through each row of the feature set\n",
    "    for idx, row in X_df.iterrows():\n",
    "        # Domain rule: If Glucose is abnormally low (< 40), 'Outcome' (label) shouldn't indicate diabetes (1)\n",
    "        \n",
    "        # Your code goes ehre\n",
    "            invalid_indices.append(idx)  # Add index to invalid list if rule is violated\n",
    "    \n",
    "    return invalid_indices\n",
    "\n",
    "# Convert augmented feature array back to a DataFrame for validation\n",
    "X_aug_df = pd.DataFrame(X_aug, columns=X.columns)\n",
    "\n",
    "# Identify invalid samples based on the domain rule\n",
    "invalid_ids = validate_labels(X_aug_df, y_aug)\n",
    "\n",
    "# Remove invalid samples from both features and labels\n",
    "X_clean = np.delete(X_aug, invalid_ids, axis=0)  # axis=0 indicates row deletion\n",
    "y_clean = np.delete(y_aug, invalid_ids)  # Corresponding labels are also removed\n",
    "\n",
    "# 'X_clean' and 'y_clean' now contain only valid data samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Data Standarization\n",
    "- **What it does**: Standardizes the features to have zero mean and unit variance.\n",
    "- **Data-centric aspect**: Ensures that all features are on the same scale, which is important for many machine learning algorithms (e.g., those using distance metrics or gradient descent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Data Standardization: Scale features to improve model performance\n",
    "\n",
    "# Initialize a StandardScaler to standardize features\n",
    "\n",
    "# Your code goes here\n",
    "\n",
    "# Fit the scaler to the data and transform it\n",
    "X_scaled = scaler.fit_transform(X_clean)\n",
    "\n",
    "# 'X_scaled' is the standardized feature set, where each feature has:\n",
    "# - Mean â‰ˆ 0\n",
    "# - Standard Deviation â‰ˆ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Model Training\n",
    "- **What it does**: Trains a Random Forest classifier on the processed data.\n",
    "- **Data-centric aspect**: The model is trained on high-quality, well-prepared data, which is the foundation of data-centric AI. The focus is on ensuring the data is clean, balanced, and representative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Split well-prepared data into training and testing sets\n",
    "\n",
    "# Split the standardized data into 80% training and 20% testing subsets\n",
    "\n",
    "X_train, X_test, y_train, y_test = # Your code goes here\n",
    "\n",
    "# 'X_train', 'y_train': Data used to train the model\n",
    "# 'X_test', 'y_test': Data used to evaluate model performance on unseen data\n",
    "\n",
    "# 9. Train a Random Forest classifier on well-prepared data\n",
    "\n",
    "# Initialize the Random Forest model with 100 decision trees\n",
    "\n",
    "model_well_prepared = # Your code goes here\n",
    "\n",
    "# Fit the model to the training data\n",
    "model_well_prepared.fit(X_train, y_train)\n",
    "\n",
    "# The model is now trained on clean, balanced, and standardized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Evaluation\n",
    "- **What it does**: Evaluates the model using the F1 score.\n",
    "- **Data-centric aspect**: The evaluation metric reflects the quality of the data and the preprocessing steps. A high F1 score indicates that the data-centric approach has improved the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Evaluate well-prepared model performance on the test set\n",
    "\n",
    "# Make predictions on the test data using the trained model\n",
    "preds_well_prepared = model_well_prepared.predict(X_test)\n",
    "\n",
    "# Calculate the F1 score for the well-prepared model\n",
    "f1_well_prepared = f1_score(y_test, preds_well_prepared)\n",
    "\n",
    "# Output the F1 score with four decimal precision\n",
    "print(f\"F1 Score (Well-Prepared Data): {f1_well_prepared:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# Performance Comparison between Data Approaches\n",
    "# -------------------------------------------------\n",
    "\n",
    "# Display a header for clarity in the output\n",
    "print(\"\\nPerformance Comparison:\")\n",
    "\n",
    "# Print the F1 score of the model trained on poorly-prepared data\n",
    "print(f\"Poorly-Prepared Data F1 Score: {f1_poorly_prepared:.4f}\")\n",
    "\n",
    "# Print the F1 score of the model trained on well-prepared data\n",
    "print(f\"Well-Prepared Data F1 Score: {f1_well_prepared:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of Data-Centric Principles\n",
    "- **Focus on Data Quality**: Cleaning, imputation, and validation ensure the dataset is reliable.\n",
    "- **Feature Engineering**: Transforming raw data into meaningful features improves model performance.\n",
    "- **Handling Imbalance**: Balancing the dataset ensures the model learns from all classes.\n",
    "- **Data Augmentation**: Increasing dataset size and diversity helps the model generalize.\n",
    "- **Domain-Specific Validation**: Ensuring labels and data align with domain knowledge improves reliability.\n",
    "- **Standardization**: Preparing data for modeling by scaling features appropriately.\n",
    "\n",
    "By focusing on these data-centric steps, the exercise demonstrates that high-quality data is the foundation of effective machine learning, and improving the data can lead to better model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion  \n",
    "This exercise demonstrates the critical role of data-centric AI principles in building effective machine learning models. By comparing the performance of models trained on poorly-prepared and well-prepared data, we observe that:\n",
    "\n",
    "- **Poorly-Prepared Data:** Skipping data-centric steps leads to a lower F1 score (**0.65**), indicating poor model performance.  \n",
    "\n",
    "- **Well-Prepared Data:** Following data-centric practices results in a higher F1 score (**0.85**), showcasing the importance of clean, balanced, and well-represented data.  \n",
    "\n",
    "The key takeaway is that **high-quality data** is the foundation of successful machine learning. By investing time in data preparation, you can significantly improve model performance and reliability.  \n",
    "\n",
    "\n",
    "## Next Steps  \n",
    "- Experiment with other datasets to see how data-centric practices impact performance.  \n",
    "- Explore additional data augmentation techniques, such as **GANs** (*Generative Adversarial Networks*).  \n",
    "- Try different machine learning models (e.g., **XGBoost**, **SVM**) to see how they perform on well-prepared data. \n",
    "\n",
    "\n",
    "## Clean up\n",
    "\n",
    "Remember to shut down your Jupyter Notebook environment and delete any unnecessary files or resources once you've completed the exercise. \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
