{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mark and Remove Missing Data\n",
    "\n",
    "Adapted from Jason Brownlee. 2020. [Data Preparation for Machine Learning](https://machinelearningmastery.com/data-preparation-for-machine-learning/).\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this tutorial, we will learn how to handle missing data in datasets, specifically focusing on marking and removing missing values. By applying these techniques, you'll be able to prepare high-quality datasets for machine learning, improving model reliability and accuracy.\n",
    "\n",
    "We'll use the Pima Indians Diabetes dataset as an example to demonstrate these techniques.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Learn how to identify and mark invalid or corrupt values as missing in a dataset\n",
    "- Understand how the presence of marked missing values affects machine learning algorithms\n",
    "- Learn how to remove rows with missing data from a dataset\n",
    "- Evaluate a learning algorithm on a dataset after removing rows with missing values\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Basic understanding of Python programming\n",
    "- Familiarity with pandas, numpy, and scikit-learn libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Started\n",
    "\n",
    "To start, we install required packages, import the necessary libraries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy pandas scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# Pima Indians Diabetes data set file\n",
    "pima_indians_diabetes_csv = \"../../Data/pima-indians-diabetes.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes Dataset\n",
    "\n",
    "The dataset classifies patient as\n",
    "either an onset of diabetes withinâ€€five years or not.\n",
    "\n",
    "```\n",
    "Number of Instances: 768\n",
    "Number of Attributes: 8 plus class\n",
    "For Each Attribute: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)\n",
    "Missing Attribute Values: Yes\n",
    "Class Distribution: (class value 1 is interpreted as \"tested positive for\n",
    "   diabetes\")\n",
    "   Class Value  Number of instances\n",
    "   0            500\n",
    "   1            268\n",
    "```\n",
    "\n",
    "You can learn more about the dataset here:\n",
    "\n",
    "- Diabetes Dataset File ([pima-indians-diabetes.csv](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv))\n",
    "- Diabetes Dataset Details ([pima-indians-diabetes.names](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names))\n",
    "\n",
    "The description of Diabetes Dataset can be found [here](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and summarize the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv(pima_indians_diabetes_csv, header=None)\n",
    "\n",
    "# Peek into the top five rows\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the dataset\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are columns that have a minimum value of zero (0).\n",
    "On some columns, a value of zero does not make sense and indicates an invalid or missing value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, the following columns have an invalid zero minimum value: 2. Plasma glucose concentration 3. Diastolic blood pressure 4. Triceps skinfold thickness 5. 2-Hour serum insulin 6. Body mass index\n",
    "\n",
    "We can confirm this by looking at the raw data and printing out the first 20 rows of data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset and review rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv(pima_indians_diabetes_csv, header=None)\n",
    "\n",
    "# Summarize the first 20 rows of data\n",
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a count of the number of missing values on each of these columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing the number of missing values for each variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv(pima_indians_diabetes_csv, header=None)\n",
    "\n",
    "# Count the number of missing values for each column\n",
    "num_missing = (dataset[[1, 2, 3, 4, 5]] == 0).sum()\n",
    "\n",
    "# Report the results\n",
    "print(num_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that columns 1, 2 and 5 have just a few zero values, whereas columns 3 and 4\n",
    "show a lot more, nearly half of the rows. This highlights that different missing value strategies\n",
    "may be needed for different columns, e.g. to ensure that there are still a sufficient number of\n",
    "records left to train a predictive model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, specifically Pandas, NumPy and Scikit-Learn, we mark missing values as NaN.\n",
    "Values with a NaN value are ignored from operations like sum, count, etc. We can mark values\n",
    "as NaN easily with the Pandas DataFrame by using the replace() function on a subset of\n",
    "the columns we are interested in. After we have marked the missing values, we can use the\n",
    "isnull() function to mark all of the NaN values in the dataset as True and get a count of the\n",
    "missing values for each column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marking missing values with nan values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv(pima_indians_diabetes_csv, header=None)\n",
    "\n",
    "# Replace '0' values with 'nan'\n",
    "dataset[[1, 2, 3, 4, 5]] = dataset[[1, 2, 3, 4, 5]].replace(0, np.nan)\n",
    "\n",
    "# Count the number of nan values in each column\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm by printing out the first 20 rows of data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review data with missing values marked with a nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv(pima_indians_diabetes_csv, header=None)\n",
    "\n",
    "# Replace '0' values with 'nan'\n",
    "dataset[[1, 2, 3, 4, 5]] = dataset[[1, 2, 3, 4, 5]].replace(0, np.nan)\n",
    "\n",
    "# Summarize the first 20 rows of data\n",
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values Cause Problems\n",
    "\n",
    "Having missing values in a dataset can cause errors with some machine learning algorithms.\n",
    "\n",
    "*Note!* You should see a message about an error occurring when you try to run the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv(pima_indians_diabetes_csv, header=None)\n",
    "\n",
    "# Replace '0' values with 'nan'\n",
    "dataset[[1, 2, 3, 4, 5]] = dataset[[1, 2, 3, 4, 5]].replace(0, np.nan)\n",
    "\n",
    "# Split dataset into inputs and outputs\n",
    "values = dataset.values\n",
    "X = values[:, 0:8]\n",
    "y = values[:, 8]\n",
    "\n",
    "# Define the model\n",
    "#\n",
    "# A classifier with a linear decision boundary, generated by fitting class\n",
    "# conditional densities to the data and using Bayes' rule.\n",
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Define the model evaluation procedure using K fold cross-validation\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "# Evaluate the model accuracy score, and report the mean performance if it succeeds.\n",
    "try:\n",
    "    result = cross_val_score(model, X, y, cv=cv, scoring=\"accuracy\")\n",
    "    print(\"Accuracy: %.3f\" % result.mean())\n",
    "except ValueError as e:\n",
    "    print(f\"********************* An (expected) error occurred *********************\\n{e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Rows With Missing Values\n",
    "\n",
    "The simplest approach for dealing with missing values is to remove entire predictor(s)\n",
    "and/or sample(s) that contain missing values.\n",
    "\n",
    "We can do this by creating a new Pandas DataFrame with the rows containing missing values\n",
    "removed. Pandas provides the `dropna()` function that can be used to drop either columns or\n",
    "rows with missing data. We can use `dropna()` to remove all rows with missing data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of removing rows that contain missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv(pima_indians_diabetes_csv, header=None)\n",
    "\n",
    "# Summarize the shape of the raw data\n",
    "print(dataset.shape)\n",
    "\n",
    "# Replace '0' values with 'nan'\n",
    "dataset[[1, 2, 3, 4, 5]] = dataset[[1, 2, 3, 4, 5]].replace(0, np.nan)\n",
    "\n",
    "# Drop rows with missing values\n",
    "dataset.dropna(inplace=True)\n",
    "\n",
    "# Summarize the shape of the data with missing rows removed\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a dataset that we could use to evaluate an algorithm sensitive to missing values\n",
    "like LDA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model on data after rows with missing data are removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv(pima_indians_diabetes_csv, header=None)\n",
    "\n",
    "# Replace '0' values with 'nan'\n",
    "dataset[[1, 2, 3, 4, 5]] = dataset[[1, 2, 3, 4, 5]].replace(0, np.nan)\n",
    "\n",
    "# Drop rows with missing values\n",
    "dataset.dropna(inplace=True)\n",
    "\n",
    "# Split dataset into inputs and outputs\n",
    "values = dataset.values\n",
    "X = values[:, 0:8]\n",
    "y = values[:, 8]\n",
    "\n",
    "# Define the model\n",
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Define the model evaluation procedure\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "# Evaluate the model accuracy score\n",
    "result = cross_val_score(model, X, y, cv=cv, scoring=\"accuracy\")\n",
    "\n",
    "# Report the mean performance\n",
    "print(\"Accuracy: %.3f\" % result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we learned how to:\n",
    "\n",
    "- Identify and mark missing values in a dataset\n",
    "- Understand the impact of missing values on machine learning algorithms\n",
    "- Remove rows with missing data\n",
    "- Evaluate a machine learning model on a cleaned dataset\n",
    "\n",
    "These skills are crucial for preparing real-world datasets for analysis and machine learning tasks.\n",
    "\n",
    "## Clean up\n",
    "\n",
    "Remember to shut down your Jupyter notebook and delete any unnecessary resources when you're finished with this tutorial."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
