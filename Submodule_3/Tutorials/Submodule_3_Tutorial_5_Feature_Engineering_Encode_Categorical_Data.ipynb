{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Categorical Data\n",
    "\n",
    "Adapted from Jason Brownlee. 2020. [Data Preparation for Machine Learning](https://machinelearningmastery.com/data-preparation-for-machine-learning/).\n",
    "\n",
    "## Overview\n",
    "\n",
    "This module covers techniques for encoding categorical data into numerical formats for machine learning models. We'll explore different encoding methods including ordinal encoding, one-hot encoding, and dummy variable encoding using a breast cancer dataset as a practical example.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Learn why encoding is required for preprocessing categorical data in machine learning algorithms\n",
    "- Understand how to use ordinal encoding for categorical variables with natural rank ordering\n",
    "- Understand one-hot encoding techniques for categorical variables without natural rank ordering\n",
    "- Apply encoding techniques to real medical data for breast cancer prediction\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Basic understanding of Python programming\n",
    "- Familiarity with NumPy libraries\n",
    "- Knowledge of basic statistical concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Started\n",
    "\n",
    "To start, we install required packages, import the necessary libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/chenc/miniconda3/lib/python3.9/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /Users/chenc/miniconda3/lib/python3.9/site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/chenc/miniconda3/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/chenc/miniconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/chenc/miniconda3/lib/python3.9/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/chenc/miniconda3/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/chenc/miniconda3/lib/python3.9/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/chenc/miniconda3/lib/python3.9/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/chenc/miniconda3/lib/python3.9/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/chenc/miniconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the numpy, pandas, and scikit-learn Python libraries using pip.\n",
    "# numpy:  A fundamental package for numerical computation in Python. It provides support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays.\n",
    "# pandas: A powerful data manipulation and analysis library. It offers data structures like DataFrames for efficiently handling and analyzing structured data (tabular data, time series, etc.).\n",
    "# scikit-learn: A widely used machine learning library in Python. It provides simple and efficient tools for data mining and data analysis, including various classification, regression, clustering algorithms, model selection, and preprocessing tools.\n",
    "%pip install numpy pandas scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the 'asarray' function from the NumPy library.\n",
    "# This function is used to convert input to a NumPy array.\n",
    "from numpy import asarray\n",
    "\n",
    "# Import the 'read_csv' function from the pandas library.\n",
    "# This function is used to read data from a CSV file into a pandas DataFrame.\n",
    "from pandas import read_csv\n",
    "\n",
    "# Import the 'LogisticRegression' class from the scikit-learn library (sklearn).\n",
    "# This class is used to create a logistic regression model for classification tasks.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import the 'accuracy_score' function from the scikit-learn metrics module.\n",
    "# This function is used to calculate the accuracy of a classification model.\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Import the 'train_test_split' function from the scikit-learn model_selection module.\n",
    "# This function is used to split a dataset into training and testing sets.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import 'LabelEncoder', 'OneHotEncoder', and 'OrdinalEncoder' classes from scikit-learn preprocessing module.\n",
    "# These classes are used for encoding categorical variables into numerical representations.\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer Categorical Dataset\n",
    "\n",
    "Breast cancer dataset classifies breast cancer\n",
    "patient as either a recurrence or no recurrence of cancer. \n",
    "\n",
    "```\n",
    "Number of Instances: 286\n",
    "Number of Attributes: 9 + the class attribute\n",
    "Attribute Information:\n",
    "   1. Class: no-recurrence-events, recurrence-events\n",
    "   2. age: 10-19, 20-29, 30-39, 40-49, 50-59, 60-69, 70-79, 80-89, 90-99.\n",
    "   3. menopause: lt40, ge40, premeno.\n",
    "   4. tumor-size: 0-4, 5-9, 10-14, 15-19, 20-24, 25-29, 30-34, 35-39, 40-44, 45-49, 50-54, 55-59.\n",
    "   5. inv-nodes: 0-2, 3-5, 6-8, 9-11, 12-14, 15-17, 18-20, 21-23, 24-26, 27-29, 30-32, 33-35, 36-39.\n",
    "   6. node-caps: yes, no.\n",
    "   7. deg-malig: 1, 2, 3.\n",
    "   8. breast: left, right.\n",
    "   9. breast-quad: left-up, left-low, right-up,\tright-low, central.\n",
    "  10. irradiat:\tyes, no.\n",
    "Missing Attribute Values: (denoted by \"?\")\n",
    "   Attribute #:  Number of instances with missing values:\n",
    "   6.             8\n",
    "   9.             1.\n",
    "Class Distribution:\n",
    "    1. no-recurrence-events: 201 instances\n",
    "    2. recurrence-events: 85 instances \n",
    "```\n",
    "\n",
    "You can learn more about the dataset here:\n",
    "* Breast Cancer Dataset ([breast-cancer.csv](https://raw.githubusercontent.com/jbrownlee/Datasets/master/breast-cancer.csv))\n",
    "* Breast Cancer Dataset Description ([breast-cancer.names](https://raw.githubusercontent.com/jbrownlee/Datasets/master/breast-cancer.names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and summarize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0          1        2      3      4    5        6           7      8  \\\n",
      "0  '40-49'  'premeno'  '15-19'  '0-2'  'yes'  '3'  'right'   'left_up'   'no'   \n",
      "1  '50-59'     'ge40'  '15-19'  '0-2'   'no'  '1'  'right'   'central'   'no'   \n",
      "2  '50-59'     'ge40'  '35-39'  '0-2'   'no'  '2'   'left'  'left_low'   'no'   \n",
      "3  '40-49'  'premeno'  '35-39'  '0-2'  'yes'  '3'  'right'  'left_low'  'yes'   \n",
      "4  '40-49'  'premeno'  '30-34'  '3-5'  'yes'  '2'   'left'  'right_up'   'no'   \n",
      "\n",
      "                        9  \n",
      "0     'recurrence-events'  \n",
      "1  'no-recurrence-events'  \n",
      "2     'recurrence-events'  \n",
      "3  'no-recurrence-events'  \n",
      "4     'recurrence-events'  \n",
      "Input (286, 9)\n",
      "Output (286,)\n"
     ]
    }
   ],
   "source": [
    "# Define a variable 'breast_cancer_csv' that stores the file path to the breast cancer dataset CSV file.\n",
    "# The file path is relative to the current script's location and points to a file named \"breast-cancer.csv\" in the \"../../Data/\" directory.\n",
    "breast_cancer_csv = \"../../Data/breast-cancer.csv\"\n",
    "\n",
    "# Load the dataset from the CSV file into a pandas DataFrame.\n",
    "# 'header=None' argument indicates that the CSV file does not have a header row.\n",
    "dataset = read_csv(breast_cancer_csv, header=None)\n",
    "\n",
    "# Print the first few rows of the DataFrame to inspect the loaded data.\n",
    "# 'dataset.head()' displays the first 5 rows by default, allowing for a quick data preview.\n",
    "print(dataset.head())\n",
    "\n",
    "# Retrieve the underlying NumPy array from the pandas DataFrame.\n",
    "# 'dataset.values' converts the DataFrame into a NumPy array for numerical operations and indexing.\n",
    "data = dataset.values\n",
    "\n",
    "# Separate the data into input features (X) and output labels (y).\n",
    "# 'data[:, :-1]' selects all rows (:) and all columns except the last one (:-1) as input features (X).\n",
    "# '.astype(str)' converts the input features to string type, assuming the features are meant to be strings.\n",
    "X = data[:, :-1].astype(str)\n",
    "\n",
    "# 'data[:, -1]' selects all rows (:) and only the last column (-1) as output labels (y).\n",
    "# '.astype(str)' converts the output labels to string type, assuming the labels are meant to be strings.\n",
    "y = data[:, -1].astype(str)\n",
    "\n",
    "# Summarize the shape of the input features (X) and output labels (y).\n",
    "# 'X.shape' returns a tuple representing the dimensions of the input feature array (rows, columns).\n",
    "# 'y.shape' returns a tuple representing the dimensions of the output label array (rows,).\n",
    "print(\"Input\", X.shape)\n",
    "print(\"Output\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We\n",
    "can see that we have 286 examples and nine input variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nominal And Ordinal Variables\n",
    "\n",
    "* **Nominal Variable**. Variable comprises a finite set of discrete values with no rank-order\n",
    "relationship between values.\n",
    "* **Ordinal Variable**. Variable comprises a finite set of discrete values with a ranked\n",
    "ordering between values.\n",
    "\n",
    "Some algorithms can work with categorical data directly. For example, a decision tree can\n",
    "be learned directly from categorical data with no data transform required (this depends on\n",
    "the specific implementation). Many machine learning algorithms cannot operate on label data\n",
    "directly. They require all input variables and output variables to be numeric. In general, this is\n",
    "mostly a constraint of the effcient implementation of machine learning algorithms rather than\n",
    "hard limitations on the algorithms themselves.\n",
    "\n",
    "Some implementations of machine learning algorithms require all data to be numerical. This means that categorical data must be converted\n",
    "to a numerical form. If the categorical variable is an output variable, you may also want to\n",
    "convert predictions by the model back into a categorical form in order to present them or use\n",
    "them in some application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Data\n",
    "\n",
    "There are three common approaches for converting ordinal and categorical variables to numerical\n",
    "values. They are:\n",
    "* Ordinal Encoding\n",
    "* One-Hot Encoding\n",
    "* Dummy Variable Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal Encoding\n",
    "\n",
    "In ordinal encoding, each unique category value is assigned an integer value. An integer ordinal encoding is a natural encoding for ordinal variables. For categorical\n",
    "variables, it imposes an ordinal relationship where no such relationship may exist. This can\n",
    "cause problems and a one-hot encoding may be used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of an ordinal encoding\n",
    "\n",
    "# Encode categorical features as an integer array\n",
    "\n",
    "# Define the categorical data as a NumPy array.\n",
    "# In this example, the data consists of color names: 'red', 'green', 'blue'.\n",
    "data = asarray([[\"red\"], [\"green\"], [\"blue\"]])\n",
    "# Print the original categorical data to show the input before encoding.\n",
    "print(\"Original data: \\n\", data)\n",
    "\n",
    "# Define the ordinal encoder.\n",
    "# OrdinalEncoder is used to convert categorical data into numerical ordinal data.\n",
    "# By default, it assigns numerical values based on the order it encounters categories.\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "# Fit OrdinalEncoder to the data and then transform the data.\n",
    "# .fit(data) learns the unique categories from the input data. In this case, it learns 'red', 'green', 'blue'.\n",
    "# .transform(data) then replaces each category in the data with its corresponding ordinal integer.\n",
    "result = encoder.fit_transform(data)\n",
    "# Print the encoded data to show the numerical representation after ordinal encoding.\n",
    "# The output will be a NumPy array where each color is replaced by an integer.\n",
    "print(\"Encoded data: \\n\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We\n",
    "can see that the numbers are assigned to the labels as we expected.\n",
    "\n",
    "This **OrdinalEncoder** class is intended for input variables that are organized into rows and\n",
    "columns, e.g. a matrix. If a categorical target variable needs to be encoded for a classification\n",
    "problem, then the **LabelEncoder** class can be used. It does the same\n",
    "thing as the **OrdinalEncoder**, although it expects a one-dimensional input for the single target\n",
    "variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n",
    "\n",
    "For categorical variables where no ordinal relationship exists, the integer encoding may not be\n",
    "enough or even misleading to the model. Forcing an ordinal relationship via an ordinal encoding\n",
    "and allowing the model to assume a natural ordering between categories may result in poor\n",
    "performance or unexpected results (predictions halfway between categories). In this case, a one\n",
    "hot encoding can be applied to the ordinal representation. This is where the integer encoded\n",
    "variable is removed and one new binary variable is added for each unique integer value in the\n",
    "variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of an one-hot encoding\n",
    "\n",
    "# Encode categorical features as a one-hot numeric array.\n",
    "\n",
    "# define data\n",
    "# Define a NumPy array named 'data' containing categorical data.\n",
    "# In this case, it's a list of color names, each as a single-element list (representing a feature for each sample).\n",
    "data = asarray([[\"red\"], [\"green\"], [\"blue\"]])\n",
    "# Print the original categorical data array.\n",
    "print(data)\n",
    "\n",
    "# define one-hot encoding\n",
    "# Initialize a OneHotEncoder object named 'encoder'.\n",
    "# sparse_output=False argument ensures that the output of the encoder will be a NumPy array, not a sparse matrix.\n",
    "# Sparse matrices are memory-efficient for high-dimensional data with many zeros, but for this example, a dense array is easier to understand.\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit OneHotEncoder to data, then transform data.\n",
    "# Fit the OneHotEncoder to the 'data' array. This learns the unique categories in each feature.\n",
    "# Then, transform the 'data' array into a one-hot encoded numerical array.\n",
    "onehot = encoder.fit_transform(data)\n",
    "# Print the resulting one-hot encoded array.\n",
    "# Each row now represents a sample, and each column represents a unique category.\n",
    "# A '1' indicates the presence of that category for the sample, and '0' indicates absence.\n",
    "print(onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the one-hot encoding\n",
    "matching our expectation of 3 binary variables in the order blue, green and red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Variable Encoding\n",
    "\n",
    "The one-hot encoding creates one binary variable for each category. The problem is that this\n",
    "representation includes redundancy. For example, if we know that `[1, 0, 0]` represents blue and\n",
    "`[0, 1, 0]` represents green we don't need another binary variable to represent red, instead we\n",
    "could use 0 values alone, e.g. `[0, 0]`. This is called a dummy variable encoding, and always\n",
    "represents `C` categories with `C - 1` binary variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the OneHotEncoder class to implement a dummy encoding as well as a one-hot\n",
    "encoding. The drop argument can be set to indicate which category will become the one that is\n",
    "assigned all zero values, called the baseline. We can set this to `firrst' so that the first category is\n",
    "used. When the labels are sorted alphabetically, the blue label will be the first and will become\n",
    "the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a dummy variable encoding\n",
    "\n",
    "# define data\n",
    "# Create a NumPy array named 'data' containing categorical strings: \"red\", \"green\", and \"blue\".\n",
    "# Each category is placed in its own row, creating a column vector-like structure.\n",
    "data = asarray([[\"red\"], [\"green\"], [\"blue\"]])\n",
    "# Print the original categorical data array to the console.\n",
    "print(data)\n",
    "\n",
    "# define one-hot encoding\n",
    "# Initialize the OneHotEncoder.\n",
    "# drop=\"first\":  Specifies to drop the first category in each feature to avoid multicollinearity in some models.\n",
    "#                If only one category is present for a feature, the feature will be dropped entirely.\n",
    "# sparse_output=False:  Sets the encoder to return a NumPy array instead of a sparse matrix.\n",
    "#                       Sparse matrices are efficient for datasets with many zeros, but arrays are often easier to work with directly.\n",
    "encoder = OneHotEncoder(drop=\"first\", sparse_output=False)\n",
    "\n",
    "# Fit OneHotEncoder to data, then transform data.\n",
    "# Fit the OneHotEncoder to the 'data' array.\n",
    "# 'fit' learns the unique categories present in the data.\n",
    "# 'transform' then applies the one-hot encoding to the data based on the learned categories.\n",
    "# 'fit_transform' combines both steps: it fits the encoder to the data and then transforms the data in a single step.\n",
    "onehot = encoder.fit_transform(data)\n",
    "# Print the resulting one-hot encoded array to the console.\n",
    "# Each category from the original data is now represented by a binary vector.\n",
    "print(onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `OrdinalEncoder` Transform\n",
    "\n",
    "An ordinal encoding involves mapping each unique label to an integer value. This type of\n",
    "encoding is really only appropriate if there is a known relationship between the categories. This\n",
    "relationship does exist for some of the variables in our dataset, and ideally, this should be\n",
    "harnessed when preparing the data. In this case, we will ignore any possible existing ordinal\n",
    "relationship and assume all variables are categorical. It can still be helpful to use an ordinal\n",
    "encoding, at least as a point of reference with other encoding schemes.\n",
    "We can use the `OrdinalEncoder` from scikit-learn to encode each variable to integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordinal Encode The Breast Cancer Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "# Load the dataset from a CSV file named 'breast_cancer_csv' into a pandas DataFrame.\n",
    "# 'header=None' indicates that the CSV file does not have a header row.\n",
    "dataset = read_csv(breast_cancer_csv, header=None)\n",
    "\n",
    "# retrieve the array of data\n",
    "# Retrieve the underlying NumPy array from the pandas DataFrame 'dataset'.\n",
    "# This converts the DataFrame into a numerical array for further processing.\n",
    "data = dataset.values\n",
    "\n",
    "# separate into input and output columns\n",
    "# Separate the dataset into input features (X) and the target variable (y).\n",
    "# X is assigned all columns except the last one (':-1').\n",
    "# y is assigned only the last column ('-1').\n",
    "# '.astype(str)' ensures that the data is treated as strings initially, which is important for ordinal encoding if the data is mixed type.\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)\n",
    "\n",
    "# ordinal encode input variables\n",
    "# Initialize an OrdinalEncoder object from scikit-learn.\n",
    "# Ordinal encoding converts categorical variables into numerical values, preserving the order if there is one.\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "# Fit the OrdinalEncoder to the input features X and then transform X.\n",
    "# 'fit_transform' learns the unique categories in each feature and replaces them with ordinal integers.\n",
    "X = ordinal_encoder.fit_transform(X)\n",
    "\n",
    "# ordinal encode target variable\n",
    "# Initialize a LabelEncoder object from scikit-learn.\n",
    "# Label encoding converts categorical labels into numerical values.\n",
    "label_encoder = LabelEncoder()\n",
    "# Fit the LabelEncoder to the target variable y and then transform y.\n",
    "# 'fit_transform' learns the unique labels in y and replaces them with integers starting from 0.\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# summarize the transformed data\n",
    "# Print a summary of the transformed input features X.\n",
    "# \"Input\", X.shape prints the string \"Input\" followed by the shape (number of rows and columns) of X.\n",
    "print(\"Input\", X.shape)\n",
    "# Print the first 5 rows and all columns of the transformed input features X.\n",
    "# X[:5, :] selects the first 5 rows and all columns.\n",
    "print(X[:5, :])\n",
    "# Print a summary of the transformed target variable y.\n",
    "# \"Output\", y.shape prints the string \"Output\" followed by the shape (number of elements) of y.\n",
    "print(\"Output\", y.shape)\n",
    "# Print the first 5 elements of the transformed target variable y.\n",
    "# y[:5] selects the first 5 elements of y.\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would expect the number of rows, and in this case, the number of columns, to be unchanged,\n",
    "except all string values are now integer values. As expected, in this case, we can see that the\n",
    "number of variables is unchanged, but all values are now ordinal encoded integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's evaluate machine learning on this dataset with this encoding. The best practice\n",
    "when encoding variables is to fit the encoding on the training dataset, then apply it to the train\n",
    "and test datasets. We will first split the dataset, then prepare the encoding on the training set,\n",
    "and apply it to the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression With Ordinal Encoding\n",
    "\n",
    "Next, we evaluate logistic regression on the breast cancer dataset with an ordinal encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset from a CSV file named 'breast_cancer_csv'.\n",
    "# 'header=None' indicates that the CSV file does not have a header row.\n",
    "dataset = read_csv(breast_cancer_csv, header=None)\n",
    "\n",
    "# retrieve the array of data from the pandas DataFrame.\n",
    "data = dataset.values\n",
    "\n",
    "# separate the data into input (X) and output (y) columns.\n",
    "# X is assigned all columns except the last one (features).\n",
    "# [:, :-1] selects all rows and all columns except the last one.\n",
    "# .astype(str) casts the input features to string type.\n",
    "X = data[:, :-1].astype(str)\n",
    "# y is assigned the last column (target variable).\n",
    "# [:, -1] selects all rows and only the last column.\n",
    "# .astype(str) casts the target variable to string type.\n",
    "y = data[:, -1].astype(str)\n",
    "\n",
    "# split the dataset into training and testing sets.\n",
    "# X_train, y_train will be used for training the model.\n",
    "# X_test, y_test will be used for evaluating the model's performance.\n",
    "# test_size=0.33 means 33% of the data will be used for testing, and 67% for training.\n",
    "# random_state=1 ensures that the split is reproducible.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=1\n",
    ")\n",
    "\n",
    "# initialize OrdinalEncoder to convert categorical input features to numerical.\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "# fit the OrdinalEncoder on the training input data to learn the categories.\n",
    "ordinal_encoder.fit(X_train)\n",
    "# transform the training input data using the fitted OrdinalEncoder.\n",
    "X_train = ordinal_encoder.transform(X_train)\n",
    "# transform the testing input data using the fitted OrdinalEncoder.\n",
    "X_test = ordinal_encoder.transform(X_test)\n",
    "\n",
    "# initialize LabelEncoder to convert categorical target variable to numerical labels.\n",
    "label_encoder = LabelEncoder()\n",
    "# fit the LabelEncoder on the training target variable to learn the unique classes.\n",
    "label_encoder.fit(y_train)\n",
    "# transform the training target variable into numerical labels using the fitted LabelEncoder.\n",
    "y_train = label_encoder.transform(y_train)\n",
    "# transform the testing target variable into numerical labels using the fitted LabelEncoder.\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# define the logistic regression model.\n",
    "model = LogisticRegression()\n",
    "\n",
    "# fit the logistic regression model to the training data.\n",
    "# X_train is the training input features, and y_train is the training target variable.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test set using the trained model.\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# evaluate the model's predictions by calculating the accuracy score.\n",
    "# accuracy_score compares the true labels (y_test) with the predicted labels (yhat).\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "# print the accuracy of the model in percentage format, rounded to two decimal places.\n",
    "print(\"Accuracy: %.2f\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the model achieved a classification accuracy of about 75.79 percent, which is a\n",
    "reasonable score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `OneHotEncoder` Transform\n",
    "\n",
    "A one-hot encoding is appropriate for categorical data where no relationship exists between\n",
    "categories. The scikit-learn library provides the OneHotEncoder class to automatically one-hot\n",
    "encode one or more variables. By default the `OneHotEncoder` will output data with a sparse\n",
    "representation, which is efficient given that most values are 0 in the encoded representation.\n",
    "We will disable this feature by setting the sparse argument to False so that we can review the\n",
    "effect of the encoding. Once defined, we can call the fit transform() function and pass it to\n",
    "our dataset to create a quantile transformed version of our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot Encode The Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from a CSV file named 'breast_cancer_csv' into a pandas DataFrame.\n",
    "# 'header=None' argument indicates that the CSV file does not have a header row.\n",
    "dataset = read_csv(breast_cancer_csv, header=None)\n",
    "\n",
    "# Retrieve the array of data from the pandas DataFrame.\n",
    "# '.values' attribute returns a NumPy array representation of the DataFrame.\n",
    "data = dataset.values\n",
    "\n",
    "# Separate the data into input (X) and output (y) columns.\n",
    "# 'data[:, :-1]' selects all rows and all columns except the last one for input features (X).\n",
    "# '.astype(str)' converts the input features to string type, which is often necessary before one-hot encoding.\n",
    "X = data[:, :-1].astype(str)\n",
    "# 'data[:, -1]' selects all rows and only the last column for the target variable (y).\n",
    "# '.astype(str)' converts the target variable to string type, which is suitable for label encoding.\n",
    "y = data[:, -1].astype(str)\n",
    "\n",
    "# One-hot encode the input variables (X).\n",
    "# Initialize OneHotEncoder with 'sparse_output=False' to return a dense NumPy array instead of a sparse matrix.\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "# Fit the OneHotEncoder to the input data X and then transform X into one-hot encoded features.\n",
    "# 'fit_transform' learns the unique categories in each feature and then transforms the data.\n",
    "X = onehot_encoder.fit_transform(X)\n",
    "\n",
    "# Ordinal encode the target variable (y). Although named 'LabelEncoder', it performs ordinal encoding for multiple classes.\n",
    "# Initialize LabelEncoder.\n",
    "label_encoder = LabelEncoder()\n",
    "# Fit the LabelEncoder to the target variable y and then transform y into label-encoded integers.\n",
    "# 'fit_transform' learns the unique classes in y and then transforms them into numerical labels.\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Summarize the transformed data.\n",
    "# Print the shape of the input data X after one-hot encoding.\n",
    "# 'X.shape' returns a tuple representing the dimensions of X (number of rows, number of columns).\n",
    "print(\"Input\", X.shape)\n",
    "# Print the first 5 rows and all columns of the transformed input data X.\n",
    "# 'X[:5, :]' selects the first 5 rows and all columns.\n",
    "print(X[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would expect the number of rows to remain the same, but the number of columns to\n",
    "dramatically increase. As expected, in this case, we can see that the number of variables has\n",
    "leaped up from 9 to 43 and all values are now binary values 0 or 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's evaluate machine learning on this dataset with this encoding as we did in the\n",
    "previous section. The encoding is fit on the training set then applied to both train and test sets\n",
    "as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression With One-Hot Encoding \n",
    "\n",
    "Next, we evaluate logistic regression on the breast cancer dataset with a one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "# Load the dataset from a CSV file named 'breast_cancer_csv' into a pandas DataFrame.\n",
    "# 'read_csv' function is assumed to be available (likely from pandas library).\n",
    "dataset = read_csv(breast_cancer_csv, header=None)\n",
    "\n",
    "# retrieve the array of data\n",
    "# Extract the values from the pandas DataFrame and convert it into a NumPy array.\n",
    "# This is often done to work with scikit-learn functions which often expect NumPy arrays.\n",
    "data = dataset.values\n",
    "\n",
    "# separate into input and output columns\n",
    "# Separate the dataset into input features (X) and the target variable (y).\n",
    "# X is assigned all columns except the last one ([:-1]), and y is assigned the last column ([-1]).\n",
    "# .astype(str) converts the data type to string, likely for handling categorical data before encoding.\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)\n",
    "\n",
    "# split the dataset into train and test sets\n",
    "# Split the dataset into training and testing sets using the train_test_split function.\n",
    "# X_train, y_train will be used for training the model.\n",
    "# X_test, y_test will be used for evaluating the model's performance on unseen data.\n",
    "# test_size=0.33 specifies that 33% of the data will be used for testing, and the rest for training.\n",
    "# random_state=1 ensures that the split is reproducible.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=1\n",
    ")\n",
    "\n",
    "# one-hot encode input variables\n",
    "# Initialize a OneHotEncoder object to perform one-hot encoding on categorical features.\n",
    "onehot_encoder = OneHotEncoder()\n",
    "# Fit the OneHotEncoder on the training input data (X_train).\n",
    "# This learns the categories to be encoded from the training set.\n",
    "onehot_encoder.fit(X_train)\n",
    "# Transform the training input data (X_train) using the fitted OneHotEncoder.\n",
    "# This converts categorical features into numerical one-hot encoded features.\n",
    "X_train = onehot_encoder.transform(X_train)\n",
    "# Transform the testing input data (X_test) using the fitted OneHotEncoder.\n",
    "# It's important to use the encoder fitted on the training data to ensure consistency.\n",
    "X_test = onehot_encoder.transform(X_test)\n",
    "\n",
    "# ordinal encode target variable\n",
    "# Initialize a LabelEncoder object to perform ordinal encoding on the target variable.\n",
    "# LabelEncoder is used here to convert string labels into numerical labels.\n",
    "label_encoder = LabelEncoder()\n",
    "# Fit the LabelEncoder on the training target variable (y_train).\n",
    "# This learns the unique classes in the training target.\n",
    "label_encoder.fit(y_train)\n",
    "# Transform the training target variable (y_train) using the fitted LabelEncoder.\n",
    "# This converts string labels in y_train to numerical labels.\n",
    "y_train = label_encoder.transform(y_train)\n",
    "# Transform the testing target variable (y_test) using the fitted LabelEncoder.\n",
    "# Use the same fitted encoder from training data for consistent encoding.\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# define the model\n",
    "# Define a Logistic Regression model.\n",
    "# Logistic Regression is a linear model used for binary and multiclass classification.\n",
    "model = LogisticRegression()\n",
    "\n",
    "# fit on the training set\n",
    "# Train the Logistic Regression model using the training data (X_train, y_train).\n",
    "# The model learns the relationship between the features and the target variable from the training data.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "# Use the trained Logistic Regression model to make predictions on the test input data (X_test).\n",
    "# yhat will contain the predicted class labels for the test set.\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# evaluate predictions\n",
    "# Evaluate the performance of the model by calculating the accuracy score.\n",
    "# accuracy_score function compares the true labels (y_test) with the predicted labels (yhat).\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "# Print the accuracy of the model in percentage format, rounded to two decimal places.\n",
    "print(\"Accuracy: %.2f\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the model achieved a classifcation accuracy of about 70.53 percent, which is\n",
    "worse than the ordinal encoding in the previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this module, we explored different techniques for encoding categorical data into numerical formats suitable for machine learning models.  Keep in mind that choice of encoding method can significantly impact model performance, and that some categorical variables may have natural relationships that should be considered when choosing encoding methods.\n",
    "\n",
    "## Clean up\n",
    "\n",
    "Remember to shut down your Jupyter Notebook environment and delete any unnecessary files or resources once you've completed the tutorial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
