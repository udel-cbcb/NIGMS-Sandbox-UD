{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Categorical Data\n",
    "\n",
    "Adapted from Jason Brownlee. 2020. [Data Preparation for Machine Learning](https://machinelearningmastery.com/data-preparation-for-machine-learning/).\n",
    "\n",
    "## Overview\n",
    "\n",
    "This module covers techniques for encoding categorical data into numerical formats for machine learning models. We'll explore different encoding methods including ordinal encoding, one-hot encoding, and dummy variable encoding using a breast cancer dataset as a practical example.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Learn why encoding is required for preprocessing categorical data in machine learning algorithms\n",
    "- Understand how to use ordinal encoding for categorical variables with natural rank ordering\n",
    "- Understand one-hot encoding techniques for categorical variables without natural rank ordering\n",
    "- Apply encoding techniques to real medical data for breast cancer prediction\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Basic understanding of Python programming\n",
    "- Familiarity with NumPy libraries\n",
    "- Knowledge of basic statistical concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Started\n",
    "\n",
    "To start, we install required packages, import the necessary libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the numpy, pandas, and scikit-learn Python libraries using pip.\n",
    "# numpy:  A fundamental package for numerical computation in Python. It provides support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays.\n",
    "# pandas: A powerful data manipulation and analysis library. It offers data structures like DataFrames for efficiently handling and analyzing structured data (tabular data, time series, etc.).\n",
    "# scikit-learn: A widely used machine learning library in Python. It provides simple and efficient tools for data mining and data analysis, including various classification, regression, clustering algorithms, model selection, and preprocessing tools.\n",
    "%pip install numpy pandas scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the 'asarray' function from the NumPy library.\n",
    "# This function is used to convert input to a NumPy array.\n",
    "from numpy import asarray\n",
    "\n",
    "# Import the 'read_csv' function from the pandas library.\n",
    "# This function is used to read data from a CSV file into a pandas DataFrame.\n",
    "from pandas import read_csv\n",
    "\n",
    "# Import the 'LogisticRegression' class from the scikit-learn library (sklearn).\n",
    "# This class is used to create a logistic regression model for classification tasks.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import the 'accuracy_score' function from the scikit-learn metrics module.\n",
    "# This function is used to calculate the accuracy of a classification model.\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Import the 'train_test_split' function from the scikit-learn model_selection module.\n",
    "# This function is used to split a dataset into training and testing sets.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import 'LabelEncoder', 'OneHotEncoder', and 'OrdinalEncoder' classes from scikit-learn preprocessing module.\n",
    "# These classes are used for encoding categorical variables into numerical representations.\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer Categorical Dataset\n",
    "\n",
    "Breast cancer dataset classifies breast cancer\n",
    "patient as either a recurrence or no recurrence of cancer. \n",
    "\n",
    "```\n",
    "Number of Instances: 286\n",
    "Number of Attributes: 9 + the class attribute\n",
    "Attribute Information:\n",
    "   1. Class: no-recurrence-events, recurrence-events\n",
    "   2. age: 10-19, 20-29, 30-39, 40-49, 50-59, 60-69, 70-79, 80-89, 90-99.\n",
    "   3. menopause: lt40, ge40, premeno.\n",
    "   4. tumor-size: 0-4, 5-9, 10-14, 15-19, 20-24, 25-29, 30-34, 35-39, 40-44, 45-49, 50-54, 55-59.\n",
    "   5. inv-nodes: 0-2, 3-5, 6-8, 9-11, 12-14, 15-17, 18-20, 21-23, 24-26, 27-29, 30-32, 33-35, 36-39.\n",
    "   6. node-caps: yes, no.\n",
    "   7. deg-malig: 1, 2, 3.\n",
    "   8. breast: left, right.\n",
    "   9. breast-quad: left-up, left-low, right-up,\tright-low, central.\n",
    "  10. irradiat:\tyes, no.\n",
    "Missing Attribute Values: (denoted by \"?\")\n",
    "   Attribute #:  Number of instances with missing values:\n",
    "   6.             8\n",
    "   9.             1.\n",
    "Class Distribution:\n",
    "    1. no-recurrence-events: 201 instances\n",
    "    2. recurrence-events: 85 instances \n",
    "```\n",
    "\n",
    "You can learn more about the dataset here:\n",
    "* Breast Cancer Dataset ([breast-cancer.csv](https://raw.githubusercontent.com/jbrownlee/Datasets/master/breast-cancer.csv))\n",
    "* Breast Cancer Dataset Description ([breast-cancer.names](https://raw.githubusercontent.com/jbrownlee/Datasets/master/breast-cancer.names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and summarize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a variable 'breast_cancer_csv' that stores the file path to the breast cancer dataset CSV file.\n",
    "# The file path is relative to the current script's location and points to a file named \"breast-cancer.csv\" in the \"../../Data/\" directory.\n",
    "breast_cancer_csv = \"../../Data/breast-cancer.csv\"\n",
    "\n",
    "# Load the dataset from the CSV file into a pandas DataFrame.\n",
    "# 'header=None' argument indicates that the CSV file does not have a header row.\n",
    "dataset = read_csv(breast_cancer_csv, header=None)\n",
    "\n",
    "# Print the first few rows of the DataFrame to inspect the loaded data.\n",
    "# 'dataset.head()' displays the first 5 rows by default, allowing for a quick data preview.\n",
    "print(dataset.head())\n",
    "\n",
    "# Retrieve the underlying NumPy array from the pandas DataFrame.\n",
    "# 'dataset.values' converts the DataFrame into a NumPy array for numerical operations and indexing.\n",
    "data = dataset.values\n",
    "\n",
    "# Separate the data into input features (X) and output labels (y).\n",
    "# 'data[:, :-1]' selects all rows (:) and all columns except the last one (:-1) as input features (X).\n",
    "# '.astype(str)' converts the input features to string type, assuming the features are meant to be strings.\n",
    "X = data[:, :-1].astype(str)\n",
    "\n",
    "# 'data[:, -1]' selects all rows (:) and only the last column (-1) as output labels (y).\n",
    "# '.astype(str)' converts the output labels to string type, assuming the labels are meant to be strings.\n",
    "y = data[:, -1].astype(str)\n",
    "\n",
    "# Summarize the shape of the input features (X) and output labels (y).\n",
    "# 'X.shape' returns a tuple representing the dimensions of the input feature array (rows, columns).\n",
    "# 'y.shape' returns a tuple representing the dimensions of the output label array (rows,).\n",
    "print(\"Input\", X.shape)\n",
    "print(\"Output\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We\n",
    "can see that we have 286 examples and nine input variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nominal and Ordinal Variables\n",
    "\n",
    "### Nominal Variable\n",
    "- A **nominal variable** consists of a finite set of discrete values with **no rank-order relationship** between them. Examples include categories like colors (e.g., red, blue, green) or types of fruit (e.g., apple, banana, orange).\n",
    "\n",
    "### Ordinal Variable\n",
    "- An **ordinal variable** consists of a finite set of discrete values with a **ranked ordering** between them. Examples include education levels (e.g., high school, bachelor’s, master’s) or survey ratings (e.g., poor, fair, good, excellent).\n",
    "\n",
    "\n",
    "### Handling Categorical Data in Machine Learning\n",
    "\n",
    "Some algorithms, such as **decision trees**, can work directly with categorical data without requiring any transformation. However, this depends on the specific implementation of the algorithm. Many machine learning algorithms, on the other hand, require all input and output variables to be **numeric**. This is often a constraint of the efficient implementation of these algorithms rather than a fundamental limitation of the algorithms themselves.\n",
    "\n",
    "\n",
    "### Converting Categorical Data to Numerical Form\n",
    "\n",
    "When working with algorithms that require numerical data, categorical variables must be converted into a numerical format. Common techniques include:\n",
    "- **Label Encoding**: Assigning a unique integer to each category.\n",
    "- **One-Hot Encoding**: Creating binary columns for each category.\n",
    "\n",
    "If the categorical variable is an **output variable**, you may also need to convert the model’s numerical predictions back into their original categorical form for interpretation or application purposes.\n",
    "them in some application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Data\n",
    "\n",
    "There are three common approaches for converting ordinal and categorical variables to numerical\n",
    "values. They are:\n",
    "* Ordinal Encoding\n",
    "* One-Hot Encoding\n",
    "* Dummy Variable Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal Encoding\n",
    "\n",
    "In **ordinal encoding**, each unique category value is assigned an integer value. This encoding is a natural fit for **ordinal variables**, where the categories have an inherent order or ranking (e.g., education levels: high school = 1, bachelor’s = 2, master’s = 3).\n",
    "\n",
    "However, for **nominal variables** (categories with no inherent order), using ordinal encoding can introduce an artificial ordinal relationship where none exists. This can mislead machine learning models by implying a false hierarchy or ranking among categories.\n",
    "\n",
    "To avoid this issue, **one-hot encoding** is often used for nominal variables. One-hot encoding creates binary columns for each category, ensuring that no unintended ordinal relationship is imposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of an ordinal encoding\n",
    "\n",
    "# Encode categorical features as an integer array\n",
    "\n",
    "# Define the categorical data as a NumPy array.\n",
    "# In this example, the data consists of color names: 'red', 'green', 'blue'.\n",
    "data = asarray([[\"red\"], [\"green\"], [\"blue\"]])\n",
    "\n",
    "# Print the original categorical data to show the input before encoding.\n",
    "print(\"Original data: \\n\", data)\n",
    "\n",
    "# Define the ordinal encoder.\n",
    "# OrdinalEncoder is used to convert categorical data into numerical ordinal data.\n",
    "# By default, it assigns numerical values based on the order it encounters categories.\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "# Fit OrdinalEncoder to the data and then transform the data.\n",
    "# .fit(data) learns the unique categories from the input data. In this case, it learns 'red', 'green', 'blue'.\n",
    "# .transform(data) then replaces each category in the data with its corresponding ordinal integer.\n",
    "result = encoder.fit_transform(data)\n",
    "\n",
    "# Print the encoded data to show the numerical representation after ordinal encoding.\n",
    "# The output will be a NumPy array where each color is replaced by an integer.\n",
    "print(\"Encoded data: \\n\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the numbers are assigned to the labels as expected, preserving the intended order for ordinal variables.\n",
    "\n",
    "The **OrdinalEncoder** class is designed for encoding input variables organized in a **matrix format** (rows and columns). It is particularly useful for transforming categorical features into numerical values while maintaining their ordinal relationships.\n",
    "\n",
    "For encoding a **categorical target variable** in classification problems, the **LabelEncoder** class is used. It performs a similar function to the `OrdinalEncoder`, but it is specifically tailored for **one-dimensional input**, such as a single target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n",
    "\n",
    "For **categorical variables** where no ordinal relationship exists, using an integer encoding can be insufficient or even misleading. Imposing an artificial ordinal relationship through ordinal encoding may cause the model to incorrectly assume a natural ordering between categories. This can lead to **poor performance** or **unexpected results**, such as predictions that fall between categories.\n",
    "\n",
    "To address this issue, **one-hot encoding** can be applied. In this approach:\n",
    "1. The integer-encoded variable is removed.\n",
    "2. A new **binary variable** is added for each unique integer value (category).\n",
    "3. Each binary variable indicates the presence (1) or absence (0) of a specific category.\n",
    "\n",
    "This ensures that no false ordinal relationship is introduced, allowing the model to interpret each category independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of an one-hot encoding\n",
    "\n",
    "# Encode categorical features as a one-hot numeric array.\n",
    "\n",
    "# Define data\n",
    "# Define a NumPy array named 'data' containing categorical data.\n",
    "# In this case, it's a list of color names, each as a single-element list (representing a feature for each sample).\n",
    "data = asarray([[\"red\"], [\"green\"], [\"blue\"]])\n",
    "# Print the original categorical data array.\n",
    "print(data)\n",
    "\n",
    "# Define one-hot encoding\n",
    "# Initialize a OneHotEncoder object named 'encoder'.\n",
    "# sparse_output=False argument ensures that the output of the encoder will be a NumPy array, not a sparse matrix.\n",
    "# Sparse matrices are memory-efficient for high-dimensional data with many zeros, but for this example, a dense array is easier to understand.\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit OneHotEncoder to data, then transform data.\n",
    "# Fit the OneHotEncoder to the 'data' array. This learns the unique categories in each feature.\n",
    "# Then, transform the 'data' array into a one-hot encoded numerical array.\n",
    "onehot = encoder.fit_transform(data)\n",
    "\n",
    "# Print the resulting one-hot encoded array.\n",
    "# Each row now represents a sample, and each column represents a unique category.\n",
    "# A '1' indicates the presence of that category for the sample, and '0' indicates absence.\n",
    "print(onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the one-hot encoding aligns with our expectations, creating **3 binary variables** corresponding to the categories: **blue**, **green**, and **red**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Variable Encoding\n",
    "\n",
    "One-hot encoding creates one binary variable for each category, but this representation includes **redundancy**. For example:\n",
    "- If `[1, 0, 0]` represents **blue** and `[0, 1, 0]` represents **green**, we don’t need a third binary variable to represent **red**. Instead, we can use `[0, 0]` to implicitly represent red.\n",
    "\n",
    "This simplified approach is called **dummy variable encoding**. It represents `C` categories using only `C - 1` binary variables, eliminating redundancy while retaining all necessary information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the **OneHotEncoder** class to implement both **one-hot encoding** and **dummy variable encoding**. The `drop` argument allows us to specify which category will serve as the **baseline** (assigned all zero values). For example, setting `drop='first'` ensures that the first category becomes the baseline.\n",
    "\n",
    "When the labels are sorted alphabetically, the **blue** label will appear first and will be used as the baseline. This approach reduces redundancy while maintaining the necessary information for encoding categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a dummy variable encoding\n",
    "\n",
    "# Define data\n",
    "# Create a NumPy array named 'data' containing categorical strings: \"red\", \"green\", and \"blue\".\n",
    "# Each category is placed in its own row, creating a column vector-like structure.\n",
    "data = asarray([[\"red\"], [\"green\"], [\"blue\"]])\n",
    "\n",
    "# Print the original categorical data array to the console.\n",
    "print(data)\n",
    "\n",
    "# Define one-hot encoding\n",
    "# Initialize the OneHotEncoder.\n",
    "# drop=\"first\":  Specifies to drop the first category in each feature to avoid multicollinearity in some models.\n",
    "#                If only one category is present for a feature, the feature will be dropped entirely.\n",
    "# sparse_output=False:  Sets the encoder to return a NumPy array instead of a sparse matrix.\n",
    "#                       Sparse matrices are efficient for datasets with many zeros, but arrays are often easier to work with directly.\n",
    "encoder = OneHotEncoder(drop=\"first\", sparse_output=False)\n",
    "\n",
    "# Fit OneHotEncoder to data, then transform data.\n",
    "# Fit the OneHotEncoder to the 'data' array.\n",
    "# 'fit' learns the unique categories present in the data.\n",
    "# 'transform' then applies the one-hot encoding to the data based on the learned categories.\n",
    "# 'fit_transform' combines both steps: it fits the encoder to the data and then transforms the data in a single step.\n",
    "onehot = encoder.fit_transform(data)\n",
    "\n",
    "# Print the resulting one-hot encoded array to the console.\n",
    "# Each category from the original data is now represented by a binary vector.\n",
    "print(onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `OrdinalEncoder` Transform\n",
    "\n",
    "**Ordinal encoding** involves mapping each unique label to an integer value. This encoding is most appropriate when there is a **known ordinal relationship** between the categories (e.g., low, medium, high). While some variables in our dataset may have such a relationship, we will assume all variables are **categorical** for this example, ignoring any inherent ordinal structure.\n",
    "\n",
    "Even in this case, using ordinal encoding can still be useful as a **baseline** or point of comparison with other encoding schemes. We can implement this using the `OrdinalEncoder` class from scikit-learn, which encodes each categorical variable into integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordinal Encode The Breast Cancer Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from a CSV file defined by a variable named 'breast_cancer_csv' into a pandas DataFrame.\n",
    "# 'header=None' indicates that the CSV file does not have a header row.\n",
    "dataset = read_csv(breast_cancer_csv, header=None)\n",
    "\n",
    "# Retrieve the underlying NumPy array from the pandas DataFrame 'dataset'.\n",
    "# This converts the DataFrame into a numerical array for further processing.\n",
    "data = dataset.values\n",
    "\n",
    "# Separate the dataset into input features (X) and the target variable (y).\n",
    "# X is assigned all columns except the last one (':-1').\n",
    "# y is assigned only the last column ('-1').\n",
    "# '.astype(str)' ensures that the data is treated as strings initially, which is important for ordinal encoding if the data is mixed type.\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)\n",
    "\n",
    "# Initialize an OrdinalEncoder object from scikit-learn.\n",
    "# Ordinal encoding converts categorical variables into numerical values, preserving the order if there is one.\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "# Fit the OrdinalEncoder to the input features X and then transform X.\n",
    "# 'fit_transform' learns the unique categories in each feature and replaces them with ordinal integers.\n",
    "X = ordinal_encoder.fit_transform(X)\n",
    "\n",
    "# Initialize a LabelEncoder object from scikit-learn.\n",
    "# Label encoding converts categorical labels into numerical values.\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the LabelEncoder to the target variable y and then transform y.\n",
    "# 'fit_transform' learns the unique labels in y and replaces them with integers starting from 0.\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Print a summary of the transformed input features X.\n",
    "# \"Input\", X.shape prints the string \"Input\" followed by the shape (number of rows and columns) of X.\n",
    "print(\"Input\", X.shape)\n",
    "\n",
    "# Print the first 5 rows and all columns of the transformed input features X.\n",
    "# X[:5, :] selects the first 5 rows and all columns.\n",
    "print(X[:5, :])\n",
    "\n",
    "# Print a summary of the transformed target variable y.\n",
    "# \"Output\", y.shape prints the string \"Output\" followed by the shape (number of elements) of y.\n",
    "print(\"Output\", y.shape)\n",
    "\n",
    "# Print the first 5 elements of the transformed target variable y.\n",
    "# y[:5] selects the first 5 elements of y.\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying the encoding, we would expect the **number of rows** and **number of columns** to remain unchanged. The only difference is that all **string values** are now replaced with **integer values**. As anticipated, we can see that the number of variables stays the same, but all categorical values have been transformed into ordinal-encoded integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's evaluate the performance of a machine learning model on this dataset using the applied encoding. A **best practice** when encoding variables is to:\n",
    "1. **Fit the encoding** on the training dataset.\n",
    "2. **Apply the encoding** to both the training and test datasets.\n",
    "\n",
    "To follow this approach, we will:\n",
    "1. **Split the dataset** into training and test sets.\n",
    "2. **Prepare the encoding** using only the training set.\n",
    "3. **Transform both the training and test sets** using the fitted encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression With Ordinal Encoding\n",
    "\n",
    "Next, we evaluate logistic regression on the breast cancer dataset with an ordinal encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from a CSV file defined by a variable named 'breast_cancer_csv'.\n",
    "# 'header=None' indicates that the CSV file does not have a header row.\n",
    "dataset = read_csv(breast_cancer_csv, header=None)\n",
    "\n",
    "# Retrieve the array of data from the pandas DataFrame.\n",
    "data = dataset.values\n",
    "\n",
    "# Separate the data into input (X) and output (y) columns.\n",
    "# X is assigned all columns except the last one (features).\n",
    "# [:, :-1] selects all rows and all columns except the last one.\n",
    "# .astype(str) casts the input features to string type.\n",
    "X = data[:, :-1].astype(str)\n",
    "\n",
    "# y is assigned the last column (target variable).\n",
    "# [:, -1] selects all rows and only the last column.\n",
    "# .astype(str) casts the target variable to string type.\n",
    "y = data[:, -1].astype(str)\n",
    "\n",
    "# Split the dataset into training and testing sets.\n",
    "# X_train, y_train will be used for training the model.\n",
    "# X_test, y_test will be used for evaluating the model's performance.\n",
    "# test_size=0.33 means 33% of the data will be used for testing, and 67% for training.\n",
    "# random_state=1 ensures that the split is reproducible.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=1\n",
    ")\n",
    "\n",
    "# Initialize OrdinalEncoder to convert categorical input features to numerical.\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "# Fit the OrdinalEncoder on the training input data to learn the categories.\n",
    "ordinal_encoder.fit(X_train)\n",
    "\n",
    "# Transform the training input data using the fitted OrdinalEncoder.\n",
    "X_train = ordinal_encoder.transform(X_train)\n",
    "\n",
    "# Transform the testing input data using the fitted OrdinalEncoder.\n",
    "X_test = ordinal_encoder.transform(X_test)\n",
    "\n",
    "# Initialize LabelEncoder to convert categorical target variable to numerical labels.\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the LabelEncoder on the training target variable to learn the unique classes.\n",
    "label_encoder.fit(y_train)\n",
    "\n",
    "# Transform the training target variable into numerical labels using the fitted LabelEncoder.\n",
    "y_train = label_encoder.transform(y_train)\n",
    "\n",
    "# Transform the testing target variable into numerical labels using the fitted LabelEncoder.\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Define the logistic regression model.\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fit the logistic regression model to the training data.\n",
    "# X_train is the training input features, and y_train is the training target variable.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using the trained model.\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's predictions by calculating the accuracy score.\n",
    "# accuracy_score compares the true labels (y_test) with the predicted labels (yhat).\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "\n",
    "# Print the accuracy of the model in percentage format, rounded to two decimal places.\n",
    "print(\"Accuracy: %.2f\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the model achieved a classification accuracy of about 75.79 percent, which is a\n",
    "reasonable score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `OneHotEncoder` Transform\n",
    "\n",
    "A **one-hot encoding** is suitable for categorical data where there is **no inherent relationship** between categories. The scikit-learn library provides the `OneHotEncoder` class to automatically perform one-hot encoding on one or more variables. \n",
    "\n",
    "By default, the `OneHotEncoder` outputs data in a **sparse representation**, which is memory-efficient since most values in the encoded representation are 0. For clarity, we will disable this feature by setting the `sparse` argument to `False`, allowing us to inspect the encoded data more easily.\n",
    "\n",
    "Once configured, we can apply the encoding by calling the `fit_transform()` function and passing our dataset to it. This creates a one-hot encoded version of the dataset, transforming categorical variables into binary columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot Encode The Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from a CSV file defined by a variable named 'breast_cancer_csv' into a pandas DataFrame.\n",
    "# 'header=None' argument indicates that the CSV file does not have a header row.\n",
    "dataset = read_csv(breast_cancer_csv, header=None)\n",
    "\n",
    "# Retrieve the array of data from the pandas DataFrame.\n",
    "# '.values' attribute returns a NumPy array representation of the DataFrame.\n",
    "data = dataset.values\n",
    "\n",
    "# Separate the data into input (X) and output (y) columns.\n",
    "# 'data[:, :-1]' selects all rows and all columns except the last one for input features (X).\n",
    "# '.astype(str)' converts the input features to string type, which is often necessary before one-hot encoding.\n",
    "X = data[:, :-1].astype(str)\n",
    "\n",
    "# 'data[:, -1]' selects all rows and only the last column for the target variable (y).\n",
    "# '.astype(str)' converts the target variable to string type, which is suitable for label encoding.\n",
    "y = data[:, -1].astype(str)\n",
    "\n",
    "# One-hot encode the input variables (X).\n",
    "# Initialize OneHotEncoder with 'sparse_output=False' to return a dense NumPy array instead of a sparse matrix.\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit the OneHotEncoder to the input data X and then transform X into one-hot encoded features.\n",
    "# 'fit_transform' learns the unique categories in each feature and then transforms the data.\n",
    "X = onehot_encoder.fit_transform(X)\n",
    "\n",
    "# Ordinal encode the target variable (y). Although named 'LabelEncoder', it performs ordinal encoding for multiple classes.\n",
    "# Initialize LabelEncoder.\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the LabelEncoder to the target variable y and then transform y into label-encoded integers.\n",
    "# 'fit_transform' learns the unique classes in y and then transforms them into numerical labels.\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Summarize the transformed data.\n",
    "# Print the shape of the input data X after one-hot encoding.\n",
    "# 'X.shape' returns a tuple representing the dimensions of X (number of rows, number of columns).\n",
    "print(\"Input\", X.shape)\n",
    "\n",
    "# Print the first 5 rows and all columns of the transformed input data X.\n",
    "# 'X[:5, :]' selects the first 5 rows and all columns.\n",
    "print(X[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying one-hot encoding, we would expect the **number of rows** to remain unchanged, but the **number of columns** to increase significantly. As anticipated, we can see that the number of variables has jumped from **9 to 43**, and all values are now binary (`0` or `1`).\n",
    "\n",
    "Next, let's evaluate the performance of a machine learning model on this encoded dataset, following the same process as in the previous section. The encoding is **fit on the training set** and then **applied to both the training and test sets**, ensuring consistency and avoiding data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression With One-Hot Encoding \n",
    "\n",
    "Next, we evaluate logistic regression on the breast cancer dataset with a one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from a CSV file defined by a variable named 'breast_cancer_csv' into a pandas DataFrame.\n",
    "# 'read_csv' function is assumed to be available (likely from pandas library).\n",
    "dataset = read_csv(breast_cancer_csv, header=None)\n",
    "\n",
    "# Extract the values from the pandas DataFrame and convert it into a NumPy array.\n",
    "# This is often done to work with scikit-learn functions which often expect NumPy arrays.\n",
    "data = dataset.values\n",
    "\n",
    "# Separate the dataset into input features (X) and the target variable (y).\n",
    "# X is assigned all columns except the last one ([:-1]), and y is assigned the last column ([-1]).\n",
    "# .astype(str) converts the data type to string, likely for handling categorical data before encoding.\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)\n",
    "\n",
    "# Split the dataset into training and testing sets using the train_test_split function.\n",
    "# X_train, y_train will be used for training the model.\n",
    "# X_test, y_test will be used for evaluating the model's performance on unseen data.\n",
    "# test_size=0.33 specifies that 33% of the data will be used for testing, and the rest for training.\n",
    "# random_state=1 ensures that the split is reproducible.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=1\n",
    ")\n",
    "\n",
    "# Initialize a OneHotEncoder object to perform one-hot encoding on categorical features.\n",
    "onehot_encoder = OneHotEncoder()\n",
    "\n",
    "# Fit the OneHotEncoder on the training input data (X_train).\n",
    "# This learns the categories to be encoded from the training set.\n",
    "onehot_encoder.fit(X_train)\n",
    "\n",
    "# Transform the training input data (X_train) using the fitted OneHotEncoder.\n",
    "# This converts categorical features into numerical one-hot encoded features.\n",
    "X_train = onehot_encoder.transform(X_train)\n",
    "\n",
    "# Transform the testing input data (X_test) using the fitted OneHotEncoder.\n",
    "# It's important to use the encoder fitted on the training data to ensure consistency.\n",
    "X_test = onehot_encoder.transform(X_test)\n",
    "\n",
    "# Initialize a LabelEncoder object to perform ordinal encoding on the target variable.\n",
    "# LabelEncoder is used here to convert string labels into numerical labels.\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the LabelEncoder on the training target variable (y_train).\n",
    "# This learns the unique classes in the training target.\n",
    "label_encoder.fit(y_train)\n",
    "\n",
    "# Transform the training target variable (y_train) using the fitted LabelEncoder.\n",
    "# This converts string labels in y_train to numerical labels.\n",
    "y_train = label_encoder.transform(y_train)\n",
    "\n",
    "# Transform the testing target variable (y_test) using the fitted LabelEncoder.\n",
    "# Use the same fitted encoder from training data for consistent encoding.\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Define a Logistic Regression model.\n",
    "# Logistic Regression is a linear model used for binary and multiclass classification.\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the Logistic Regression model using the training data (X_train, y_train).\n",
    "# The model learns the relationship between the features and the target variable from the training data.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained Logistic Regression model to make predictions on the test input data (X_test).\n",
    "# yhat will contain the predicted class labels for the test set.\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model by calculating the accuracy score.\n",
    "# accuracy_score function compares the true labels (y_test) with the predicted labels (yhat).\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "\n",
    "# Print the accuracy of the model in percentage format, rounded to two decimal places.\n",
    "print(\"Accuracy: %.2f\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the model achieved a classifcation accuracy of about 70.53 percent, which is\n",
    "worse than the ordinal encoding in the previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this module, we explored various techniques for **encoding categorical data** into numerical formats that are suitable for machine learning models. It’s important to remember that the choice of encoding method can **significantly impact model performance**. Additionally, some categorical variables may have **natural relationships** (e.g., ordinality) that should be taken into account when selecting the appropriate encoding method.\n",
    "\n",
    "## Clean up\n",
    "\n",
    "Remember to shut down your Jupyter Notebook environment and delete any unnecessary files or resources once you've completed the tutorial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
