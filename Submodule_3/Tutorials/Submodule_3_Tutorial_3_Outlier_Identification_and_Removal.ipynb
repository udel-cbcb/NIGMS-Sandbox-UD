{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Identification and Removal\n",
    "\n",
    "Adapted from Jason Brownlee. 2020. [Data Preparation for Machine Learning](https://machinelearningmastery.com/data-preparation-for-machine-learning/).\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial covers the identification and removal of outliers in datasets. We'll explore various techniques to detect and handle outliers, which are data points that significantly differ from other observations in a dataset.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Understand what outliers are and why they matter in data analysis\n",
    "- Learn different methods to identify outliers\n",
    "- Implement outlier removal techniques\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Basic understanding of Python programming\n",
    "- Familiarity with NumPy libraries\n",
    "- Knowledge of basic statistical concepts (mean, standard deviation, percentiles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Started\n",
    "\n",
    "To start, we install required packages, import the necessary libraries, and define a helper function to download data using the `requests` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib seaborn numpy pandas requests scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from numpy import percentile, random\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import LocalOutlierFactor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utility functions\n",
    "\n",
    "Define a helper function for downloading example datasets.  \n",
    "\n",
    "*Note!* It is not essential that you understand the following code.  It is just for getting the example data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url, to_file):\n",
    "    \"\"\"Download content from the given URL and save it to a file.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL to download the content from.\n",
    "        to_file (str): The name of the file to save the downloaded content to.\n",
    "\n",
    "    \"\"\"\n",
    "    response = requests.get(url, timeout=10)\n",
    "    Path(to_file).write_bytes(response.content)\n",
    "    print(f\"downloaded file '{to_file}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Identification and Removal\n",
    "\n",
    "### What are Outliers?\n",
    "\n",
    "An outlier is an observation that is unlike the other observations. They are rare, distinct, or do\n",
    "notâ€€fit in some way.\n",
    "\n",
    "We will generally define outliers as samples that are exceptionally far from the\n",
    "mainstream of the data.\n",
    "\n",
    "Outliers can have many causes, such as:\n",
    "\n",
    "- Measurement or input error.\n",
    "- Data corruption.\n",
    "- True outlier observation.\n",
    "\n",
    "There is no precise way to define and identify outliers in general because of the specifics of\n",
    "each dataset. Instead, you, or a domain expert, must interpret the raw observations and decide\n",
    "whether a value is an outlier or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers using Standard Deviation method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a dataset of random observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed the random number generator\n",
    "random.seed(1)\n",
    "\n",
    "# Generate univariate observations\n",
    "data = 5 * random.randn(10000) + 50\n",
    "\n",
    "# Summarize\n",
    "print(\"mean=%.3f stdv=%.3f\" % (np.mean(data), np.std(data)))\n",
    "\n",
    "# Plot the data\n",
    "sns.displot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary statistics\n",
    "data_mean, data_std = np.mean(data), np.std(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define outliers\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "\n",
    "# Identify outliers\n",
    "outliers = [x for x in data if x < lower or x > upper]\n",
    "print(\"Identified outliers: %d\" % len(outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify non-outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify non outliers\n",
    "non_outliers = [x for x in data if x >= lower and x <= upper]\n",
    "print(\"Non-outlier observations: %d\" % len(non_outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers using Interquartile Range method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a dataset of random observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed the random number generator\n",
    "random.seed(1)\n",
    "\n",
    "# Generate univariate observations\n",
    "data = 5 * random.randn(10000) + 50\n",
    "\n",
    "# Plot the data\n",
    "sns.displot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate interquartile range\n",
    "q25, q75 = percentile(data, 25), percentile(data, 75)\n",
    "iqr = q75 - q25\n",
    "print(\"Percentiles: 25th=%.3f, 75th=%.3f, IQR=%.3f\" % (q25, q75, iqr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the outlier cutoff\n",
    "cut_off = iqr * 1.5\n",
    "lower, upper = q25 - cut_off, q75 + cut_off\n",
    "\n",
    "# Identify outliers\n",
    "outliers = [x for x in data if x < lower or x > upper]\n",
    "print(\"Identified outliers: %d\" % len(outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify non-outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify non outliers\n",
    "non_outliers = [x for x in data if x >= lower and x <= upper]\n",
    "print(\"Non-outlier observations: %d\" % len(non_outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers using Automatic Outlier Detection method\n",
    "\n",
    "A simple approach to identifying outliers is to locate those examples that are far from the\n",
    "other examples in the multi-dimensional feature space. This can work well for feature spaces\n",
    "with low dimensionality (few features), although it can become less reliable as the number of\n",
    "features is increased, referred to as the **curse of dimensionality**. The local outlier factor, or\n",
    "LOF for short, is a technique that attempts to harness the idea of nearest neighbors for outlier\n",
    "detection. Each example is assigned a scoring of how isolated or how likely it is to be outliers\n",
    "based on the size of its local neighborhood. Those examples with the largest score are more\n",
    "likely to be outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diabetes Dataset\n",
    "\n",
    "The dataset classifies patient as\n",
    "either an onset of diabetes within five years or not. \n",
    "\n",
    "```\n",
    "Number of Instances: 768\n",
    "Number of Attributes: 8 plus class \n",
    "For Each Attribute: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)\n",
    "Missing Attribute Values: Yes\n",
    "Class Distribution: (class value 1 is interpreted as \"tested positive for\n",
    "   diabetes\")\n",
    "   Class Value  Number of instances\n",
    "   0            500\n",
    "   1            268\n",
    "```\n",
    "\n",
    "You can learn more about the dataset here:\n",
    "\n",
    "- Diabetes Dataset File ([pima-indians-diabetes.csv](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv))\n",
    "- Diabetes Dataset Details ([pima-indians-diabetes.names](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and summarize diabetes data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data\n",
    "download(\n",
    "  url=\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv\",\n",
    "  to_file=\"pima-indians-diabetes.csv\"\n",
    ")\n",
    "download(\n",
    "  url=\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names\",\n",
    "  to_file=\"pima-indians-diabetes.names\"\n",
    ")\n",
    "\n",
    "# Load and summarize the dataset\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"pima-indians-diabetes.csv\", header=None)\n",
    "\n",
    "# Retrieve the array\n",
    "data = df.values\n",
    "\n",
    "# Split into input and output elements\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "\n",
    "# Summarize the shape of the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split into train (70%) and test sets (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Summarize the shape of the train and test sets\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate module on raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# Evaluate predictions using mean absolute error\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print(\"MAE: %.3f\" % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove outliers from the data using Local Outlier Factor (LOF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can try removing outliers from the training dataset. The expectation is that the\n",
    "outliers are causing the linear regression model to learn a bias or skewed understanding of the\n",
    "problem, and that removing these outliers from the training set will allow a more effective model\n",
    "to be learned.\n",
    "\n",
    "The **Local Outlier Factor** (LOF) algorithm is an unsupervised anomaly detection method which computes the local density deviation of a given data point with respect to its neighbors. It considers as outliers the samples that have a substantially lower density than their neighbors. \n",
    "\n",
    "We can achieve this by defining the **LocalOutlierFactor** model and using it to\n",
    "make a prediction on the training dataset, marking each row in the training dataset as normal\n",
    "(1) or an outlier (-1). We will use the default hyperparameters for the outlier detection model,\n",
    "although it is a good idea to tune the configuration to the specifics of your dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsupervised anomaly detection method which computes the local density\n",
    "# deviation of a given data point with respect to its neighbors.  It considers\n",
    "# as outliers the samples that have a substantially lower density than their\n",
    "# neighbors.\n",
    "lof = LocalOutlierFactor()\n",
    "\n",
    "# Fit the model to the training set X and return the labels.\n",
    "yhat = lof.fit_predict(X_train)\n",
    "\n",
    "# Select all rows that are not outliers\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask, :], y_train[mask]\n",
    "\n",
    "# Summarize the shape of the updated training dataset\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "# Fit the model without outliers\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# Evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print(\"MAE: %.3f\" % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see MAE (Mean Absolute Error) reduced from to 0.324 to 0.317."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we've learned how to identify and remove outliers using various statistical methods. We've seen how outliers can affect data analysis and how their removal can lead to more accurate insights. Always to consider the context of your data when applying outlier removal techniques, as some apparent outliers may contain useful information.\n",
    "\n",
    "## Clean up\n",
    "\n",
    "Remember to shut down your Jupyter Notebook environment and delete any unnecessary files or resources once you've completed the tutorial."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
