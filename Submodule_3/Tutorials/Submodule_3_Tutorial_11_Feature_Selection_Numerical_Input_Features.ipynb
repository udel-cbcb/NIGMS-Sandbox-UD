{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection:  Select Numerical Input Features\n",
    "\n",
    "Adapted from Jason Brownlee. 2020. [Data Preparation for Machine Learning](https://machinelearningmastery.com/data-preparation-for-machine-learning/).\n",
    "\n",
    "## Overview\n",
    "\n",
    "Feature selection is the process of identifying and selecting a subset of input features that are\n",
    "most relevant to the target variable. Feature selection is often straightforward when working\n",
    "with real-valued input and output data, such as using the Pearson's correlation coefficient, but\n",
    "can be challenging when working with numerical input data and a categorical target variable.\n",
    "The two most commonly used feature selection methods for numerical input data when the\n",
    "target variable is categorical (e.g. classification predictive modeling) are the ANOVA F-test\n",
    "statistic and the mutual information statistic. \n",
    "\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Learn how to evaluate the importance of numerical features using ANOVA F-test statistics and mutual information statistics\n",
    "- Learn how to perform feature selection for numerical data when fitting and evaluating classification models\n",
    "- Learn how to tune and optimize feature selection parameters using grid search methods\n",
    "\n",
    "### Tasks to complete\n",
    "\n",
    "- Implement ANOVA F-test feature selection\n",
    "- Implement mutual information feature selection \n",
    "- Build and evaluate models using selected features\n",
    "- Tune feature selection parameters using grid search\n",
    "- Visualize feature selection results\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- A working Python environment and familiarity with Python\n",
    "- Basic understanding of machine learning concepts\n",
    "- Familiarity with pandas and numpy libraries\n",
    "- Knowledge of basic statistical concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Started\n",
    "\n",
    "To start, we install required packages and import the necessary libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the necessary libraries for data analysis and plotting\n",
    "# %pip is used to install packages in a Jupyter notebook cell\n",
    "# matplotlib: Library for creating static, animated, and interactive visualizations in Python\n",
    "# numpy: Fundamental package for scientific computing, handling arrays and numerical operations\n",
    "# pandas: Library for data manipulation and analysis, providing data structures like DataFrames\n",
    "# scikit-learn: A machine learning library for Python, providing simple and efficient tools for data mining and data analysis\n",
    "\n",
    "%pip install matplotlib numpy pandas scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for plotting, numerical operations, and machine learning\n",
    "from matplotlib import pyplot  # Import pyplot for creating visualizations\n",
    "from numpy import mean, std    # Import mean and std functions from numpy for statistical calculations\n",
    "from pandas import read_csv    # Import read_csv to load CSV files into pandas DataFrame\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif  # Import feature selection methods\n",
    "from sklearn.linear_model import LogisticRegression  # Import Logistic Regression model from sklearn\n",
    "from sklearn.metrics import accuracy_score  # Import accuracy_score to evaluate model performance\n",
    "from sklearn.model_selection import (  # Import model selection tools from sklearn\n",
    "    GridSearchCV,  # For hyperparameter tuning via grid search\n",
    "    RepeatedStratifiedKFold,  # For cross-validation with stratified splits\n",
    "    cross_val_score,  # For evaluating models using cross-validation\n",
    "    train_test_split,  # For splitting data into training and testing sets\n",
    ")\n",
    "from sklearn.pipeline import Pipeline  # Import Pipeline for chaining multiple steps together (e.g., preprocessing and model)\n",
    "\n",
    "# Path to the dataset file (Pima Indians Diabetes dataset)\n",
    "pima_indians_diabetes_csv = \"../../Data/pima-indians-diabetes.csv\"  # Set the path to the CSV dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes Dataset\n",
    "\n",
    "The dataset classifies patient data as\n",
    "either an onset of diabetes withinâ€€five years or not. \n",
    "\n",
    "```\n",
    "Number of Instances: 768\n",
    "Number of Attributes: 8 plus class \n",
    "For Each Attribute: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)\n",
    "Missing Attribute Values: Yes\n",
    "Class Distribution: (class value 1 is interpreted as \"tested positive for\n",
    "   diabetes\")\n",
    "   Class Value  Number of instances\n",
    "   0            500\n",
    "   1            268\n",
    "```\n",
    "\n",
    "You can learn more about the dataset here:\n",
    "\n",
    "* Diabetes Dataset File ([pima-indians-diabetes.csv](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv))\n",
    "* Diabetes Dataset Details ([pima-indians-diabetes.names](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and splitting Diabetes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and summarize the dataset\n",
    "\n",
    "# Function to load a dataset from a given file and split it into input and output variables\n",
    "def load_dataset(filename):\n",
    "    # Load the dataset as a pandas DataFrame from the specified file\n",
    "    dataset = read_csv(filename, header=None)  # Assumes the CSV has no header\n",
    "\n",
    "    # Retrieve the underlying numpy array from the DataFrame\n",
    "    data = dataset.values  # This gives us a 2D numpy array of the dataset\n",
    "\n",
    "    # Split the data into input variables (X) and output variables (y)\n",
    "    X = data[:, :-1]  # Select all rows, and all columns except the last one for input features\n",
    "    y = data[:, -1]   # Select all rows, but only the last column for the output variable\n",
    "\n",
    "    # Return the input and output variables\n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "# load the dataset\n",
    "X, y = load_dataset(pima_indians_diabetes_csv)\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=1\n",
    ")\n",
    "\n",
    "# summarize\n",
    "print(\"Train\", X_train.shape, y_train.shape)\n",
    "print(\"Test\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Feature Selection\n",
    "\n",
    "There are two popular feature selection techniques that can be used for numerical input data\n",
    "and a categorical (class) target variable. They are:\n",
    "\n",
    "* ANOVA F-Statistic.\n",
    "* Mutual Information Statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA F-test Feature Selection\n",
    "\n",
    "ANOVA is an acronym for analysis of variance and is a parametric statistical hypothesis test for\n",
    "determining whether the means from two or more samples of data (often three or more) come\n",
    "from the same distribution or not. An F-statistic, or F-test, is a class of statistical tests that\n",
    "calculate the ratio between variances values, such as the variance from two different samples or\n",
    "the explained and unexplained variance by a statistical test, like ANOVA. The ANOVA method\n",
    "is a type of F-statistic referred to here as an ANOVA F-test.\n",
    "\n",
    "Importantly, ANOVA is used when one variable is numeric and one is categorical, such as\n",
    "numerical input variables and categorical target variable in a classification task. The results\n",
    "of this test can be used for feature selection where those features that are independent of the\n",
    "target variable can be removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of anova f-test feature selection for numerical data\n",
    "\n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "    # load the dataset as a pandas DataFrame\n",
    "    dataset = read_csv(filename, header=None)\n",
    "\n",
    "    # retrieve numpy array\n",
    "    data = dataset.values\n",
    "\n",
    "    # split into input (X) and output (y) variables\n",
    "    X = data[:, :-1]\n",
    "    y = data[:, -1]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select all features\n",
    "    fs = SelectKBest(score_func=f_classif, k=\"all\")\n",
    "\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "\n",
    "# load the dataset\n",
    "X, y = load_dataset(pima_indians_diabetes_csv)\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=1\n",
    ")\n",
    "\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "\n",
    "# what are scores for the features\n",
    "for i in range(len(fs.scores_)):\n",
    "    print(\"Feature %d: %f\" % (i, fs.scores_[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we can see that some features stand out as perhaps being more relevant than\n",
    "others, with much larger test statistic values. Perhaps features 1, 5, and 7 are most relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the feature selection scores\n",
    "\n",
    "# 'fs.scores_' contains the scores (e.g., feature importance or relevance) for each feature\n",
    "# 'range(len(fs.scores_))' generates a list of positions (x-axis) for the bars, one for each feature\n",
    "# 'pyplot.bar' creates a bar plot where each bar corresponds to a feature's score\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)  # Create a bar plot of feature scores\n",
    "\n",
    "# Display the plot\n",
    "pyplot.show()  # Show the generated plot to the user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bar chart of the feature importance scores for each input feature is created. This clearly\n",
    "shows that feature 1 might be the most relevant (according to test statistic) and that perhaps\n",
    "six of the eight input features are the most relevant. We could set k=6 when configuring the\n",
    "SelectKBest to select these six features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information Feature Selection\n",
    "\n",
    "Mutual information from the field of information theory is the application of information gain\n",
    "(typically used in the construction of decision trees) to feature selection. Mutual information is\n",
    "calculated between two variables and measures the reduction in uncertainty for one variable given\n",
    "a known value of the other variable. Mutual information is straightforward when considering\n",
    "the distribution of two discrete (categorical or ordinal) variables, such as categorical input and\n",
    "categorical output data. Nevertheless, it can be adapted for use with numerical input and\n",
    "categorical output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of mutual information feature selection for numerical input data\n",
    "\n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "    # load the dataset as a pandas DataFrame\n",
    "    dataset = read_csv(filename, header=None)\n",
    "\n",
    "    # retrieve numpy array\n",
    "    data = dataset.values\n",
    "\n",
    "    # split into input (X) and output (y) variables\n",
    "    X = data[:, :-1]\n",
    "    y = data[:, -1]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select all features\n",
    "    fs = SelectKBest(score_func=mutual_info_classif, k=\"all\")\n",
    "\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "\n",
    "# load the dataset\n",
    "X, y = load_dataset(pima_indians_diabetes_csv)\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=1\n",
    ")\n",
    "\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "\n",
    "# what are scores for the features\n",
    "for i in range(len(fs.scores_)):\n",
    "    print(\"Feature %d: %f\" % (i, fs.scores_[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we can see that some of the features have a modestly low score, suggesting that\n",
    "perhaps they can be removed. Perhaps features 1 and 5 are most relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the feature selection scores\n",
    "\n",
    "# 'fs.scores_' contains the importance or score of each feature (e.g., in feature selection)\n",
    "# We create a bar plot where the x-axis represents the feature indices and the y-axis represents their scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)  # Create a bar plot with feature indices on the x-axis and feature scores on the y-axis\n",
    "\n",
    "# Display the plot to the user\n",
    "pyplot.show()  # Show the generated plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bar chart of the feature importance scores for each input feature is created. Importantly,\n",
    "a different mixture of features is promoted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling With Selected Features\n",
    "\n",
    "A robust approach is to evaluate models using different\n",
    "feature selection methods (and numbers of features) and select the method that results in a\n",
    "model with the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Built Using All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation of a model using all input features\n",
    "\n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "    # load the dataset as a pandas DataFrame\n",
    "    dataset = read_csv(filename, header=None)\n",
    "\n",
    "    # retrieve numpy array\n",
    "    data = dataset.values\n",
    "\n",
    "    # split into input (X) and output (y) variables\n",
    "    X = data[:, :-1]\n",
    "    y = data[:, -1]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# load the dataset\n",
    "X, y = load_dataset(pima_indians_diabetes_csv)\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=1\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "model = LogisticRegression(solver=\"liblinear\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print(\"Accuracy: %.2f\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we can see that the model achieves a classification accuracy of about 77 percent.\n",
    "We would prefer to use a subset of features that achieves a classification accuracy that is as\n",
    "good or better than this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Built Using ANOVA F-test Features\n",
    "\n",
    "We can use the ANOVA F-test to score the features and select the four most relevant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation of a model using 4 features chosen with anova f-test\n",
    "\n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "    # load the dataset as a pandas DataFrame\n",
    "    dataset = read_csv(filename, header=None)\n",
    "\n",
    "    # retrieve numpy array\n",
    "    data = dataset.values\n",
    "\n",
    "    # split into input (X) and output (y) variables\n",
    "    X = data[:, :-1]\n",
    "    y = data[:, -1]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select a subset of features\n",
    "    fs = SelectKBest(score_func=f_classif, k=4)\n",
    "\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "\n",
    "# load the dataset\n",
    "X, y = load_dataset(pima_indians_diabetes_csv)\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=1\n",
    ")\n",
    "\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "\n",
    "# fit the model\n",
    "model = LogisticRegression(solver=\"liblinear\")\n",
    "model.fit(X_train_fs, y_train)\n",
    "\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_fs)\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print(\"Accuracy: %.2f\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we see that the model achieved an accuracy of about 78.74 percent, a lift in\n",
    "performance compared to the baseline that achieved 77.56 percent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Built Using Mutual Information Features\n",
    "\n",
    "We can repeat the experiment and select the top four features using a mutual information\n",
    "statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation of a model using 4 features chosen with mutual information\n",
    "\n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "    # load the dataset as a pandas DataFrame\n",
    "    dataset = read_csv(filename, header=None)\n",
    "\n",
    "    # retrieve numpy array\n",
    "    data = dataset.values\n",
    "\n",
    "    # split into input (X) and output (y) variables\n",
    "    X = data[:, :-1]\n",
    "    y = data[:, -1]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select a subset of features\n",
    "    fs = SelectKBest(score_func=mutual_info_classif, k=4)  # mutual_info_classif()\n",
    "\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "\n",
    "# load the dataset\n",
    "X, y = load_dataset(pima_indians_diabetes_csv)\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=1\n",
    ")\n",
    "\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "\n",
    "# fit the model\n",
    "model = LogisticRegression(solver=\"liblinear\")\n",
    "model.fit(X_train_fs, y_train)\n",
    "\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test_fs)\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print(\"Accuracy: %.2f\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we can make no difference compared to the baseline model. This is interesting\n",
    "as we know the method chose a different four features compared to the previous method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune the Number of Selected Features\n",
    "\n",
    "Instead of guessing, we can systematically test a range\n",
    "of different numbers of selected features and discover which results in the best performing\n",
    "model. This is called a **grid search**, where the k argument to the SelectKBest class can be\n",
    "tuned. It is good practice to evaluate model configurations on classification tasks using repeated\n",
    "stratified k-fold cross-validation. We will use three repeats of 10-fold cross-validation via the\n",
    "RepeatedStratifiedKFold class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare different numbers of features selected using anova f-test\n",
    "\n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "    # load the dataset as a pandas DataFrame\n",
    "    dataset = read_csv(filename, header=None)\n",
    "\n",
    "    # retrieve numpy array\n",
    "    data = dataset.values\n",
    "\n",
    "    # split into input (X) and output (y) variables\n",
    "    X = data[:, :-1]\n",
    "    y = data[:, -1]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# define dataset\n",
    "X, y = load_dataset(pima_indians_diabetes_csv)\n",
    "\n",
    "# define the evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# define the pipeline to evaluate\n",
    "model = LogisticRegression(solver=\"liblinear\")\n",
    "fs = SelectKBest(score_func=f_classif)\n",
    "pipeline = Pipeline(steps=[(\"anova\", fs), (\"lr\", model)])\n",
    "\n",
    "# define the grid\n",
    "grid = dict()\n",
    "grid[\"anova__k\"] = [i + 1 for i in range(X.shape[1])]\n",
    "print(grid)\n",
    "\n",
    "# define the grid search\n",
    "\n",
    "# Exhaustive search over specified parameter values for an estimator.\n",
    "search = GridSearchCV(pipeline, grid, scoring=\"accuracy\", n_jobs=-1, cv=cv)\n",
    "\n",
    "# perform the search\n",
    "results = search.fit(X, y)\n",
    "\n",
    "# summarize best\n",
    "print(\"Best Mean Accuracy: %.3f\" % results.best_score_)\n",
    "print(\"Best Config: %s\" % results.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we can see that the best number of selected features is five; that achieves an\n",
    "accuracy of about 77 percent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might want to see the relationship between the number of selected features and classification accuracy. In this relationship, we may expect that more features result in a better\n",
    "performance to a point. This relationship can be explored by manually evaluating each configuration of **k** for the SelectKBest, gathering the sample of accuracy scores, and\n",
    "plotting the results using box and whisker plots side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare different numbers of features selected using anova f-test\n",
    "\n",
    "# load the dataset\n",
    "def load_dataset(filename):\n",
    "    # load the dataset as a pandas DataFrame\n",
    "    dataset = read_csv(filename, header=None)\n",
    "\n",
    "    # retrieve numpy array\n",
    "    data = dataset.values\n",
    "\n",
    "    # split into input (X) and output (y) variables\n",
    "    X = data[:, :-1]\n",
    "    y = data[:, -1]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring=\"accuracy\", cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "\n",
    "# define dataset\n",
    "X, y = load_dataset(pima_indians_diabetes_csv)\n",
    "\n",
    "# define number of features to evaluate\n",
    "num_features = [i + 1 for i in range(X.shape[1])]\n",
    "\n",
    "# enumerate each number of features\n",
    "results = list()\n",
    "for k in num_features:\n",
    "    # create pipeline\n",
    "    model = LogisticRegression(solver=\"liblinear\")\n",
    "    fs = SelectKBest(score_func=f_classif, k=k)\n",
    "    pipeline = Pipeline(steps=[(\"anova\", fs), (\"lr\", model)])\n",
    "\n",
    "    # evaluate the model\n",
    "    scores = evaluate_model(pipeline)\n",
    "    results.append(scores)\n",
    "\n",
    "    # summarize the results\n",
    "    print(\">%d %.3f (%.3f)\" % (k, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, it looks like selecting five or seven features results in roughly the same accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a boxplot to compare the performance of different models\n",
    "\n",
    "# 'results' contains the performance data for each model (e.g., accuracy scores, etc.)\n",
    "# 'num_features' represents the number of features used in the models, which will be used as labels on the x-axis\n",
    "# The 'boxplot' function creates the boxplot to visually compare the model performances\n",
    "# 'showmeans=True' will display the mean values in the boxplot\n",
    "pyplot.boxplot(results, labels=num_features, showmeans=True)\n",
    "\n",
    "# Display the plot\n",
    "pyplot.show()  # Show the generated plot to the user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "Through this tutorial, we learned how to perform feature selection on numerical data for classification tasks. We explored two key methods - ANOVA F-test and mutual information statistics - and learned how to evaluate their effectiveness through model performance. We also discovered how to systematically tune feature selection parameters using grid search to find the optimal number of features.\n",
    "\n",
    "## Clean up\n",
    "\n",
    "Remember to shut down your Jupyter Notebook environment and delete any unnecessary files or resources once you've completed the tutorial."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
