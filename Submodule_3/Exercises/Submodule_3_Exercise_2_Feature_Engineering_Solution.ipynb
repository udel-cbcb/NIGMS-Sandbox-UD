{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Exercise (Solution)\n",
    "\n",
    "Adapted from Dipanjan Sarkar et al. 2018. [Practical Machine Learning with Python](https://link.springer.com/book/10.1007/978-1-4842-3207-1).\n",
    "\n",
    "## Overview\n",
    "\n",
    "Feature engineering is a crucial step in developing effective Machine Learning systems, blending domain expertise with mathematical transformations. It focuses on processing diverse data types and variables, with each Machine Learning problem demanding tailored feature engineering strategies. This module explores techniques for engineering both **numeric** and **categorical** features.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Transform and engineer numeric features\n",
    "  - Apply raw measures and counts\n",
    "  - Implement binarization techniques\n",
    "  - Perform rounding operations\n",
    "  - Create feature interactions\n",
    "- Transform and engineer categorical features\n",
    "  - Convert nominal features to numeric representations\n",
    "  - Transform ordinal features with preserved ordering\n",
    "  - Apply encoding schemes for categorical data\n",
    "    - One Hot Encoding\n",
    "    - Dummy Coding\n",
    "\n",
    "### Tasks to complete\n",
    "\n",
    "- Implement numeric feature engineering techniques\n",
    "- Transform categorical variables\n",
    "- Apply various encoding schemes\n",
    "- Analyze transformed features\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python programming environment\n",
    "- Basic understanding of statistical and machine learning concepts\n",
    "- Familiarity with common ML libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Started\n",
    "\n",
    "- Please select kernel \"conda_python3\" from SageMaker notebook instance.\n",
    "\n",
    "### Import necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary dependencies\n",
    "\n",
    "# Matplotlib for plotting and visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NumPy for numerical operations and array manipulations\n",
    "import numpy as np\n",
    "\n",
    "# Pandas for data manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# SciPy statistical functions for advanced statistical analysis\n",
    "import scipy.stats as spstats\n",
    "\n",
    "# Scikit-learn preprocessing tools for data transformation\n",
    "from sklearn.preprocessing import (\n",
    "    Binarizer,           # Converts numerical values into binary (0 or 1) based on a threshold\n",
    "    LabelEncoder,        # Encodes categorical labels as integers (useful for classification tasks)\n",
    "    OneHotEncoder,       # Encodes categorical variables as one-hot (dummy) variables\n",
    "    PolynomialFeatures,  # Generates polynomial features for regression models\n",
    ")\n",
    "\n",
    "\n",
    "# Enable inline plotting in Jupyter Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Reload Matplotlib's style library to ensure the latest settings are applied\n",
    "mpl.style.reload_library()\n",
    "\n",
    "# Set the Matplotlib style to \"classic\" for a traditional look\n",
    "mpl.style.use(\"classic\")\n",
    "\n",
    "# Set the background color of figures to transparent (white with 0 alpha)\n",
    "mpl.rcParams[\"figure.facecolor\"] = (1, 1, 1, 0)\n",
    "\n",
    "# Define the default figure size as 6 inches by 4 inches\n",
    "mpl.rcParams[\"figure.figsize\"] = [6.0, 4.0]\n",
    "\n",
    "# Set the figure resolution to 100 dots per inch (DPI) for better clarity\n",
    "mpl.rcParams[\"figure.dpi\"] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering on Numeric Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although numeric data can be directly used as input for Machine Learning models, it is often necessary to engineer features that are relevant to the specific scenario, problem, and domain before building a model. This underscores the importance of feature engineering. Key considerations for numeric features include their **scale** and **distribution**. In some cases, transformations are required to adjust the scale of numeric values, while in others, the overall distribution may need to be modifiedâ€”for example, converting a skewed distribution into a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Measures\n",
    "\n",
    "Raw measures refer to the direct use of numeric variables as features without any transformation or engineering. These features typically represent values or counts in their original form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Values\n",
    "\n",
    "Scalar values in their raw form typically represent a specific measurement, metric, or observation associated with a particular variable or field. The meaning of the field is usually derived from its name or, if available, a data dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecoli Dataset\n",
    "\n",
    "Ecoli dataset is for predicting Protein Localization Sites in Ecoli.\n",
    "\n",
    "```\n",
    "Number of Instances:  336\n",
    "Number of Attributes: 8 ( 7 predictive, 1 name )\n",
    "Attribute Information.\n",
    "  1. Sequence Name: Accession number for the SWISS-PROT database\n",
    "  2. mcg: McGeoch's method for signal sequence recognition.\n",
    "  3. gvh: von Heijne's method for signal sequence recognition.\n",
    "  4. lip: von Heijne's Signal Peptidase II consensus sequence score (Binary attribute).\n",
    "  5. chg: Presence of charge on N-terminus of predicted lipoproteins (Binary attribute).\n",
    "  6. aac: score of discriminant analysis of the amino acid content of outer membrane and periplasmic proteins.\n",
    "  7. alm1: score of the ALOM membrane spanning region prediction program.\n",
    "  8. alm2: score of ALOM program after excluding putative cleavable signal regions from the sequence.\n",
    "Missing Attribute Values: None.\n",
    "Class Distribution. The class is the localization site.\n",
    "  cp  (cytoplasm)                                    143\n",
    "  im  (inner membrane without signal sequence)        77\n",
    "  pp  (perisplasm)                                    52\n",
    "  imU (inner membrane, uncleavable signal sequence)   35\n",
    "  om  (outer membrane)                                20\n",
    "  omL (outer membrane lipoprotein)                     5\n",
    "  imL (inner membrane lipoprotein)                     2\n",
    "  imS (inner membrane, cleavable signal sequence)      2\n",
    "```\n",
    "\n",
    "You can learn more about the dataset here:\n",
    "\n",
    "- Ecoli Dataset ([ecoli.csv](https://raw.githubusercontent.com/jbrownlee/Datasets/master/ecoli.data))\n",
    "- Ecoli Dataset Description ([ecoli.names](https://raw.githubusercontent.com/jbrownlee/Datasets/master/ecoli.names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path to the Ecoli dataset (relative path)\n",
    "ecoli_data = \"../../Data/ecoli.csv\"\n",
    "\n",
    "# Load the dataset into a Pandas DataFrame\n",
    "ecoli_df = pd.read_csv(ecoli_data)\n",
    "\n",
    "# Display the first 10 rows of the dataset to inspect its structure\n",
    "ecoli_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the selected feature columns (\"mcg\", \"gvh\", \"chg\") \n",
    "# from the ecoli dataset\n",
    "ecoli_df[[\"mcg\", \"gvh\", \"chg\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute basic statistical measures (count, mean, std, min, max, and quartiles)\n",
    "# for the numerical columns 'mcg', 'gvh', and 'chg' in the DataFrame 'ecoli_df'\n",
    "ecoli_df[[\"mcg\", \"gvh\", \"chg\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts\n",
    "\n",
    "Raw numeric measures can also represent counts, frequencies, or occurrences of specific attributes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes Dataset\n",
    "\n",
    "The dataset classifies patient data as\n",
    "either an onset of diabetes within five years or not.\n",
    "\n",
    "```\n",
    "Number of Instances: 768\n",
    "Number of Attributes: 8 plus class\n",
    "For Each Attribute: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)\n",
    "Missing Attribute Values: Yes\n",
    "Class Distribution: (class value 1 is interpreted as \"tested positive for\n",
    "   diabetes\")\n",
    "   Class Value  Number of instances\n",
    "   0            500\n",
    "   1            268\n",
    "```\n",
    "\n",
    "You can learn more about the dataset here:\n",
    "\n",
    "- Diabetes Dataset File ([pima-indians-diabetes.csv](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv))\n",
    "- Diabetes Dataset Details ([pima-indians-diabetes.names](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Diabetes dataset from a CSV file\n",
    "diabetes_data = \"../../Data/pima-indians-diabetes.csv\"\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame, specifying no header row (header=None)\n",
    "diabetes_df = pd.read_csv(diabetes_data, header=None)\n",
    "\n",
    "# Assign column names to the dataset for better readability\n",
    "diabetes_df.columns = [\n",
    "    \"pregnancy\",  # Number of times pregnant\n",
    "    \"glucose\",    # Plasma glucose concentration\n",
    "    \"bp\",         # Diastolic blood pressure (mm Hg)\n",
    "    \"triceps\",    # Triceps skinfold thickness (mm)\n",
    "    \"insulin\",    # 2-Hour serum insulin (mu U/ml)\n",
    "    \"bmi\",        # Body Mass Index (weight in kg/(height in m)^2)\n",
    "    \"pedigree\",   # Diabetes pedigree function (genetic risk factor)\n",
    "    \"age\",        # Age in years\n",
    "    \"diabetes\",   # Diabetes diagnosis (1 = positive, 0 = negative)\n",
    "]\n",
    "\n",
    "# Display the first 10 rows of the dataset\n",
    "diabetes_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarization\n",
    "\n",
    "If the focus is on identifying whether specific songs have been listened to (rather than the number of times they were played), a binary feature is more suitable than a count-based feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'age' column to a NumPy array for easier manipulation\n",
    "age = np.array(diabetes_df[\"age\"])\n",
    "\n",
    "# Create a copy of the 'age' array to store the binarized values\n",
    "old = np.array(diabetes_df[\"age\"])\n",
    "\n",
    "# Assign 1 to individuals older than 50\n",
    "old[age > 50] = 1\n",
    "\n",
    "# Assign 0 to individuals aged 50 or younger\n",
    "old[age <= 50] = 0\n",
    "\n",
    "# Add the binarized 'old' column back to the DataFrame\n",
    "diabetes_df[\"old\"] = old\n",
    "\n",
    "# Display the first 10 rows of the updated DataFrame\n",
    "diabetes_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize 'age' field using Binarizer\n",
    "# This transformation converts numerical values into binary (0 or 1) based on a given threshold.\n",
    "\n",
    "# Initialize the Binarizer with a threshold of 50\n",
    "# Any age value greater than 50 will be mapped to 1, while 50 and below will be mapped to 0.\n",
    "bn = Binarizer(threshold=50)\n",
    "\n",
    "# Apply the transformation on the 'age' column of the diabetes dataset\n",
    "# Note: `Binarizer.transform()` expects a 2D array, so we wrap the column inside a list.\n",
    "bn_old = bn.transform([diabetes_df[\"age\"]])[0]  \n",
    "\n",
    "# Store the binarized values in a new column 'bn_old' in the DataFrame\n",
    "diabetes_df[\"bn_old\"] = bn_old\n",
    "\n",
    "# Display the first 10 rows of the updated DataFrame to verify the transformation\n",
    "diabetes_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rounding\n",
    "\n",
    "When working with numeric attributes such as proportions or percentages, high precision is often unnecessary. In such cases, it is practical to round these values to whole numbers. These rounded integers can then be used directly as raw numeric values or even as categorical (discrete class-based) features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'pedigree_scale_10' by multiplying the 'pedigree' column by 10 \n",
    "# and rounding the values to the nearest integer, then converting them to integers\n",
    "diabetes_df[\"pedigree_scale_10\"] = np.array(\n",
    "    np.round((diabetes_df[\"pedigree\"] * 10)), dtype=\"int\"\n",
    ")\n",
    "\n",
    "# Create a new column 'pedigree_scale_100' by multiplying the 'pedigree' column by 100 \n",
    "# and rounding the values to the nearest integer, then converting them to integers\n",
    "diabetes_df[\"pedigree_scale_100\"] = np.array(\n",
    "    np.round((diabetes_df[\"pedigree\"] * 100)), dtype=\"int\"\n",
    ")\n",
    "\n",
    "# Display the updated DataFrame\n",
    "diabetes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactions\n",
    "\n",
    "In real-world datasets and scenarios, it is often beneficial to capture interactions between feature variables and include them as part of the input feature set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the \"gvh\" (global protein localization) and \"lip\" (lipoprotein signal) columns from the ecoli_df DataFrame\n",
    "gvh_lip = ecoli_df[[\"gvh\", \"lip\"]]\n",
    "\n",
    "# Display the first 5 rows of the selected subset to inspect the data\n",
    "gvh_lip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of PolynomialFeatures with the following parameters:\n",
    "# degree=2: Generate features up to the second degree (squared features and interactions).\n",
    "# interaction_only=False: Allow both interaction terms (e.g., feature1*feature2) and polynomial terms (e.g., feature1^2).\n",
    "# include_bias=False: Exclude the bias column (column of ones) that represents the intercept term.\n",
    "pf = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "\n",
    "# Fit the PolynomialFeatures transformer on the dataset (gvh_lip) and then transform it.\n",
    "# This will generate new features that are combinations of the original features up to the specified degree.\n",
    "res = pf.fit_transform(gvh_lip)\n",
    "\n",
    "# Output the transformed feature set (the original features and their polynomial interactions).\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of five features including the new interaction\n",
    "features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the degree of each feature in the matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pf.powers_ attribute to a Pandas DataFrame\n",
    "# 'pf.powers_' is assumed to be a NumPy array or similar structure containing power values.\n",
    "# The columns are labeled as 'gvh_degree' and 'lip_degree' for clarity.\n",
    "pd.DataFrame(pf.powers_, columns=[\"gvh_degree\", \"lip_degree\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what each feature actually represented from the degrees depicted, we can assign a\n",
    "name to each feature as follows to get the updated feature set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the list 'res' with specific column names\n",
    "intr_features = pd.DataFrame(res, columns=[\"gvh\", \"lip\", \"gvh^2\", \"gvh x lip\", \"lip^2\"])\n",
    "\n",
    "# Display the first 5 rows of the DataFrame to preview the data\n",
    "intr_features.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming new data in the future (during predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame containing sample observations for 'gvh' (attack) and 'lip' (defense)\n",
    "# Each row represents a new PokÃ©mon's features (attack and defense)\n",
    "new_df = pd.DataFrame(\n",
    "    [[0.35, 0.49], [0.46, 0.38], [0.25, 0.48]],  # Sample feature values for 3 new PokÃ©mon\n",
    "    columns=[\"gvh\", \"lip\"]  # Define column names as 'gvh' (attack) and 'lip' (defense)\n",
    ")\n",
    "\n",
    "# Display the newly created DataFrame\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the pf object that we created earlier to transform the input features \n",
    "# and generate interaction features from the new data (new_df).\n",
    "new_res = pf.transform(new_df)\n",
    "\n",
    "# Convert the resulting interaction features (new_res) into a DataFrame \n",
    "# with column names representing the specific interaction terms and transformations.\n",
    "new_intr_features = pd.DataFrame(\n",
    "    new_res,  # The transformed features\n",
    "    columns=[\"gvh\", \"lip\", \"gvh^2\", \"gvh x lip\", \"lip^2\"]  # Assigning column names to the features\n",
    ")\n",
    "\n",
    "# Output the DataFrame containing the new interaction features\n",
    "new_intr_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering on Categorical Data\n",
    "\n",
    "Any categorical attribute or feature represents discrete values that fall within a specific, finite set of categories or classes. These category or class labels can be either text or numeric. Categorical variables are typically divided into two types: **nominal** and **ordinal**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Nominal Features\n",
    "\n",
    "Nominal features or attributes are categorical variables with a finite set of distinct discrete values. These values are often represented as strings or text, which Machine Learning algorithms cannot process directly. As a result, it is usually necessary to transform these features into a numeric format that algorithms can interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 11 rows of the dataframe 'ecoli_df'\n",
    "ecoli_df.head(11)  # This will show the first 11 entries in the dataframe, including column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset depicted in this dataframe shows us various attributes pertaining to video games. Features\n",
    "like Platform, Genre, and Publisher are nominal categorical variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique values from the \"site\" column in the ecoli_df DataFrame\n",
    "sites = np.unique(ecoli_df[\"site\"])\n",
    "\n",
    "# Display the unique site values\n",
    "sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output tells us we have 8 distinct sites in Ecoli dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LabelEncoder\n",
    "sle = LabelEncoder()\n",
    "\n",
    "# Encode the 'site' column in ecoli_df, converting categorical values into numeric labels\n",
    "site_labels = sle.fit_transform(ecoli_df[\"site\"])\n",
    "\n",
    "# Create a dictionary mapping each numeric label back to its original category\n",
    "site_mappings = {index: label for index, label in enumerate(sle.classes_)}\n",
    "\n",
    "# Display the mapping of encoded values to original categories\n",
    "site_mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mapping scheme has been generated where each site value is\n",
    "mapped to a number with the help of the LabelEncoder object sle. The transformed labels are stored in the\n",
    "site_labels value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the list/array 'site_labels' to a new column 'siteLabel' in the dataframe 'ecoli_df'\n",
    "ecoli_df[\"siteLabel\"] = site_labels  \n",
    "\n",
    "# Display the first 11 rows of the dataframe to check the assigned labels\n",
    "ecoli_df.head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SiteLabel field shows the mapped numeric labels for each of the site labels and we can clearly\n",
    "see that this adheres to the mappings that we generated earlier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Ordinal Features\n",
    "\n",
    "Ordinal features are similar to nominal features, but with one key difference: the order of values matters and is an inherent property that provides meaning to these features. Like nominal features, ordinal features may also be represented as text, requiring transformation into a numeric format for Machine Learning algorithms to interpret them effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Generation based on 'age'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the \"age\" column of the diabetes dataframe to a NumPy array\n",
    "age = np.array(diabetes_df[\"age\"])\n",
    "\n",
    "# Create a new column \"Generation\" based on age groups using a lambda function\n",
    "diabetes_df[\"Generation\"] = diabetes_df[\"age\"].apply(\n",
    "    lambda value: (\n",
    "        \"Gen Z\" if value <= 25  # Ages 25 and below belong to Generation Z\n",
    "        else (\n",
    "            \"Millennials\" if value <= 41  # Ages 26-41 belong to Millennials\n",
    "            else (\n",
    "                \"Gen X\" if value <= 57  # Ages 42-57 belong to Generation X\n",
    "                else (\n",
    "                    \"Boomers II\" if value <= 67  # Ages 58-67 belong to Boomers II\n",
    "                    else (\n",
    "                        \"Boomers I\" if value <= 76  # Ages 68-76 belong to Boomers I\n",
    "                        else (\n",
    "                            \"Post WWII\" if value <= 94  # Ages 77-94 belong to Post-WWII generation\n",
    "                            else \"WWII\"  # Ages 95+ belong to WWII generation\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the first 10 rows of the \"age\" and \"Generation\" columns\n",
    "diabetes_df[[\"age\", \"Generation\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values from the \"Generation\" column of the diabetes_df DataFrame\n",
    "unique_generations = np.unique(diabetes_df[\"Generation\"])\n",
    "\n",
    "# Display the unique generation values\n",
    "print(unique_generations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this output, we can observe that there are six distinct generations of people. This attribute is clearly ordinal, as the generations have a natural sense of order.\n",
    "\n",
    "However, there is no built-in module or function to automatically map and transform these features into numeric representations. As a result, we need to manually implement this transformation using custom logic, as shown in the following code snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to map generation labels to ordinal values\n",
    "gen_ord_map = {\n",
    "    \"Gen Z\": 1,         # Youngest generation in the dataset\n",
    "    \"Millennials\": 2,   # Followed by Millennials\n",
    "    \"Gen X\": 3,         # Middle-aged generation\n",
    "    \"Boomers II\": 4,    # Late Boomers\n",
    "    \"Boomers I\": 5,     # Early Boomers\n",
    "    \"Post WWII\": 6,     # Oldest generation in the dataset\n",
    "}\n",
    "\n",
    "# Map the 'Generation' column in the diabetes dataset to corresponding ordinal values\n",
    "diabetes_df[\"GenerationLabel\"] = diabetes_df[\"Generation\"].map(gen_ord_map)\n",
    "\n",
    "# Display selected columns (age, original generation label, and mapped generation label)\n",
    "# for rows 4 to 9 (since slicing is exclusive of the end index)\n",
    "diabetes_df[[\"age\", \"Generation\", \"GenerationLabel\"]].iloc[4:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create BMI Class based on 'bmi'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'bmi' column from the diabetes DataFrame and store it as a numpy array\n",
    "bmi = np.array(diabetes_df[\"bmi\"])\n",
    "\n",
    "# Create a new 'BMI' column in the dataframe by applying a function to the 'bmi' values\n",
    "diabetes_df[\"BMI\"] = diabetes_df[\"bmi\"].apply(\n",
    "    lambda value: (\n",
    "        \"Underweight\"  # If the BMI is less than or equal to 18.5, classify as Underweight\n",
    "        if value <= 18.5\n",
    "        else (\n",
    "            \"Normal\"  # If BMI is between 18.6 and 22.9, classify as Normal\n",
    "            if value <= 22.9\n",
    "            else (\n",
    "                \"Pre-obese\"  # If BMI is between 23 and 24.9, classify as Pre-obese\n",
    "                if value <= 24.9\n",
    "                else (\n",
    "                    \"Class I obesity\"  # If BMI is between 25 and 29.9, classify as Class I obesity\n",
    "                    if value <= 29.9\n",
    "                    else \"Class II obesity\"  # If BMI is between 30 and 34.9, classify as Class II obesity\n",
    "                    if value <= 34.9 \n",
    "                    else \"Class II obesity\"  # If BMI is greater than 35, classify as Class II obesity\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the first 10 rows of 'bmi' and the newly created 'BMI' column for review\n",
    "diabetes_df[[\"bmi\", \"BMI\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique values in the 'BMI' column of the diabetes_df DataFrame\n",
    "# 'diabetes_df[\"BMI\"]' selects the BMI column from the dataframe\n",
    "# np.unique() returns the sorted unique values in the specified array\n",
    "unique_bmi_values = np.unique(diabetes_df[\"BMI\"])\n",
    "\n",
    "# Output the unique BMI values\n",
    "print(unique_bmi_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this output, we can observe that there are five distinct BMI classes. This attribute is clearly ordinal, as the classes follow a natural order.\n",
    "\n",
    "However, there is no built-in module or function to automatically map and transform these features into numeric representations. As a result, we need to manually implement this transformation using custom logic, as shown in the following code snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping BMI categories to ordinal values\n",
    "bmi_ord_map = {\n",
    "    \"Underweight\": 1,       # \"Underweight\" corresponds to 1\n",
    "    \"Normal\": 2,            # \"Normal\" corresponds to 2\n",
    "    \"Pre-obese\": 3,         # \"Pre-obese\" corresponds to 3\n",
    "    \"Class I obesity\": 4,   # \"Class I obesity\" corresponds to 4\n",
    "    \"Class II obesity\": 5,  # \"Class II obesity\" corresponds to 5\n",
    "}\n",
    "\n",
    "# Map the 'BMI' column in diabetes_df to its corresponding ordinal value using the bmi_ord_map dictionary\n",
    "diabetes_df[\"BMILabel\"] = diabetes_df[\"BMI\"].map(bmi_ord_map)\n",
    "\n",
    "# Display a subset of the dataframe (rows 4 to 9) showing 'bmi', 'BMI', and 'BMILabel' columns\n",
    "diabetes_df[[\"bmi\", \"BMI\", \"BMILabel\"]].iloc[4:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this output, we can observe that there are six distinct generations of PokÃ©mon. This attribute is clearly ordinal, as PokÃ©mon from Generation 1 were introduced earlier in the video games and television shows compared to Generation 2, and so on. This establishes a natural order among the generations.\n",
    "\n",
    "However, there is no built-in module or function to automatically map and transform these features into numeric representations. As a result, we need to manually implement this transformation using custom logic, as shown in the following code snippet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Features\n",
    "\n",
    "If we directly feed these transformed numeric representations of categorical features into an algorithm, the model will interpret them as raw numeric features. This introduces an incorrect notion of magnitude, as the numeric values do not inherently carry meaningful order or scale.\n",
    "\n",
    "As a result, models built using these features directly would be suboptimal and inaccurate. To address this, several strategies exist for creating dummy features, where each unique value or label from the distinct categories is represented separately. In the following sections, we will explore some of these strategies, including **one-hot encoding**, **dummy coding**, **effect coding**, and **feature hashing schemes**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding Scheme\n",
    "\n",
    "For a categorical feature with **m** unique labels, the one-hot encoding scheme transforms the feature into **m** binary features, each of which can only take a value of **1** or **0**. Each observation in the categorical feature is converted into a vector of size **m**, where only one element is **1** (indicating the active category) and the rest are **0**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subset of the DataFrame 'diabetes_df' with specific columns\n",
    "# - 'diabetes': The target variable indicating if the person has diabetes (e.g., 1 or 0)\n",
    "# - 'Generation': A categorical variable representing the generation group (e.g., Gen X, Millennial)\n",
    "# - 'BMI': A numerical variable for Body Mass Index (BMI)\n",
    "\n",
    "# Use 'iloc' to filter rows between index 4 and 9 (remember, Python is 0-indexed, so row 4 is included, row 10 is excluded)\n",
    "diabetes_df[[\"diabetes\", \"Generation\", \"BMI\"]].iloc[4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LabelEncoder for \"Generation\"\n",
    "gen_le = LabelEncoder()\n",
    "\n",
    "# Fit the LabelEncoder on the \"Generation\" column and transform it into numerical labels\n",
    "gen_labels = gen_le.fit_transform(diabetes_df[\"Generation\"])\n",
    "\n",
    "# Add the transformed \"Generation\" labels as a new column in the dataframe\n",
    "diabetes_df[\"Gen_Label\"] = gen_labels\n",
    "\n",
    "# Initialize the LabelEncoder for \"BMI\"\n",
    "bmi_le = LabelEncoder()\n",
    "\n",
    "# Fit the LabelEncoder on the \"BMI\" column and transform it into numerical labels\n",
    "bmi_labels = bmi_le.fit_transform(diabetes_df[\"BMI\"])\n",
    "\n",
    "# Add the transformed \"BMI\" labels as a new column in the dataframe\n",
    "diabetes_df[\"BMI_Label\"] = bmi_labels\n",
    "\n",
    "# Create a new dataframe subset with only relevant columns: \n",
    "# \"diabetes\" (target variable), \"Generation\", \"Gen_Label\", \"BMI\", and \"BMI_Label\"\n",
    "diabetes_df_sub = diabetes_df[\n",
    "    [\"diabetes\", \"Generation\", \"Gen_Label\", \"BMI\", \"BMI_Label\"]\n",
    "]\n",
    "\n",
    "# Display rows 4 to 9 (5th to 10th) from the new dataframe subset\n",
    "diabetes_df_sub.iloc[4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode generation labels using one-hot encoding scheme\n",
    "gen_ohe = OneHotEncoder()  # Initialize the OneHotEncoder for 'Gen_Label'\n",
    "gen_feature_arr = gen_ohe.fit_transform(diabetes_df[[\"Gen_Label\"]]).toarray()  \n",
    "# Apply the encoder to the \"Gen_Label\" column and convert the result into an array\n",
    "gen_feature_labels = list(gen_ohe.categories_[0])  \n",
    "# Extract the unique categories from the 'Gen_Label' encoding and convert to a list\n",
    "gen_features = pd.DataFrame(gen_feature_arr, columns=gen_feature_labels)  \n",
    "# Create a DataFrame with the encoded features, with the appropriate column labels\n",
    "\n",
    "# Encode BMI labels using one-hot encoding scheme\n",
    "bmi_ohe = OneHotEncoder()  # Initialize the OneHotEncoder for 'BMI_Label'\n",
    "bmi_feature_arr = bmi_ohe.fit_transform(diabetes_df[[\"BMI_Label\"]]).toarray()  \n",
    "# Apply the encoder to the \"BMI_Label\" column and convert the result into an array\n",
    "bmi_feature_labels = [\"BMI_\" + str(cls_label) for cls_label in bmi_ohe.categories_[0]]  \n",
    "# Create BMI feature labels by prepending \"BMI_\" to the class labels of the BMI categories\n",
    "bmi_features = pd.DataFrame(bmi_feature_arr, columns=bmi_feature_labels)  \n",
    "# Create a DataFrame with the encoded BMI features, with the appropriate column labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the dataframes: diabetes_df_sub, gen_features, and bmi_features along columns (axis=1)\n",
    "# This will combine the features from these different sources into a single dataframe\n",
    "diabetes_df_ohe = pd.concat([diabetes_df_sub, gen_features, bmi_features], axis=1)\n",
    "\n",
    "# Create the column names list by combining predefined column labels and the feature labels\n",
    "# \"diabetes\", \"Generation\", and \"Gen_Label\" are predefined columns\n",
    "# gen_feature_labels and bmi_feature_labels are dynamically created lists based on features\n",
    "columns = sum(\n",
    "    [\n",
    "        [\"diabetes\", \"Generation\", \"Gen_Label\"],  # Predefined column names\n",
    "        gen_feature_labels,  # Feature labels for genetic data\n",
    "        [\"BMI\", \"BMI_Label\"],  # Predefined BMI-related column names\n",
    "        bmi_feature_labels,  # Feature labels for BMI-related data\n",
    "    ],\n",
    "    [],  # Flatten the list of lists into a single list\n",
    ")\n",
    "\n",
    "# Display a slice (rows 4 to 9) of the concatenated dataframe with the newly created columns\n",
    "diabetes_df_ohe[columns].iloc[4:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly observe the new one-hot encoded features for **Gen_Label** and **BMI_Label**. Each of these one-hot encoded features is binary, meaning they can only take a value of **1** or **0**. A value of **1** indicates that the feature is active for the corresponding observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code creates a dummy DataFrame with two data points representing new diabetes cases.\n",
    "new_diabetes_df = pd.DataFrame(\n",
    "    # Data: A list of lists, where each list represents a data point\n",
    "    [[\"1\", \"Gen X\", \"Pre-obese\"],  # First data point: diabetes (1), Generation (Gen X), BMI (Pre-obese)\n",
    "     [\"0\", \"Boomers II\", \"Class I obesity\"]],  # Second data point: diabetes (0), Generation (Boomers II), BMI (Class I obesity)\n",
    "    \n",
    "    # Columns: Names of the columns for the DataFrame\n",
    "    columns=[\"diabetes\", \"Generation\", \"BMI\"],  # Define the names for each column (diabetes, Generation, BMI)\n",
    ")\n",
    "\n",
    "# Display the DataFrame to show the created data points\n",
    "new_diabetes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the text categories into numeric representations using our previously built LabelEncoder objects\n",
    "\n",
    "# Transforming the 'Generation' column values to numeric using the previously fitted LabelEncoder (gen_le)\n",
    "new_gen_labels = gen_le.transform(new_diabetes_df[\"Generation\"])\n",
    "\n",
    "# Adding the transformed numeric labels as a new column called \"Gen_Label\" in the DataFrame\n",
    "new_diabetes_df[\"Gen_Label\"] = new_gen_labels\n",
    "\n",
    "# Transforming the 'BMI' column values to numeric using the previously fitted LabelEncoder (bmi_le)\n",
    "new_bmi_labels = bmi_le.transform(new_diabetes_df[\"BMI\"])\n",
    "\n",
    "# Adding the transformed numeric labels as a new column called \"BMI_Label\" in the DataFrame\n",
    "new_diabetes_df[\"BMI_Label\"] = new_bmi_labels\n",
    "\n",
    "# Displaying the relevant columns to inspect the new encoded labels\n",
    "new_diabetes_df[[\"diabetes\", \"Generation\", \"Gen_Label\", \"BMI\", \"BMI_Label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform 'Gen_Label' column using previously built LabelEncoder to one-hot encoded features\n",
    "# 'gen_ohe' is assumed to be a previously fitted OneHotEncoder for the 'Gen_Label' column.\n",
    "new_gen_feature_arr = gen_ohe.transform(new_diabetes_df[[\"Gen_Label\"]]).toarray()  \n",
    "# Convert the resulting array into a DataFrame with appropriate column names from 'gen_feature_labels'\n",
    "new_gen_features = pd.DataFrame(new_gen_feature_arr, columns=gen_feature_labels)  \n",
    "\n",
    "# Transform 'BMI_Label' column using previously built LabelEncoder to one-hot encoded features\n",
    "# 'bmi_ohe' is assumed to be a previously fitted OneHotEncoder for the 'BMI_Label' column.\n",
    "new_bmi_feature_arr = bmi_ohe.transform(new_diabetes_df[[\"BMI_Label\"]]).toarray()  \n",
    "# Convert the resulting array into a DataFrame with appropriate column names from 'bmi_feature_labels'\n",
    "new_bmi_features = pd.DataFrame(new_bmi_feature_arr, columns=bmi_feature_labels)  \n",
    "\n",
    "# Concatenate the original dataframe 'new_diabetes_df' with the newly generated one-hot encoded features\n",
    "# This will add the new columns from 'new_gen_features' and 'new_bmi_features' to the original data\n",
    "new_diabetes_ohe = pd.concat(\n",
    "    [new_diabetes_df, new_gen_features, new_bmi_features], axis=1\n",
    ")\n",
    "\n",
    "# Define the desired column order, starting with diabetes-related columns, then adding one-hot encoded features\n",
    "columns = sum(\n",
    "    [\n",
    "        [\"diabetes\", \"Generation\", \"Gen_Label\"],  # The original columns from the dataset\n",
    "        gen_feature_labels,  # Columns generated from one-hot encoding of 'Gen_Label'\n",
    "        [\"BMI\", \"BMI_Label\"],  # The BMI-related columns\n",
    "        bmi_feature_labels,  # Columns generated from one-hot encoding of 'BMI_Label'\n",
    "    ],\n",
    "    [],\n",
    ")\n",
    "\n",
    "# Display the dataframe with the new column order\n",
    "new_diabetes_ohe[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas provides the 'get_dummies()' function that can help us easily perform one-hot encoding.\n",
    "# It converts a categorical column into multiple binary columns, each representing a category in the original column.\n",
    "gen_onehot_features = pd.get_dummies(diabetes_df[\"Generation\"])\n",
    "\n",
    "# Concatenate the original dataframe with the one-hot encoded columns, while keeping the \"diabetes\" and \"Generation\" columns.\n",
    "# We use `axis=1` to concatenate along columns (horizontally).\n",
    "# The 'iloc[4:10]' selects rows 4 through 9 (i.e., 6 rows) from the resulting dataframe.\n",
    "# This gives a glimpse of the encoded features for a specific subset of rows.\n",
    "pd.concat([diabetes_df[[\"diabetes\", \"Generation\"]], gen_onehot_features], axis=1).iloc[\n",
    "    4:10\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Coding Scheme\n",
    "\n",
    "The dummy coding scheme is similar to one-hot encoding, with one key difference: when applied to a categorical feature with **m** distinct labels, it generates **m-1** binary features. As a result, each value of the categorical variable is converted into a vector of size **m-1**. The remaining feature is entirely omitted, and if the category values range from {**0, 1, ..., m-1**}, the 0th or (m-1)th feature is typically represented by a vector of all zeros (**0**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy (one-hot encoded) variables for the \"Generation\" column in the diabetes dataset.\n",
    "# The first category (Boomers I) is dropped to avoid the dummy variable trap (multicollinearity).\n",
    "gen_dummy_features = pd.get_dummies(diabetes_df[\"Generation\"], drop_first=True)\n",
    "\n",
    "# Concatenate the original \"diabetes\" and \"Generation\" columns with the newly created dummy variables.\n",
    "# Select and display rows 4 to 9 for inspection.\n",
    "pd.concat([diabetes_df[[\"diabetes\", \"Generation\"]], gen_dummy_features], axis=1).iloc[4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding on the \"Generation\" column, creating binary features for each unique category.\n",
    "gen_onehot_features = pd.get_dummies(diabetes_df[\"Generation\"])\n",
    "\n",
    "# Drop the last column to avoid the dummy variable trap (multicollinearity issue).\n",
    "# This ensures that information is preserved without redundancy.\n",
    "gen_dummy_features = gen_onehot_features.iloc[:, :-1]\n",
    "\n",
    "# Concatenate the original \"diabetes\" and \"Generation\" columns with the encoded dummy variables.\n",
    "# Then, display rows 4 to 9 of the resulting DataFrame.\n",
    "pd.concat([diabetes_df[[\"diabetes\", \"Generation\"]], gen_dummy_features], axis=1).iloc[4:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Through this module, we learned essential feature engineering techniques for both numeric and categorical data, including:\n",
    "\n",
    "- Converting raw data into machine learning-ready features\n",
    "- Applying appropriate transformations based on data type\n",
    "- Understanding and implementing different encoding schemes\n",
    "- Creating meaningful feature interactions\n",
    "- Handling both nominal and ordinal categorical variables\n",
    "\n",
    "## Clean up\n",
    "\n",
    "Remember to shut down your Jupyter Notebook environment and delete any unnecessary files or resources once you've completed the tutorial.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
