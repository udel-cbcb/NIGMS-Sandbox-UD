{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#**Mark and Remove Missing Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, you will learn:\n",
    "\n",
    "* How to mark invalid or corrupt values as missing in your dataset.\n",
    "* How to confirm that the presence of marked missing values causes problems for learning algorithms.\n",
    "* How to remove rows with missing data from your dataset and evaluate a learning algorithm on the transformed dataset.\n",
    "\n",
    "Adapted from Jason Brownlee. 2020. [Data Preparation for Machine Learning](https://machinelearningmastery.com/data-preparation-for-machine-learning/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Diabetes Dataset\n",
    "The dataset classifies patient as\n",
    "either an onset of diabetes withinâ€€five years or not. \n",
    "```\n",
    "Number of Instances: 768\n",
    "Number of Attributes: 8 plus class \n",
    "For Each Attribute: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)\n",
    "Missing Attribute Values: Yes\n",
    "Class Distribution: (class value 1 is interpreted as \"tested positive for\n",
    "   diabetes\")\n",
    "   Class Value  Number of instances\n",
    "   0            500\n",
    "   1            268\n",
    "```\n",
    "You can learn more about the dataset here:\n",
    "\n",
    "* Diabetes Dataset File ([pima-indians-diabetes.csv](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv))\n",
    "* Diabetes Dataset Details ([pima-indians-diabetes.names](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names))\n",
    "\n",
    "The description of Diabetes Dataset can be found [here](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Download Diabetes data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wget\n",
    "!python -m wget \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv\" -o pima-indians-diabetes.csv\n",
    "!python -m wget \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names\" -o pima-indians-diabetes.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and summarize the dataset\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# Peek into the top five rows\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the dataset\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are columns that have a minimum value of zero (0).\n",
    "On some columns, a value of zero does not make sense and indicates an invalid or missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, the following columns have an invalid zero minimum value:\n",
    "2. Plasma glucose concentration\n",
    "3. Diastolic blood pressure\n",
    "4. Triceps skinfold thickness\n",
    "5. 2-Hour serum insulin\n",
    "6. Body mass index\n",
    "\n",
    "We can confirm this by looking at the raw data and printing out the first 20 rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset and review rows\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# summarize the first 20 rows of data\n",
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a count of the number of missing values on each of these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizing the number of missing values for each variable\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# count the number of missing values for each column\n",
    "num_missing = (dataset[[1,2,3,4,5]] == 0).sum()\n",
    "# report the results\n",
    "print(num_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that columns 1, 2 and 5 have just a few zero values, whereas columns 3 and 4\n",
    "show a lot more, nearly half of the rows. This highlights that different missing value strategies\n",
    "may be needed for different columns, e.g. to ensure that there are still a sufficient number of\n",
    "records left to train a predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, specifically Pandas, NumPy and Scikit-Learn, we mark missing values as NaN.\n",
    "Values with a NaN value are ignored from operations like sum, count, etc. We can mark values\n",
    "as NaN easily with the Pandas DataFrame by using the replace() function on a subset of\n",
    "the columns we are interested in. After we have marked the missing values, we can use the\n",
    "isnull() function to mark all of the NaN values in the dataset as True and get a count of the\n",
    "missing values for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marking missing values with nan values\n",
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# replace '0' values with 'nan'\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "# count the number of nan values in each column\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm by printing out the first 20 rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review data with missing values marked with a nan\n",
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# replace '0' values with 'nan'\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "# summarize the first 20 rows of data\n",
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Missing Values Cause Problems\n",
    "Having missing values in a dataset can cause errors with some machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example where missing values cause errors\n",
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# replace '0' values with 'nan'\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "# split dataset into inputs and outputs\n",
    "values = dataset.values\n",
    "X = values[:,0:8]\n",
    "y = values[:,8]\n",
    "# define the model\n",
    "# A classifier with a linear decision boundary, generated by fitting class\n",
    "# conditional densities to the data and using Bayes' rule.\n",
    "model = LinearDiscriminantAnalysis()\n",
    "# define the model evaluation procedure using K fold cross-valiation\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "# evaluate the model accuracy score\n",
    "result = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "# report the mean performance\n",
    "print('Accuracy: %.3f' % result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Remove Rows With Missing Values\n",
    "\n",
    "The simplest approach for dealing with missing values is to remove entire predictor(s)\n",
    "and/or sample(s) that contain missing values.\n",
    "\n",
    "We can do this by creating a new Pandas DataFrame with the rows containing missing values\n",
    "removed. Pandas provides the **dropna**() function that can be used to drop either columns or\n",
    "rows with missing data. We can use **dropna**() to remove all rows with missing data,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of removing rows that contain missing values\n",
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# summarize the shape of the raw data\n",
    "print(dataset.shape)\n",
    "# replace '0' values with 'nan'\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "# drop rows with missing values\n",
    "dataset.dropna(inplace=True)\n",
    "# summarize the shape of the data with missing rows removed\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a dataset that we could use to evaluate an algorithm sensitive to missing values\n",
    "like LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on data after rows with missing data are removed\n",
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# replace '0' values with 'nan'\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "# drop rows with missing values\n",
    "dataset.dropna(inplace=True)\n",
    "# split dataset into inputs and outputs\n",
    "values = dataset.values\n",
    "X = values[:,0:8]\n",
    "y = values[:,8]\n",
    "# define the model\n",
    "model = LinearDiscriminantAnalysis()\n",
    "# define the model evaluation procedure\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "# evaluate the model accuracy score\n",
    "result = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "# report the mean performance\n",
    "print('Accuracy: %.3f' % result.mean())"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
