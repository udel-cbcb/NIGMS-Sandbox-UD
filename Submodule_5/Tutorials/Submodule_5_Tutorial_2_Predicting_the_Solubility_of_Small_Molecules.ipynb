{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Solubility of Small Molecules using DeepChem\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial demonstrates how to use DeepChem to build models for predicting small molecule solubility. We'll explore how to work with molecular data and implement deep learning models for chemical property prediction.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Learn how to use DeepChem for molecular property prediction\n",
    "- Understand how to process and prepare molecular data for machine learning\n",
    "- Build and train deep learning models for solubility prediction\n",
    "- Evaluate model performance on chemical datasets\n",
    "\n",
    "### Tasks to complete\n",
    "\n",
    "- Load and process molecular data\n",
    "- Build DeepChem model\n",
    "- Train the model on solubility data\n",
    "- Evaluate predictions and model performance\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- A working Python environment and familiarity with Python\n",
    "- Basic understanding of machine learning concepts\n",
    "- Familiarity with pandas and numpy libraries\n",
    "- Knowledge of basic statistical concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Started\n",
    "\n",
    "- Please select \"conda_tensorflow2_p310\" kernel from SageMake Jupyter-lab notebook.\n",
    "\n",
    "### Import necessary libraries\n",
    "\n",
    "Note that you will likely get some warnings about missing dependencies and removed features.  This is expected since we aren't using the full capabilities of deepchem in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the pre-release version of the deepchem library with tensorflow support using pip.\n",
    "%pip install --pre deepchem[tensorflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the DeepChem library, which provides tools for deep learning in chemistry and drug discovery.\n",
    "import deepchem as dc\n",
    "# Import the 'warnings' module to manage warning messages during code execution.\n",
    "import warnings\n",
    "# Filter out and ignore all warning messages that might be generated during the execution of the code.\n",
    "warnings.filterwarnings('ignore')\n",
    "# Print the version of the DeepChem library that is currently installed.\n",
    "dc.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Model with DeepChem\n",
    "\n",
    "Deep learning can be used to solve many sorts of problems, but the basic workflow is usually the same.  Here are the typical steps you follow.\n",
    "\n",
    "1. Select the data set you will train your model on (or create a new data set if there isn't an existing suitable one).\n",
    "2. Create the model.\n",
    "3. Train the model on the data.\n",
    "4. Evaluate the model on an independent test set to see how well it works.\n",
    "5. Use the model to make predictions about new data.\n",
    "\n",
    "With DeepChem, each of these steps can be as little as one or two lines of Python code.  In this tutorial we will walk through a basic example showing the complete workflow to solve a real world scientific problem.\n",
    "\n",
    "The problem we will solve is predicting the solubility of small molecules given their chemical formulas.  This is a very important property in drug development: if a proposed drug isn't soluble enough, you probably won't be able to get enough into the patient's bloodstream to have a therapeutic effect.  \n",
    "\n",
    "The first thing we need is a data set of measured solubilities for real molecules.  One of the core components of DeepChem is MoleculeNet, a diverse collection of chemical and molecular data sets.  For this tutorial, we can use the Delaney solubility data set. The property of solubility in this data set is reported in log(solubility) where solubility is measured in moles/liter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Delaney (ESOL) dataset a regression dataset containing structures and\n",
    "# water solubility data for 1128 compounds. The dataset is widely used to\n",
    "# validate machine learning models on estimating solubility directly from\n",
    "# molecular structures (as encoded in SMILES strings).\n",
    "# featurizer: the featurizer to use for processing the data.\n",
    "tasks, datasets, transformers = dc.molnet.load_delaney(featurizer=\"GraphConv\")\n",
    "# Load the Delaney dataset using DeepChem's molnet module.\n",
    "#   - tasks:  List of tasks in the dataset (in this case, solubility prediction).\n",
    "#   - datasets: Tuple containing training, validation, and test datasets.\n",
    "#   - transformers: List of transformers used for data preprocessing (not used in this line but returned).\n",
    "#   - featurizer=\"GraphConv\": Specifies that the 'GraphConv' featurizer should be used to convert molecular SMILES strings into graph-based features.\n",
    "tasks, datasets, transformers = dc.molnet.load_delaney(featurizer=\"GraphConv\")\n",
    "# Unpack the datasets tuple into separate variables for training, validation, and test sets.\n",
    "train_dataset, valid_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_dataset.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, notice the `featurizer` argument passed to the `load_delaney()` function.  Molecules can be represented in many ways.  We therefore tell it which representation we want to use, or in more technical language, how to \"featurize\" the data.  Second, notice that we actually get three different data sets: a training set, a validation set, and a test set.  Each of these serves a different function in the standard deep learning workflow.\n",
    "\n",
    "### Create model\n",
    "\n",
    "Now that we have our data, the next step is to create a model.  We will use a particular kind of model called a \"graph convolutional network\", or \"graphconv\" for short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Graph Convolutional Models.\n",
    "# These graph convolutions start with a per-atom set of\n",
    "# descriptors for each atom in a molecule, then combine and recombine these\n",
    "# descriptors over convolutional layers.\n",
    "# model = dc.models.GraphConvModel(n_tasks=1, mode=\"regression\", dropout=0.2)\n",
    "# Graph convolutional model for regression\n",
    "import warnings # Import the warnings module to handle warning messages.\n",
    "warnings.filterwarnings('ignore') # Filter and ignore warning messages to keep the output clean.\n",
    "model = dc.models.GraphConvModel( # Initialize a Graph Convolutional Model from DeepChem.\n",
    "    n_tasks=1,       # Specify the number of tasks the model will predict (1 for single regression task).\n",
    "    mode=\"regression\",  # Set the model mode to 'regression' for predicting continuous values.\n",
    "    dropout=0.2      # Apply dropout regularization with a probability of 0.2 to prevent overfitting.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "We now need to train the model on the data set.  We simply give it the data set and tell it how many epochs of training to perform (that is, how many complete passes through the data to make)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppresses warning messages during code execution to keep the output cleaner.\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Trains the machine learning model using the provided training dataset.\n",
    "# - train_dataset: Input dataset used for training the model. This likely contains features and corresponding labels.\n",
    "# - nb_epoch=200: Specifies the number of training epochs (iterations over the entire training dataset) to be performed, set to 200 in this case.\n",
    "model.fit(train_dataset, nb_epoch=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model\n",
    "\n",
    "If everything has gone well, we should now have a fully trained model!  But do we?  To find out, we must evaluate the model on the test set.  We do that by selecting an evaluation metric and calling `evaluate()` on the model.  For this example, let's use the Pearson correlation, also known as r<sup>2</sup>, as our metric.  We can evaluate it on both the training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Metric object from DeepChem's metrics module.\n",
    "# This metric will be used to evaluate the model's performance.\n",
    "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
    "# Evaluate the model on the training dataset using the specified metric (Pearson R^2 score).\n",
    "# Print the training set score, which indicates how well the model performs on the data it was trained on.\n",
    "print(\"Training set score:\", model.evaluate(train_dataset, [metric], transformers))\n",
    "# Evaluate the model on the test dataset using the same metric (Pearson R^2 score).\n",
    "# Print the test set score, which indicates how well the model generalizes to unseen data.\n",
    "print(\"Test set score:\", model.evaluate(test_dataset, [metric], transformers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that it has a higher score on the training set than the test set.  Models usually perform better on the particular data they were trained on than they do on similar but independent data.  This is called \"overfitting\", and it is the reason it is essential to evaluate your model on an independent test set.\n",
    "\n",
    "Our model still has quite respectable performance on the test set.  For comparison, a model that produced totally random outputs would have a correlation of 0, while one that made perfect predictions would have a correlation of 1.  Our model does quite well, so now we can use it to make predictions about other molecules we care about.\n",
    "\n",
    "### Make predictions\n",
    "\n",
    "Let's just use the first ten molecules from the test set.  For each one we print out the chemical structure (represented as a SMILES string) and the predicted log(solubility). To put these predictions in \n",
    "context, we print out the log(solubility) values from the test set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts solubilities for the first 10 samples in the test dataset using the model in batch mode.\n",
    "solubilities = model.predict_on_batch(test_dataset.X[:10])\n",
    "# Iterates through the first 10 molecules, their predicted solubilities, and their actual test solubilities.\n",
    "for molecule, solubility, test_solubility in zip(\n",
    "    test_dataset.ids, solubilities, test_dataset.y\n",
    "):\n",
    "# Prints the predicted solubility, actual test solubility, and molecule identifier for each molecule.\n",
    "print(solubility, test_solubility, molecule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we learned how to:\n",
    "\n",
    "- Work with molecular data using DeepChem\n",
    "- Build deep learning models for property prediction\n",
    "- Process chemical structures for machine learning\n",
    "- Make predictions about molecular solubility\n",
    "\n",
    "## Clean up\n",
    "\n",
    "Remember to shut down your Jupyter Notebook environment and delete any unnecessary files or resources once you've completed the tutorial.\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
