{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Solubility of Small Molecules using DeepChem\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial demonstrates how to use DeepChem to build models for predicting small molecule solubility. We'll explore how to work with molecular data and implement deep learning models for chemical property prediction.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Learn how to use DeepChem for molecular property prediction\n",
    "- Understand how to process and prepare molecular data for machine learning\n",
    "- Build and train deep learning models for solubility prediction\n",
    "- Evaluate model performance on chemical datasets\n",
    "\n",
    "### Tasks to complete\n",
    "\n",
    "- Load and process molecular data\n",
    "- Build DeepChem model\n",
    "- Train the model on solubility data\n",
    "- Evaluate predictions and model performance\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- A working Python environment and familiarity with Python\n",
    "- Basic understanding of machine learning concepts\n",
    "- Familiarity with pandas and numpy libraries\n",
    "- Knowledge of basic statistical concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Started\n",
    "\n",
    "- Please select \"conda_tensorflow2_p310\" kernel from SageMake Jupyter-lab notebook.\n",
    "\n",
    "### Import necessary libraries\n",
    "\n",
    "Note that you will likely get some warnings about missing dependencies and removed features.  This is expected since we aren't using the full capabilities of deepchem in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --pre deepchem[tensorflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "dc.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Model with DeepChem\n",
    "\n",
    "Deep learning can be used to solve many sorts of problems, but the basic workflow is usually the same.  Here are the typical steps you follow.\n",
    "\n",
    "1. Select the data set you will train your model on (or create a new data set if there isn't an existing suitable one).\n",
    "2. Create the model.\n",
    "3. Train the model on the data.\n",
    "4. Evaluate the model on an independent test set to see how well it works.\n",
    "5. Use the model to make predictions about new data.\n",
    "\n",
    "With DeepChem, each of these steps can be as little as one or two lines of Python code.  In this tutorial we will walk through a basic example showing the complete workflow to solve a real world scientific problem.\n",
    "\n",
    "The problem we will solve is predicting the solubility of small molecules given their chemical formulas.  This is a very important property in drug development: if a proposed drug isn't soluble enough, you probably won't be able to get enough into the patient's bloodstream to have a therapeutic effect.  \n",
    "\n",
    "The first thing we need is a data set of measured solubilities for real molecules.  One of the core components of DeepChem is MoleculeNet, a diverse collection of chemical and molecular data sets.  For this tutorial, we can use the Delaney solubility data set. The property of solubility in this data set is reported in log(solubility) where solubility is measured in moles/liter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Delaney (ESOL) dataset a regression dataset containing structures and\n",
    "# water solubility data for 1128 compounds. The dataset is widely used to\n",
    "# validate machine learning models on estimating solubility directly from\n",
    "# molecular structures (as encoded in SMILES strings).\n",
    "# featurizer: the featurizer to use for processing the data.\n",
    "tasks, datasets, transformers = dc.molnet.load_delaney(featurizer=\"GraphConv\")\n",
    "train_dataset, valid_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_dataset.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, notice the `featurizer` argument passed to the `load_delaney()` function.  Molecules can be represented in many ways.  We therefore tell it which representation we want to use, or in more technical language, how to \"featurize\" the data.  Second, notice that we actually get three different data sets: a training set, a validation set, and a test set.  Each of these serves a different function in the standard deep learning workflow.\n",
    "\n",
    "### Create model\n",
    "\n",
    "Now that we have our data, the next step is to create a model.  We will use a particular kind of model called a \"graph convolutional network\", or \"graphconv\" for short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Graph Convolutional Models.\n",
    "# These graph convolutions start with a per-atom set of\n",
    "# descriptors for each atom in a molecule, then combine and recombine these\n",
    "# descriptors over convolutional layers.\n",
    "# model = dc.models.GraphConvModel(n_tasks=1, mode=\"regression\", dropout=0.2)\n",
    "# Graph convolutional model for regression\n",
    "warnings.filterwarnings('ignore')\n",
    "model = dc.models.GraphConvModel(\n",
    "    n_tasks=1,       # Number of regression targets (e.g., predicting a single property)\n",
    "    mode=\"regression\",  # Task type (regression/classification)\n",
    "    dropout=0.2      # Regularization to prevent overfitting\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "We now need to train the model on the data set.  We simply give it the data set and tell it how many epochs of training to perform (that is, how many complete passes through the data to make)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "# Returns the average loss over the most recent checkpoint interval\n",
    "model.fit(train_dataset, nb_epoch=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model\n",
    "\n",
    "If everything has gone well, we should now have a fully trained model!  But do we?  To find out, we must evaluate the model on the test set.  We do that by selecting an evaluation metric and calling `evaluate()` on the model.  For this example, let's use the Pearson correlation, also known as r<sup>2</sup>, as our metric.  We can evaluate it on both the training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
    "print(\"Training set score:\", model.evaluate(train_dataset, [metric], transformers))\n",
    "print(\"Test set score:\", model.evaluate(test_dataset, [metric], transformers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that it has a higher score on the training set than the test set.  Models usually perform better on the particular data they were trained on than they do on similar but independent data.  This is called \"overfitting\", and it is the reason it is essential to evaluate your model on an independent test set.\n",
    "\n",
    "Our model still has quite respectable performance on the test set.  For comparison, a model that produced totally random outputs would have a correlation of 0, while one that made perfect predictions would have a correlation of 1.  Our model does quite well, so now we can use it to make predictions about other molecules we care about.\n",
    "\n",
    "### Make predictions\n",
    "\n",
    "Let's just use the first ten molecules from the test set.  For each one we print out the chemical structure (represented as a SMILES string) and the predicted log(solubility). To put these predictions in \n",
    "context, we print out the log(solubility) values from the test set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solubilities = model.predict_on_batch(test_dataset.X[:10])\n",
    "for molecule, solubility, test_solubility in zip(\n",
    "    test_dataset.ids, solubilities, test_dataset.y\n",
    "):\n",
    "    print(solubility, test_solubility, molecule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we learned how to:\n",
    "\n",
    "- Work with molecular data using DeepChem\n",
    "- Build deep learning models for property prediction\n",
    "- Process chemical structures for machine learning\n",
    "- Make predictions about molecular solubility\n",
    "\n",
    "## Clean up\n",
    "\n",
    "Remember to shut down your Jupyter Notebook environment and delete any unnecessary files or resources once you've completed the tutorial.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
