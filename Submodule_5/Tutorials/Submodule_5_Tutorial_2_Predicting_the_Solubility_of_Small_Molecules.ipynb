{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Solubility of Small Molecules using DeepChem\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial provides a practical introduction to predicting small molecule solubility using DeepChem, an open-source toolkit that combines cheminformatics with machine learning. We'll walk through the essential steps of building predictive models, starting with how to represent molecular structures in formats suitable for machine learning algorithms.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Learn how to use DeepChem for molecular property prediction\n",
    "- Understand how to process and prepare molecular data for machine learning\n",
    "- Build and train deep learning models for solubility prediction\n",
    "- Evaluate model performance on chemical datasets\n",
    "\n",
    "### Tasks to complete\n",
    "\n",
    "- Load and process molecular data\n",
    "- Build DeepChem model\n",
    "- Train the model on solubility data\n",
    "- Evaluate predictions and model performance\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- A working Python environment and familiarity with Python\n",
    "- Basic understanding of machine learning concepts\n",
    "- Familiarity with pandas and numpy libraries\n",
    "- Knowledge of basic statistical concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Started\n",
    "\n",
    "- Please select \"conda_tensorflow2_p310\" kernel from SageMake Jupyter-lab notebook.\n",
    "\n",
    "### Import necessary libraries\n",
    "\n",
    "Note that you will likely get some warnings about missing dependencies and removed features.  This is expected since we aren't using the full capabilities of deepchem in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the pre-release version of the deepchem library with tensorflow support using pip.\n",
    "%pip install --pre deepchem[tensorflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the DeepChem library, which provides tools for deep learning in chemistry and drug discovery.\n",
    "import deepchem as dc\n",
    "\n",
    "# Import the 'warnings' module to manage warning messages during code execution.\n",
    "import warnings\n",
    "# Filter out and ignore all warning messages that might be generated during the execution of the code.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "# Suppress all logs (INFO, WARNING, ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "# Disable GPU usage to avoid CUDA initialization errors\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "# Import TensorFlow after setting environment variables\n",
    "\n",
    "# Print the version of the DeepChem library that is currently installed.\n",
    "dc.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Model with DeepChem\n",
    "\n",
    "Deep learning can solve diverse problems through a consistent workflow. Here's the typical process:\n",
    "\n",
    "### Basic Workflow Steps\n",
    "\n",
    "1. **Data Selection**  \n",
    "   Choose an existing dataset or create a new one suitable for your task.\n",
    "\n",
    "2. **Model Creation**  \n",
    "   Design the architecture of your deep learning model.\n",
    "\n",
    "3. **Model Training**  \n",
    "   Fit the model to your training data.\n",
    "\n",
    "4. **Model Evaluation**  \n",
    "   Test the model's performance on an independent test set.\n",
    "\n",
    "5. **Model Deployment**  \n",
    "   Use the trained model to make predictions on new data.\n",
    "\n",
    "### DeepChem Implementation\n",
    "\n",
    "With DeepChem, each step can be implemented in just 1-2 lines of Python code. This tutorial demonstrates the complete workflow for a real-world scientific problem.\n",
    "\n",
    "### Problem Statement: Solubility Prediction\n",
    "\n",
    "**Objective**: Predict small molecule solubility from chemical formulas.  \n",
    "\n",
    "**Importance**: Solubility is crucial in drug development - insufficient solubility may prevent therapeutic concentrations in the bloodstream.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "We'll use the **Delaney solubility dataset** from MoleculeNet (a DeepChem component offering diverse chemical datasets).  \n",
    "\n",
    "**Key Details**:\n",
    "- Measures solubility in log(solubility)\n",
    "- Units: moles/liter\n",
    "- Contains experimentally measured values for real molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Delaney (ESOL) dataset a regression dataset containing structures and\n",
    "# water solubility data for 1128 compounds. The dataset is widely used to\n",
    "# validate machine learning models on estimating solubility directly from\n",
    "# molecular structures (as encoded in SMILES strings).\n",
    "\n",
    "# Load the Delaney dataset using DeepChem's molnet module.\n",
    "#   - tasks:  List of tasks in the dataset (in this case, solubility prediction).\n",
    "#   - datasets: Tuple containing training, validation, and test datasets.\n",
    "#   - transformers: List of transformers used for data preprocessing (not used in this line but returned).\n",
    "#   - featurizer=\"GraphConv\": Specifies that the 'GraphConv' featurizer should be used to convert molecular SMILES strings into graph-based features.\n",
    "tasks, datasets, transformers = dc.molnet.load_delaney(featurizer=\"GraphConv\")\n",
    "\n",
    "# Unpack the datasets tuple into separate variables for training, validation, and test sets.\n",
    "train_dataset, valid_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_dataset.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_delaney()` function accepts a `featurizer` argument, which specifies how to convert molecular structures into machine-readable representations. Since molecules can be represented in multiple ways, this parameter determines the specific featurization method. \n",
    "\n",
    "The function returns three distinct datasets:\n",
    "   - **Training set**: Used for model fitting\n",
    "   - **Validation set**: Used for hyperparameter tuning\n",
    "   - **Test set**: Used for final performance evaluation  \n",
    "   \n",
    "This tripartite split follows standard deep learning practices, where each subset serves a unique purpose in the model development workflow.\n",
    "\n",
    "### Create Model\n",
    "\n",
    "With our data prepared, we proceed to model creation using a **Graph Convolutional Network (GCN)**. \n",
    "\n",
    "#### GraphConvModel Implementation\n",
    "- **Model Type**: `GraphConvModel` from DeepChem  \n",
    "- **Task**: Regression (predicting molecular solubility)  \n",
    "- **Architecture**:  \n",
    "  - Processes molecular structures as graphs (atoms=nodes, bonds=edges)  \n",
    "  - Uses graph convolutions to capture atomic interactions and spatial relationships  \n",
    "  - Optimized for molecular property prediction  \n",
    "\n",
    "#### Data Featurization  \n",
    "- The `load_delaney()` function accepts a `featurizer` argument to specify molecular representation  \n",
    "- Featurization converts raw molecular data into model-digestible formats  \n",
    "\n",
    "#### Dataset Splits  \n",
    "Three distinct datasets are generated:  \n",
    "1. **Training set**: Model learning  \n",
    "2. **Validation set**: Hyperparameter tuning  \n",
    "3. **Test set**: Final performance evaluation  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Graph Convolutional Models.\n",
    "# These graph convolutions start with a per-atom set of\n",
    "# descriptors for each atom in a molecule, then combine and recombine these\n",
    "# descriptors over convolutional layers.\n",
    "# model = dc.models.GraphConvModel(n_tasks=1, mode=\"regression\", dropout=0.2)\n",
    "# Graph convolutional model for regression\n",
    "import warnings # Import the warnings module to handle warning messages.\n",
    "warnings.filterwarnings('ignore') # Filter and ignore warning messages to keep the output clean.\n",
    "\n",
    "model = dc.models.GraphConvModel( # Initialize a Graph Convolutional Model from DeepChem.\n",
    "    n_tasks=1,       # Specify the number of tasks the model will predict (1 for single regression task).\n",
    "    mode=\"regression\",  # Set the model mode to 'regression' for predicting continuous values.\n",
    "    dropout=0.2      # Apply dropout regularization with a probability of 0.2 to prevent overfitting.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "The model is now initialized and ready for training on the featurized Delaney dataset.\n",
    "\n",
    "To train our model on the prepared dataset:\n",
    "\n",
    "- Use the `fit()` method to handle the entire training process\n",
    "- Key parameters:\n",
    "  - Training dataset (features and labels)\n",
    "  - Number of epochs (`nb_epoch`)\n",
    "\n",
    "**Training Details:**\n",
    "- Each epoch = one complete pass through the training data\n",
    "- Model iteratively adjusts parameters during training\n",
    "- For this solubility prediction task:\n",
    "  - Training duration: **200 epochs**\n",
    "  - Allows the model to adequately learn complex structure-solubility relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppresses warning messages during code execution to keep the output cleaner.\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Trains the machine learning model using the provided training dataset.\n",
    "# - train_dataset: Input dataset used for training the model. This likely contains features and corresponding labels.\n",
    "# - nb_epoch=200: Specifies the number of training epochs (iterations over the entire training dataset) to be performed, set to 200 in this case.\n",
    "model.fit(train_dataset, nb_epoch=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "With training complete, we now validate our model's performance through comprehensive evaluation. This involves:\n",
    "\n",
    "- **Dual Assessment**:\n",
    "  - Testing on **training data** to verify learning efficacy\n",
    "  - Testing on **holdout test set** to measure generalization capability\n",
    "\n",
    "- **Primary Metric**: \n",
    "  - Pearson R² (r-squared) score for regression performance\n",
    "    - Range: 0 (no correlation) to 1 (perfect correlation)\n",
    "    - Measures how closely predictions match actual solubility values\n",
    "\n",
    "This evaluation framework ensures we quantify both memorization capacity and true predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Metric object from DeepChem's metrics module.\n",
    "# This metric will be used to evaluate the model's performance.\n",
    "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
    "\n",
    "# Evaluate the model on the training dataset using the specified metric (Pearson R^2 score).\n",
    "# Print the training set score, which indicates how well the model performs on the data it was trained on.\n",
    "print(\"Training set score:\", model.evaluate(train_dataset, [metric], transformers))\n",
    "\n",
    "# Evaluate the model on the test dataset using the same metric (Pearson R^2 score).\n",
    "# Print the test set score, which indicates how well the model generalizes to unseen data.\n",
    "print(\"Test set score:\", model.evaluate(test_dataset, [metric], transformers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Performance Analysis  \n",
    "\n",
    "- **Training vs. Test Scores**:  \n",
    "  The model shows a higher score on the training set compared to the test set. This is expected because models typically perform better on the data they were trained on than on independent data—a phenomenon known as **overfitting**.  \n",
    "  **Key Takeaway**: Always evaluate models on a separate test set to detect overfitting.  \n",
    "\n",
    "- **Test Set Performance**:  \n",
    "  Despite the slight drop in performance, the model achieves **respectable results** on the test set. For context:  \n",
    "  - Random predictions would yield a correlation of **0**.  \n",
    "  - Perfect predictions would score **1**.  \n",
    "  Our model’s performance is statistically meaningful, confirming its utility for real-world applications.  \n",
    "\n",
    "- **Next Steps**:  \n",
    "  With validation complete, the model is now ready to generate predictions for new molecules of interest.  \n",
    "\n",
    "### Make predictions\n",
    "\n",
    "To demonstrate our model's predictive capabilities, we'll examine its performance on a representative subset of molecules. The code below analyzes the first ten compounds from the test set, displaying each molecule's SMILES string (a text-based representation of its chemical structure), the model's predicted log(solubility) value, and the corresponding experimental measurement from the test set for direct comparison.\n",
    "\n",
    "This side-by-side comparison serves multiple purposes:\n",
    "- Provides immediate, interpretable validation of the model's predictions at the molecular level\n",
    "- Helps identify any systematic prediction errors (e.g., consistently overestimating certain chemical classes)\n",
    "- Offers tangible examples of the model's performance beyond aggregate metrics\n",
    "- Allows quick visual inspection of whether prediction errors correlate with specific structural features\n",
    "\n",
    "The output format clearly distinguishes between the model's predictions and ground truth values, enabling researchers to assess predictive accuracy for individual compounds while maintaining the context of experimental measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts solubilities for the first 10 samples in the test dataset using the model in batch mode.\n",
    "solubilities = model.predict_on_batch(test_dataset.X[:10])\n",
    "\n",
    "# Iterates through the first 10 molecules, their predicted solubilities, and their actual test solubilities.\n",
    "for molecule, solubility, test_solubility in zip(test_dataset.ids, solubilities, test_dataset.y):\n",
    "    # Prints the predicted solubility, actual test solubility, and molecule identifier for each molecule.\n",
    "    print(solubility, test_solubility, molecule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we learned how to:\n",
    "\n",
    "- Work with molecular data using DeepChem\n",
    "- Build deep learning models for property prediction\n",
    "- Process chemical structures for machine learning\n",
    "- Make predictions about molecular solubility\n",
    "\n",
    "## Clean up\n",
    "\n",
    "Remember to shut down your Jupyter Notebook environment and delete any unnecessary files or resources once you've completed the tutorial.\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
