{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pfam Protein Sequence Classification with Tensorflow and Keras\n",
    "\n",
    "Adapted from Saleh Alkhalifa. [Machine Learning in Biotechnology and Life Sciences](https://github.com/PacktPublishing/Machine-Learning-in-Biotechnology-and-Life-Sciences).\n",
    "\n",
    "In this tutorial, we will attempt to develop a protein sequence classification model in which we will classify protein sequences based on their known family accession using the Pfam (https://pfam.xfam.org/) dataset.\n",
    "\n",
    "Pfam: The protein families database in 2021: J. Mistry, S. Chuguransky, L. Williams, M. Qureshi, G.A. Salazar, E.L.L. Sonnhammer, S.C.E. Tosatto, L. Paladin, S. Raj, L.J. Richardson, R.D. Finn, A. Bateman\n",
    "Nucleic Acids Research (2020) doi: 10.1093/nar/gkaa913\n",
    "\n",
    "The Pfam dataset consists of several columns, as follows:\n",
    "\n",
    "- *Family_id*: The name of the family that the seqeunce belongs to (for example, filamin).\n",
    "- *Family Accession*: The class or output that our model will aim to predict.\n",
    "- *Sequence*: The amino acid sequence we will use as input for our model\n",
    "\n",
    "We will use the seqeunce data to develop model to determine each seqeunece's associated family accession. The sequences are in their raw state with different lengths and sizes. We will need to pre-process the data and structure it in such a way as to prepare it for sequence classification. We will develop a model using a *balanced* set of different labels to ensure the model does not learn any particular bias.\n",
    "\n",
    "- **TensorFlow** is an end-to-end open source platform for machine learning. It has a comprehensive, flexible ecosystem of tools, libraries and community. \n",
    "- **Keras** is a deep learning API written in Python, running on top of the machine learning platform TensorFlow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import (\n",
    "    LSTM,\n",
    "    Bidirectional,\n",
    "    Conv1D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Embedding,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    MaxPooling1D,\n",
    ")\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.regularizers import l2\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-in-Biotechnology-and-Life-Sciences/main/datasets/dataset_pfam\"\n",
    "\n",
    "files = []\n",
    "for i in range(8):\n",
    "    df = pd.read_csv(f\"{URL}/dataset_pfam_seq_sd{i+1}.csv\", index_col=None, header=0)\n",
    "    files.append(df)\n",
    "\n",
    "df = pd.concat(files, axis=0, ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peek into the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get top 10 abundant family ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"family_id\"].groupby(df[\"family_id\"]).value_counts().nlargest(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get top 10 abundant family accessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"family_accession\"].groupby(df[\"family_accession\"]).value_counts().nlargest(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the sequence length frequency distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df[\"sequence\"].apply(lambda x: len(x)), bins=75, height=4, aspect=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get mean sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sequence\"].str.len().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get min sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sequence\"].str.len().min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get max sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sequence\"].str.len().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get median sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sequence\"].str.len().median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get family accessions with counts more than 1200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filt = df.groupby(\"family_accession\").filter(lambda x: len(x) > 1200)\n",
    "df_filt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bal = df_filt.groupby(\"family_accession\").apply(lambda x: x.sample(1200))\n",
    "df_bal.family_accession.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peek into the balanced dataset\n",
    "df_bal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare input dataframe for modeling\n",
    "\n",
    "`reset_index` in pandas is used to reset index of the dataframe object to default indexing (0 to number of rows minus 1) or to reset multi level index. By doing so, the original index gets converted to a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_red = df_bal[[\"family_accession\", \"sequence\"]].reset_index(drop=True)\n",
    "df_red.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute num of unique classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(df_red.family_accession.value_counts())\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Pfam family accession unique number counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_red.family_accession.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make train and test datasets\n",
    "\n",
    "Split data into 75% X_train and 25% X_Test, among `X_Test`, 50% for validation (`X_val`) and 50% for test (`X_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_Test = train_test_split(df_red, test_size=0.25)\n",
    "X_val, X_test = train_test_split(X_Test, test_size=0.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the train, test, and validation dataset sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create amino acid sequence dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_seq_dict = {\n",
    "    \"A\": 1,\n",
    "    \"C\": 2,\n",
    "    \"D\": 3,\n",
    "    \"E\": 4,\n",
    "    \"F\": 5,\n",
    "    \"G\": 6,\n",
    "    \"H\": 7,\n",
    "    \"I\": 8,\n",
    "    \"K\": 9,\n",
    "    \"L\": 10,\n",
    "    \"M\": 11,\n",
    "    \"N\": 12,\n",
    "    \"P\": 13,\n",
    "    \"Q\": 14,\n",
    "    \"R\": 15,\n",
    "    \"S\": 16,\n",
    "    \"T\": 17,\n",
    "    \"V\": 18,\n",
    "    \"W\": 19,\n",
    "    \"Y\": 20,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode amino acid sequence using the dictionary above\n",
    "def aa_seq_encoder(data):\n",
    "    full_sequence_list = []\n",
    "    for i in data[\"sequence\"].values:\n",
    "        row_sequence_list = []\n",
    "        for j in i:\n",
    "            row_sequence_list.append(aa_seq_dict.get(j, 0))\n",
    "        full_sequence_list.append(np.array(row_sequence_list))\n",
    "    return full_sequence_list\n",
    "\n",
    "\n",
    "X_train_encode = aa_seq_encoder(X_train)\n",
    "X_val_encode = aa_seq_encoder(X_val)\n",
    "X_test_encode = aa_seq_encoder(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show an example encoded amino acid sequence\n",
    "X_train_encode[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad sequence to the same length of 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 100\n",
    "\n",
    "X_train_padded = pad_sequences(\n",
    "    X_train_encode, maxlen=max_length, padding=\"post\", truncating=\"post\"\n",
    ")\n",
    "X_val_padded = pad_sequences(\n",
    "    X_val_encode, maxlen=max_length, padding=\"post\", truncating=\"post\"\n",
    ")\n",
    "X_test_padded = pad_sequences(\n",
    "    X_test_encode, maxlen=max_length, padding=\"post\", truncating=\"post\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.sequence[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encode[1][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_padded[1][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode target labels with value between `0` and `n_classes-1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "y_train_enc = le.fit_transform(X_train[\"family_accession\"])\n",
    "y_val_enc = le.transform(X_val[\"family_accession\"])\n",
    "y_test_enc = le.transform(X_test[\"family_accession\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"family_accession\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(le.classes_)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts a class vector (integers) to binary class matrix.\n",
    "\n",
    "y_train = to_categorical(y_train_enc)\n",
    "y_val = to_categorical(y_val_enc)\n",
    "y_test = to_categorical(y_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential groups a linear stack of layers into a tf.keras.Model.\n",
    "# Sequential provides training and inference features on this model.\n",
    "model = Sequential()\n",
    "\n",
    "# EmbeddingLayer: Turns positive integers (indexes) into dense vectors of fixed size.\n",
    "#  input_dim: Integer. Size of the vocabulary, i.e. maximum integer index + 1.\n",
    "#  output_dim: Integer. Dimension of the dense embedding.\n",
    "#  input_length: Length of input sequences, when it is constant.\n",
    "model.add(Embedding(21, 16, input_length=max_length, name=\"EmbeddingLayer\"))\n",
    "\n",
    "# Bidirectional wrapper for RNNs with 16 units of LSTM\n",
    "model.add(Bidirectional(LSTM(16), name=\"BidirectionalLayer\"))\n",
    "\n",
    "# Applies Dropout to the input with 20% of the input units to drop.\n",
    "model.add(Dropout(0.2, name=\"DropoutLayer\"))\n",
    "\n",
    "# densely-connected NN layer of 28 units\n",
    "model.add(Dense(28, activation=\"softmax\", name=\"DenseLayer\"))\n",
    "\n",
    "# Optimizer that implements the Adam algorithm\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Configures the model for training use 'Adam' as optimizer, 'categorical_crossentropy'\n",
    "# as loss funciton, and 'accuracy' as evaluation metrics\n",
    "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop training when a monitored metric has stopped improving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monitor: Quantity to be monitored.\n",
    "# patience: Number of epochs with no improvement after which training will be stopped.\n",
    "# verbose: verbosity mode on\n",
    "es = EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The following cell may takeu a few minutes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains the model for a fixed number of epochs (iterations on a dataset)\n",
    "history = model.fit(\n",
    "    X_train_padded,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    validation_data=(X_val_padded, y_val),\n",
    "    callbacks=[es],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy and loss across epochs\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "# total_rows, total_columns, subplot_index(1st, 2nd, etc..)\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"Accuracy\", fontsize=15)\n",
    "plt.xlabel(\"Epochs\", fontsize=15)\n",
    "plt.ylabel(\"Accuracy (%)\", fontsize=15)\n",
    "plt.plot(\n",
    "    history.history[\"val_accuracy\"], label=\"Validation Accuracy\", linestyle=\"dashed\"\n",
    ")\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "plt.legend([\"Validation\", \"Training\"], loc=\"lower right\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"Loss\", fontsize=15)\n",
    "plt.xlabel(\"Epochs\", fontsize=15)\n",
    "plt.ylabel(\"Loss\", fontsize=15)\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation loss\", linestyle=\"dashed\")\n",
    "plt.plot(history.history[\"loss\"], label=\"Training loss\")\n",
    "plt.legend([\"Validation\", \"Training\"], loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates output predictions for the input samples\n",
    "y_pred = model.predict(X_test_padded)\n",
    "\n",
    "# Build a text report showing the main classification metrics\n",
    "print(\n",
    "    classification_report(\n",
    "        np.argmax(y_test, axis=1),\n",
    "        np.argmax(y_pred, axis=1),\n",
    "        target_names=le.classes_,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Support** is the number of actual occurrences of the class in the specified dataset. \n",
    "- **Macro avg** takes the arithmetic mean (aka unweighted mean). \n",
    "- **Weighted avg** takes the mean of all per-class while considering each classâ€™s support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "\n",
    "Compute confusion matrix to evaluate the accuracy of a classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(cf_matrix, annot=True, fmt=\"\", cmap=\"Blues\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nigms_sandbox_ud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
