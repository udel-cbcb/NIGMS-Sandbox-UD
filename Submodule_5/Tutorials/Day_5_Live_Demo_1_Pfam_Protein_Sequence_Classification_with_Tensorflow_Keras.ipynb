{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#**Pfam Protein Sequence Classification with Tensorflow and Keras**\n",
    "\n",
    "\n",
    "In this tutorial, we will attempt to develop a protein sequence classification model in which we will classify protein sequences based on their known family accession using the Pfam (https://pfam.xfam.org/) dataset.\n",
    "\n",
    "Pfam: The protein families database in 2021: J. Mistry, S. Chuguransky, L. Williams, M. Qureshi, G.A. Salazar, E.L.L. Sonnhammer, S.C.E. Tosatto, L. Paladin, S. Raj, L.J. Richardson, R.D. Finn, A. Bateman\n",
    "Nucleic Acids Research (2020) doi: 10.1093/nar/gkaa913\n",
    "\n",
    "The Pfam dataset consists of several columns, as follows:\n",
    "* *Family_id*: The name of the family that the seqeunce belongs to (for example, filamin).\n",
    "* *Family Accession*: The class or output that our model will aim to predict.\n",
    "* *Sequence*: The amino acid sequence we will use as input for our model\n",
    "\n",
    "We will use the seqeunce data to develop model to determine each seqeunece's associated family accession. The sequences are in their raw state with different lengths and sizes. We will need to pre-process the data and structure it in such a way as to prepare it for sequence classification. We will develop a model using a *balanced* set of different labels to ensure the model does not learn any particular bias.\n",
    "\n",
    "Adapted from Saleh Alkhalifa. [Machine Learning in Biotechnology and Life Sciences](https://github.com/PacktPublishing/Machine-Learning-in-Biotechnology-and-Life-Sciences)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Install tensorflow and keras\n",
    "\n",
    "\n",
    "**TensorFlow** is an end-to-end open source platform for machine learning. It has a comprehensive, flexible ecosystem of tools, libraries and community. \n",
    "\n",
    "**Keras** is a deep learning API written in Python, running on top of the machine learning platform TensorFlow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow keras --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Converts a class vector (integers) to binary class matrix.\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-in-Biotechnology-and-Life-Sciences/main/datasets/dataset_pfam/\"\n",
    "\n",
    "files = []\n",
    "for i in range(8):\n",
    "    df = pd.read_csv(URL+f\"dataset_pfam_seq_sd{i+1}.csv\", index_col=None, header=0)\n",
    "    files.append(df)\n",
    "    \n",
    "df = pd.concat(files, axis=0, ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peek into the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing data\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 10 abundant family ids\n",
    "df[\"family_id\"].groupby(df[\"family_id\"]).value_counts().nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 10 abundant family accessions\n",
    "df[\"family_accession\"].groupby(df[\"family_accession\"]).value_counts().nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the sequence length frequency distribution\n",
    "sns.displot(df[\"sequence\"].apply(lambda x: len(x)), bins=75, height=4, aspect=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mean sequence length\n",
    "df[\"sequence\"].str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get min sequence length\n",
    "df[\"sequence\"].str.len().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get max sequence length\n",
    "df[\"sequence\"].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get median sequence length\n",
    "df[\"sequence\"].str.len().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get family accessions with counts more than 1200\n",
    "df_filt = df.groupby(\"family_accession\").filter(lambda x: len(x) > 1200)\n",
    "df_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a balanced dataset\n",
    "df_bal = df_filt.groupby('family_accession').apply(lambda x: x.sample(1200))\n",
    "df_bal.family_accession.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peek into the balanced dataset\n",
    "df_bal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare input dataframe for modeling\n",
    "# reset_index in pandas is used to reset index of the dataframe object to default indexing (0 to number of rows minus 1) \n",
    "# or to reset multi level index. By doing so, the original index gets converted to a column.\n",
    "df_red = df_bal[[\"family_accession\", \"sequence\"]].reset_index(drop=True)\n",
    "df_red.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute num of unique classes\n",
    "num_classes = len(df_red.family_accession.value_counts())\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Pfam family accession unique number counts\n",
    "df_red.family_accession.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into 75% X_train and 25% X_Test, among X_Test, 50% for validation(X_val) and 50% for test (X_test)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_Test = train_test_split(df_red, test_size=0.25)\n",
    "X_val, X_test = train_test_split(X_Test, test_size=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the train, test, and validation dataaset sizes\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create amino acid seqence dictionary\n",
    "aa_seq_dict = {'A': 1,'C': 2,'D': 3,'E': 4,'F': 5,'G': 6,'H': 7,'I': 8,'K': 9,'L': 10,'M': 11,'N': 12,'P': 13,'Q': 14,'R': 15,'S': 16,'T': 17,'V': 18,'W': 19,'Y': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode amino acid sequence using the dictionary above\n",
    "def aa_seq_encoder(data):\n",
    "    full_sequence_list = []\n",
    "    for i in data['sequence'].values:\n",
    "        row_sequence_list = []\n",
    "        for j in i:\n",
    "            row_sequence_list.append(aa_seq_dict.get(j, 0))\n",
    "        full_sequence_list.append(np.array(row_sequence_list))\n",
    "    return full_sequence_list\n",
    "  \n",
    "X_train_encode = aa_seq_encoder(X_train) \n",
    "X_val_encode = aa_seq_encoder(X_val) \n",
    "X_test_encode = aa_seq_encoder(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show an example encoded amino acid sequence\n",
    "X_train_encode[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pad sequence to the same length of 100\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_length = 100\n",
    "\n",
    "X_train_padded = pad_sequences(X_train_encode, maxlen=max_length, padding='post', truncating='post')\n",
    "X_val_padded = pad_sequences(X_val_encode, maxlen=max_length, padding='post', truncating='post')\n",
    "X_test_padded = pad_sequences(X_test_encode, maxlen=max_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.sequence[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encode[1][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_padded[1][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Encode target labels with value between 0 and n_classes-1.\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_train_enc = le.fit_transform(X_train['family_accession'])\n",
    "y_val_enc = le.transform(X_val['family_accession'])\n",
    "y_test_enc = le.transform(X_test['family_accession'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['family_accession']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(le.classes_)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts a class vector (integers) to binary class matrix.\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train_enc)\n",
    "y_val = to_categorical(y_val_enc)\n",
    "y_test = to_categorical(y_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tensorflow and keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Input, Bidirectional, LSTM, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "# Sequential groups a linear stack of layers into a tf.keras.Model.\n",
    "# Sequential provides training and inference features on this model.\n",
    "model = Sequential()\n",
    "\n",
    "# EmbeddingLayer: Turns positive integers (indexes) into dense vectors of fixed size.\n",
    "#  input_dim: Integer. Size of the vocabulary, i.e. maximum integer index + 1.\n",
    "#  output_dim: Integer. Dimension of the dense embedding.\n",
    "#  input_length: Length of input sequences, when it is constant.\n",
    "model.add(Embedding(21, 16, input_length=max_length, name=\"EmbeddingLayer\"))\n",
    "# Bidirectional wrapper for RNNs with 16 units of LSTM\n",
    "model.add(Bidirectional(LSTM(16), name=\"BidirectionalLayer\"))\n",
    "# Applies Dropout to the input with 20% of the input units to drop.\n",
    "model.add(Dropout(0.2, name=\"DropoutLayer\"))\n",
    "# densely-connected NN layer of 28 units\n",
    "model.add(Dense(28, activation='softmax', name=\"DenseLayer\"))\n",
    "\n",
    "# Optimizer that implements the Adam algorithm\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Configures the model for training use 'Adam' as optimizer, 'categorical_crossentropy' \n",
    "# as loss funciton, and 'accuracy' as evaluation metrics\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Stop training when a monitored metric has stopped improving\n",
    "# monitor: Quantity to be monitored.\n",
    "# patience: Number of epochs with no improvement after which training will be stopped.\n",
    "# verbose: verbosity mode on\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains the model for a fixed number of epochs (iterations on a dataset)\n",
    "history = model.fit(\n",
    "    X_train_padded, y_train,\n",
    "    epochs=100, batch_size=256,\n",
    "    validation_data=(X_val_padded, y_val),\n",
    "    callbacks=[es]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accurcy and loss across epochs\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "# total_rows, total_columns, subplot_index(1st, 2nd, etc..)\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"Accuracy\", fontsize=15)\n",
    "plt.xlabel(\"Epochs\", fontsize=15)\n",
    "plt.ylabel(\"Accuracy (%)\", fontsize=15)\n",
    "plt.plot(history.history[\"val_accuracy\"], label='Validation Accuracy', linestyle='dashed')\n",
    "plt.plot(history.history[\"accuracy\"], label='Training Accuracy')\n",
    "plt.legend([\"Validation\", \"Training\"], loc=\"lower right\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"Loss\", fontsize=15)\n",
    "plt.xlabel(\"Epochs\", fontsize=15)\n",
    "plt.ylabel(\"Loss\", fontsize=15)\n",
    "plt.plot(history.history[\"val_loss\"], label='Validation loss', linestyle='dashed')\n",
    "plt.plot(history.history[\"loss\"], label='Training loss')\n",
    "plt.legend([\"Validation\", \"Training\"], loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generates output predictions for the input samples\n",
    "y_pred = model.predict(X_test_padded)\n",
    "\n",
    "# Build a text report showing the main classification metrics\n",
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support** is the number of actual occurrences of the class in the specified dataset. **macro avg** takes the arithmetic mean (aka unweighted mean). **weighted avg** takes the mean of all per-class while considering each classâ€™s support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show predicted values\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute confusion matrix to evaluate the accuracy of a classification\n",
    "cf_matrix = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion_matrix\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='', cmap='Blues')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
