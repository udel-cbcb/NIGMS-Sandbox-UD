{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Types Analysis Using Deep Learning Exercise Solution\n",
    "\n",
    "Adapted from Dipanjan Sarkar et al. 2018. [Practical Machine Learning with Python](https://link.springer.com/book/10.1007/978-1-4842-3207-1).\n",
    "\n",
    "## Overview\n",
    "\n",
    "This module focuses on building predictive models to predict wine types (red or white wine) based on various features using Deep Learning techniques. The analysis uses a dataset containing wine quality measurements and characteristics.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Build and train a Deep Neural Network model for wine type classification\n",
    "- Understand feature scaling and preprocessing techniques\n",
    "- Evaluate model performance using various metrics\n",
    "- Visualize model training progress and results\n",
    "- Apply binary classification techniques using deep learning\n",
    "\n",
    "### Tasks to complete\n",
    "\n",
    "- Build and compile a Deep Neural Network model\n",
    "- Train the model using scaled features\n",
    "- Evaluate model performance on test data\n",
    "- Generate performance visualizations and metrics\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python programming environment\n",
    "- Basic understanding of statistical and machine learning concepts\n",
    "- Familiarity with common ML libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary dependencies\n",
    "# We wil use matplotlib and seaborn for exploratory data analysis and visualizations\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from scipy import interp\n",
    "from sklearn import metrics\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, label_binarize\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and merge datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_wine = pd.read_csv(\"../../Data/winequality-white.csv\", sep=\";\")\n",
    "red_wine = pd.read_csv(\"../../Data/winequality-red.csv\", sep=\";\")\n",
    "\n",
    "# store wine type as an attribute\n",
    "red_wine[\"wine_type\"] = \"red\"\n",
    "white_wine[\"wine_type\"] = \"white\"\n",
    "# bucket wine quality scores into qualitative quality labels\n",
    "# Wine quality scores of 3, 4, and 5 are mapped to low quality,\n",
    "# 6 and 7 are mapped to medium quality, 8 and 9 are mapped to high quality\n",
    "# wines under the quality_label attribute.\n",
    "red_wine[\"quality_label\"] = red_wine[\"quality\"].apply(\n",
    "    lambda value: \"low\" if value <= 5 else \"medium\" if value <= 7 else \"high\"\n",
    ")\n",
    "red_wine[\"quality_label\"] = pd.Categorical(\n",
    "    red_wine[\"quality_label\"], categories=[\"low\", \"medium\", \"high\"]\n",
    ")\n",
    "white_wine[\"quality_label\"] = white_wine[\"quality\"].apply(\n",
    "    lambda value: \"low\" if value <= 5 else \"medium\" if value <= 7 else \"high\"\n",
    ")\n",
    "white_wine[\"quality_label\"] = pd.Categorical(\n",
    "    white_wine[\"quality_label\"], categories=[\"low\", \"medium\", \"high\"]\n",
    ")\n",
    "\n",
    "# merge red and white wine datasets\n",
    "wines = pd.concat([red_wine, white_wine])\n",
    "# re-shuffle records just to randomize data points\n",
    "wines = wines.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand dataset features and values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(white_wine.shape, red_wine.shape)\n",
    "print(wines.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 4898 white wine data points and 1599 red wine data points. The\n",
    "merged dataset contains a total of 6497 data points and we also get an idea of numeric and categorical\n",
    "attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Letâ€™s take a peek at our dataset to see some sample data points.\n",
    "wines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilty functions for model evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(true_labels, predicted_labels):\n",
    "\n",
    "    print(\n",
    "        \"Accuracy:\", np.round(metrics.accuracy_score(true_labels, predicted_labels), 4)\n",
    "    )\n",
    "    print(\n",
    "        \"Precision:\",\n",
    "        np.round(\n",
    "            metrics.precision_score(true_labels, predicted_labels, average=\"weighted\"),\n",
    "            4,\n",
    "        ),\n",
    "    )\n",
    "    print(\n",
    "        \"Recall:\",\n",
    "        np.round(\n",
    "            metrics.recall_score(true_labels, predicted_labels, average=\"weighted\"), 4\n",
    "        ),\n",
    "    )\n",
    "    print(\n",
    "        \"F1 Score:\",\n",
    "        np.round(\n",
    "            metrics.f1_score(true_labels, predicted_labels, average=\"weighted\"), 4\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def display_classification_report(true_labels, predicted_labels, classes=[1, 0]):\n",
    "\n",
    "    report = metrics.classification_report(\n",
    "        y_true=true_labels, y_pred=predicted_labels, labels=classes\n",
    "    )\n",
    "    print(report)\n",
    "\n",
    "\n",
    "def display_confusion_matrix(true_labels, predicted_labels, classes=[1, 0]):\n",
    "\n",
    "    total_classes = len(classes)\n",
    "    level_labels = [total_classes * [0], list(range(total_classes))]\n",
    "    cm = metrics.confusion_matrix(\n",
    "        y_true=true_labels, y_pred=predicted_labels, labels=classes\n",
    "    )\n",
    "    cm_frame = pd.DataFrame(\n",
    "        data=cm,\n",
    "        columns=pd.MultiIndex(levels=[[\"Predicted:\"], classes], codes=level_labels),\n",
    "        index=pd.MultiIndex(levels=[[\"Actual:\"], classes], codes=level_labels),\n",
    "    )\n",
    "    print(cm_frame)\n",
    "\n",
    "\n",
    "def display_model_performance_metrics(true_labels, predicted_labels, classes=[1, 0]):\n",
    "    print(\"Model Performance metrics:\")\n",
    "    print(\"-\" * 30)\n",
    "    get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)\n",
    "    print(\"\\nModel Classification report:\")\n",
    "    print(\"-\" * 30)\n",
    "    display_classification_report(\n",
    "        true_labels=true_labels, predicted_labels=predicted_labels, classes=classes\n",
    "    )\n",
    "    print(\"\\nPrediction Confusion Matrix:\")\n",
    "    print(\"-\" * 30)\n",
    "    display_confusion_matrix(\n",
    "        true_labels=true_labels, predicted_labels=predicted_labels, classes=classes\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_model_roc_curve(\n",
    "    clf, features, true_labels, label_encoder=None, class_names=None\n",
    "):\n",
    "\n",
    "    ## Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    if hasattr(clf, \"classes_\"):\n",
    "        class_labels = clf.classes_\n",
    "    elif label_encoder:\n",
    "        class_labels = label_encoder.classes_\n",
    "    elif class_names:\n",
    "        class_labels = class_names\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Unable to derive prediction classes, please specify class_names!\"\n",
    "        )\n",
    "    n_classes = len(class_labels)\n",
    "    y_test = label_binarize(true_labels, classes=class_labels)\n",
    "    if n_classes == 2:\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            prob = clf.predict_proba(features)\n",
    "            y_score = prob[:, prob.shape[1] - 1]\n",
    "        elif hasattr(clf, \"decision_function\"):\n",
    "            prob = clf.decision_function(features)\n",
    "            y_score = prob[:, prob.shape[1] - 1]\n",
    "        else:\n",
    "            raise AttributeError(\n",
    "                \"Estimator doesn't have a probability or confidence scoring system!\"\n",
    "            )\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(\n",
    "            fpr,\n",
    "            tpr,\n",
    "            label=\"ROC curve (area = {0:0.2f})\" \"\".format(roc_auc),\n",
    "            linewidth=2.5,\n",
    "        )\n",
    "\n",
    "    elif n_classes > 2:\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            y_score = clf.predict_proba(features)\n",
    "        elif hasattr(clf, \"decision_function\"):\n",
    "            y_score = clf.decision_function(features)\n",
    "        else:\n",
    "            raise AttributeError(\n",
    "                \"Estimator doesn't have a probability or confidence scoring system!\"\n",
    "            )\n",
    "\n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        ## Compute micro-average ROC curve and ROC area\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "        ## Compute macro-average ROC curve and ROC area\n",
    "        # First aggregate all false positive rates\n",
    "        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "        # Then interpolate all ROC curves at this points\n",
    "        mean_tpr = np.zeros_like(all_fpr)\n",
    "        for i in range(n_classes):\n",
    "            mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "        # Finally average it and compute AUC\n",
    "        mean_tpr /= n_classes\n",
    "        fpr[\"macro\"] = all_fpr\n",
    "        tpr[\"macro\"] = mean_tpr\n",
    "        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "        ## Plot ROC curves\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.plot(\n",
    "            fpr[\"micro\"],\n",
    "            tpr[\"micro\"],\n",
    "            label=\"micro-average ROC curve (area = {0:0.2f})\"\n",
    "            \"\".format(roc_auc[\"micro\"]),\n",
    "            linewidth=3,\n",
    "        )\n",
    "\n",
    "        plt.plot(\n",
    "            fpr[\"macro\"],\n",
    "            tpr[\"macro\"],\n",
    "            label=\"macro-average ROC curve (area = {0:0.2f})\"\n",
    "            \"\".format(roc_auc[\"macro\"]),\n",
    "            linewidth=3,\n",
    "        )\n",
    "\n",
    "        for i, label in enumerate(class_labels):\n",
    "            plt.plot(\n",
    "                fpr[i],\n",
    "                tpr[i],\n",
    "                label=\"ROC curve of class {0} (area = {1:0.2f})\"\n",
    "                \"\".format(label, roc_auc[i]),\n",
    "                linewidth=2,\n",
    "                linestyle=\":\",\n",
    "            )\n",
    "    else:\n",
    "        raise ValueError(\"Number of classes should be atleast 2 or more\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_model_decision_surface(\n",
    "    clf,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    plot_step=0.02,\n",
    "    cmap=plt.cm.RdYlBu,\n",
    "    markers=None,\n",
    "    alphas=None,\n",
    "    colors=None,\n",
    "):\n",
    "\n",
    "    if train_features.shape[1] != 2:\n",
    "        raise ValueError(\"X_train should have exactly 2 columnns!\")\n",
    "\n",
    "    x_min, x_max = (\n",
    "        train_features[:, 0].min() - plot_step,\n",
    "        train_features[:, 0].max() + plot_step,\n",
    "    )\n",
    "    y_min, y_max = (\n",
    "        train_features[:, 1].min() - plot_step,\n",
    "        train_features[:, 1].max() + plot_step,\n",
    "    )\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.arange(x_min, x_max, plot_step), np.arange(y_min, y_max, plot_step)\n",
    "    )\n",
    "\n",
    "    clf_est = clone(clf)\n",
    "    clf_est.fit(train_features, train_labels)\n",
    "    if hasattr(clf_est, \"predict_proba\"):\n",
    "        Z = clf_est.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "    else:\n",
    "        Z = clf_est.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=cmap)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_enc = le.fit_transform(train_labels)\n",
    "    n_classes = len(le.classes_)\n",
    "    plot_colors = \"\".join(colors) if colors else [None] * n_classes\n",
    "    label_names = le.classes_\n",
    "    markers = markers if markers else [None] * n_classes\n",
    "    alphas = alphas if alphas else [None] * n_classes\n",
    "    for i, color in zip(range(n_classes), plot_colors):\n",
    "        idx = np.where(y_enc == i)\n",
    "        plt.scatter(\n",
    "            train_features[idx, 0],\n",
    "            train_features[idx, 1],\n",
    "            c=color,\n",
    "            label=label_names[i],\n",
    "            cmap=cmap,\n",
    "            edgecolors=\"black\",\n",
    "            marker=markers[i],\n",
    "            alpha=alphas[i],\n",
    "        )\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Wine Types\n",
    "\n",
    "We will predict the wine type based on other features. To start with, we\n",
    "will first select our necessary features and separate out the prediction class labels and prepare train and test\n",
    "datasets. We use the prefix **wtp\\_** in our variables to easily identify them as needed, where **wtp** depicts wine\n",
    "type prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtp_features = wines.iloc[:, :-3]\n",
    "wtp_feature_names = wtp_features.columns\n",
    "wtp_class_labels = np.array(wines[\"wine_type\"])\n",
    "\n",
    "# prepare train and test datasets\n",
    "wtp_train_X, wtp_test_X, wtp_train_y, wtp_test_y = train_test_split(\n",
    "    wtp_features, wtp_class_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(Counter(wtp_train_y), Counter(wtp_test_y))\n",
    "print(\"Features:\", list(wtp_feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers show us the wine samples for each class and we can also see the feature names which will\n",
    "be used in our feature set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "We will be using a standard scaler in this scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scaler\n",
    "wtp_ss = StandardScaler().fit(wtp_train_X)\n",
    "\n",
    "# Scale the train set\n",
    "wtp_train_SX = wtp_ss.transform(wtp_train_X)\n",
    "\n",
    "# Scale the test set\n",
    "wtp_test_SX = wtp_ss.transform(wtp_test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Model using Deep Learning (MLP)\n",
    "\n",
    "Letâ€™s try\n",
    "modeling the data using a fully connected deep neural network (DNN) with three hidden layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encodes wine type class labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(wtp_train_y)\n",
    "# encode wine type labels\n",
    "wtp_train_ey = le.transform(wtp_train_y)\n",
    "wtp_test_ey = le.transform(wtp_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build & Compile DNN Model Architecture\n",
    "\n",
    "Letâ€™s build the architecture for our three-hidden layer DNN where each hidden layer has 16 units (the\n",
    "input layer has 11 units for the 11 features) and the output layer has 1 unit to predict a 0 or 1, which maps\n",
    "back to red or white wine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a sequential model of three-hidden layer DNN where each hidden layer has 16 units and 'relu' activation\n",
    "# (the input layer has 11 units for the 11 features) and the output layer has 1 unit and 'sigmoid' activation\n",
    "wtp_dnn_model = Sequential()\n",
    "wtp_dnn_model.add(Dense(16, activation=\"relu\", input_shape=(11,)))\n",
    "wtp_dnn_model.add(Dense(16, activation=\"relu\"))\n",
    "wtp_dnn_model.add(Dense(16, activation=\"relu\"))\n",
    "wtp_dnn_model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Configures the model for training use 'Adam' as optimizer, 'binary_crossentropy'\n",
    "# as loss funciton, and 'accuracy' as evaluation metrics\n",
    "wtp_dnn_model.compile(\n",
    "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model\n",
    "\n",
    "We use 10% of the training data for a validation set while training the model to see how it performs at\n",
    "each epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = wtp_dnn_model.fit(\n",
    "    wtp_train_SX,\n",
    "    wtp_train_ey,\n",
    "    epochs=10,\n",
    "    batch_size=5,\n",
    "    shuffle=True,\n",
    "    validation_split=0.1,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on test data\n",
    "\n",
    "Letâ€™s now predict and evaluate our model on the actual test dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtp_dnn_ypred = wtp_dnn_model.predict(wtp_test_SX)\n",
    "wtp_dnn_ypred = np.round(wtp_dnn_ypred).astype(int)\n",
    "wtp_dnn_predictions = le.inverse_transform(np.ravel(wtp_dnn_ypred))  # make 1d array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Model Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_model_performance_metrics(\n",
    "    true_labels=wtp_test_y,\n",
    "    predicted_labels=wtp_dnn_predictions,\n",
    "    classes=[\"red\", \"white\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an overall F1 Score and model accuracy of 99.5%, which is even\n",
    "better than our previous model! This goes to prove you donâ€™t always need big data but good quality data\n",
    "and features even for Deep Learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss and accurcy measures at each epoch\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "t = f.suptitle(\"Deep Neural Net Performance\", fontsize=12)\n",
    "f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "epochs = list(range(1, 11))\n",
    "ax1.plot(epochs, history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "ax1.plot(epochs, history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "ax1.set_xticks(epochs)\n",
    "ax1.set_ylabel(\"Accuracy Value\")\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_title(\"Accuracy\")\n",
    "l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(epochs, history.history[\"loss\"], label=\"Train Loss\")\n",
    "ax2.plot(epochs, history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "ax2.set_xticks(epochs)\n",
    "ax2.set_ylabel(\"Loss Value\")\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.set_title(\"Loss\")\n",
    "l2 = ax2.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Through this module, we successfully implemented a complete deep learning workflow including:\n",
    "\n",
    "- Data preprocessing and feature scaling techniques\n",
    "- Building a three-layer Deep Neural Network architecture\n",
    "- Training the model with validation monitoring\n",
    "- Implementing comprehensive model evaluation metrics\n",
    "- Creating performance visualizations to track model training\n",
    "- Applying binary classification techniques to real-world data\n",
    "\n",
    "These practical skills demonstrate the end-to-end process of developing and deploying deep learning models for classification tasks.\n",
    "\n",
    "## Clean up\n",
    "\n",
    "Remember to shut down your Jupyter Notebook environment and delete any unnecessary files or resources once you've completed the tutorial.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
