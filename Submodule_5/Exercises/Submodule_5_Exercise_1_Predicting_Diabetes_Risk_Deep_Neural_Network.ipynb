{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65fc0a41-058d-481a-99c9-ae0ad2eea34b",
   "metadata": {},
   "source": [
    "# **Diabetes Prediction using Deep Neural Network (DNN)**\n",
    "\n",
    "Adapted from Dipanjan Sarkar et al. 2018. [Practical Machine Learning with Python](https://link.springer.com/book/10.1007/978-1-4842-3207-1).\n",
    "\n",
    "## **Overview**\n",
    "This notebook demonstrates how to build a **deep neural network (DNN)** model using **TensorFlow and Keras** to predict whether a patient has diabetes. We will use the **Pima Indians Diabetes Dataset** and go through the process of **data loading, preprocessing, model creation, training, and evaluation**.  This notebook provides a practical example of applying deep learning techniques to a binary classification problem in healthcare.\n",
    "\n",
    "---\n",
    "\n",
    "## **Learning Objectives**\n",
    "By the end of this notebook, you will be able to:\n",
    "- Load and explore the **Pima Indians Diabetes Dataset**.\n",
    "- Preprocess data for neural network training, including **feature scaling**.\n",
    "- Build a **sequential deep neural network model** using **TensorFlow/Keras**.\n",
    "- Train the DNN model to predict diabetes using the dataset.\n",
    "- Evaluate the model's performance using **accuracy, precision, recall, F1-score, and confusion matrix**.\n",
    "- Visualize model training progress using **accuracy and loss curves**.\n",
    "- Make **predictions on new sample data** using the trained DNN model.\n",
    "\n",
    "---\n",
    "\n",
    "## **Tasks to Complete**\n",
    "1. **Load and Explore the Dataset:**\n",
    "    - Read the Pima Indians Diabetes Dataset from a CSV file.\n",
    "    - Display dataset information and sample data to understand its structure and features.\n",
    "\n",
    "2. **Preprocess the Data:**\n",
    "    - Prepare features and labels for model training.\n",
    "    - Split the dataset into **training and testing sets**.\n",
    "    - **Standardize numerical features** using `StandardScaler`.\n",
    "\n",
    "3. **Build and Train a Deep Neural Network (DNN) Model:**\n",
    "    - Create a **Sequential model** using TensorFlow/Keras with multiple dense layers and ReLU activation, and a sigmoid output layer for binary classification.\n",
    "    - **Compile the model** with binary cross-entropy loss, Adam optimizer, and accuracy metric.\n",
    "    - **Train the DNN model** using the training data, including validation during training.\n",
    "\n",
    "4. **Evaluate Model Performance:**\n",
    "    - Make predictions on the test set.\n",
    "    - Evaluate and display model performance metrics: **accuracy, precision, recall, F1-score, classification report, and confusion matrix**.\n",
    "    - Plot **training accuracy and loss curves** to visualize training progress.\n",
    "\n",
    "5. **Make Predictions on New Samples:**\n",
    "    - Create new sample patient data.\n",
    "    - Preprocess the new sample data using the **same scaler** fitted on the training data.\n",
    "    - Use the trained DNN model to **predict diabetes risk probabilities** for the new samples.\n",
    "    - Display the predicted outcomes and probabilities for each sample.\n",
    "\n",
    "---\n",
    "\n",
    "## **Prerequisites**\n",
    "Before running this notebook, ensure you have the following:\n",
    "- **Python 3.6+**\n",
    "- **Required Python libraries installed:**\n",
    "    ```bash\n",
    "    pip install numpy pandas matplotlib scikit-learn tensorflow\n",
    "    ```\n",
    "    *(Specifically, ensure you have TensorFlow and Keras installed)*\n",
    "\n",
    "---\n",
    "\n",
    "## **Get Started**\n",
    "- Please ensure you have a **Python environment with TensorFlow and Keras installed**.\n",
    "- Select a suitable kernel for running this notebook (e.g., a Python kernel with TensorFlow).\n",
    "- Execute the code cells in the notebook sequentially to follow the steps of building, training, and evaluating the diabetes prediction DNN model.\n",
    "- Please select kernel \"conda_tensorflow2_p310\" from SageMaker notebook instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc03ea7b-5245-4323-9443-7e1872f15fb0",
   "metadata": {},
   "source": [
    "### Import necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31872426-87ed-4f35-95b2-808be6d65f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the NumPy library for numerical operations in Python.\n",
    "import numpy as np\n",
    "# Import the Pandas library for data manipulation and analysis using DataFrames.\n",
    "import pandas as pd\n",
    "# Import the Pyplot module from Matplotlib library for creating static, interactive, and animated visualizations in Python.\n",
    "import matplotlib.pyplot as plt\n",
    "# Import the 'read_csv' function from the Pandas library to read comma-separated values (CSV) files into DataFrame.\n",
    "from pandas import read_csv\n",
    "# Import the 'Counter' class from the 'collections' module for counting hashable objects.\n",
    "from collections import Counter\n",
    "# Import the 'metrics' module from scikit-learn library for model evaluation metrics.\n",
    "from sklearn import metrics\n",
    "# Import the 'train_test_split' function from scikit-learn to split data into training and testing sets.\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import specific modules from scikit-learn for preprocessing data: LabelEncoder, StandardScaler, and label_binarize.\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, label_binarize\n",
    "# Import the 'Sequential' model from TensorFlow Keras to build neural network models layer by layer.\n",
    "from tensorflow.keras.models import Sequential\n",
    "# Import the 'Dense' layer from TensorFlow Keras to create densely connected neural network layers.\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Enable matplotlib to display plots inline within the notebook.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d485582-1fc4-4ec9-8c79-0552cbe49f49",
   "metadata": {},
   "source": [
    "# Pima Indians Diabetes Dataset\n",
    "\n",
    "## Overview\n",
    "The **Pima Indians Diabetes Dataset** is a well-known dataset used for binary classification tasks in machine learning, specifically for predicting whether a patient has diabetes based on various medical attributes. The dataset originates from the **National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK)** and focuses on female patients of **Pima Indian heritage**.\n",
    "\n",
    "## Source\n",
    "- **Dataset Repository:** [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/12/pima+indians+diabetes)\n",
    "- **Original Source:** National Institute of Diabetes and Digestive and Kidney Diseases\n",
    "- **Purpose:** Predicting the onset of diabetes based on diagnostic measurements.\n",
    "\n",
    "## Dataset Description\n",
    "The dataset contains **768 samples** with **8 numerical features** and **1 binary target variable** (diabetes outcome).\n",
    "\n",
    "### **Features:**\n",
    "1. **Pregnancies** – Number of times pregnant  \n",
    "2. **Glucose** – Plasma glucose concentration over 2 hours in an oral glucose tolerance test  \n",
    "3. **BloodPressure** – Diastolic blood pressure (mm Hg)  \n",
    "4. **SkinThickness** – Triceps skinfold thickness (mm)  \n",
    "5. **Insulin** – 2-Hour serum insulin (mu U/ml)  \n",
    "6. **BMI** – Body mass index (weight in kg/(height in m²))  \n",
    "7. **DiabetesPedigreeFunction** – Diabetes pedigree function (genetic influence)  \n",
    "8. **Age** – Age of the patient (years)  \n",
    "9. **Outcome** – Binary classification (1 = Diabetic, 0 = Non-Diabetic)  \n",
    "\n",
    "## Summary Statistics\n",
    "- **Total samples:** 768  \n",
    "- **Diabetes positive cases (Outcome = 1):** ~35%  \n",
    "- **Diabetes negative cases (Outcome = 0):** ~65%  \n",
    "- **Missing values:** Some attributes contain zero values which may indicate missing data (e.g., Glucose, BloodPressure).\n",
    "\n",
    "## Example Usage\n",
    "This dataset is frequently used in **machine learning** and **statistical modeling** for:\n",
    "- Logistic Regression\n",
    "- Decision Trees & Random Forests\n",
    "- Support Vector Machines (SVM)\n",
    "- Deep Learning\n",
    "- Feature Engineering and Imputation Techniques\n",
    "\n",
    "## References\n",
    "- UCI Machine Learning Repository: [Pima Indians Diabetes Dataset](https://archive.ics.uci.edu/dataset/12/pima+indians+diabetes)\n",
    "- Smith, J. W., et al. \"Using the ADAP learning algorithm to forecast the onset of diabetes mellitus.\" In Proceedings of the Annual Symposium on Computer Application in Medical Care. American Medical Informatics Association, 1988."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de2540c-df33-4c3a-8605-48908eaeae3b",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2932a8c-d11f-4535-8c52-ebca643569b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the pima-indians-diabetes dataset CSV file.\n",
    "diabetes_data = \"../../Data/pima-indians-diabetes.csv\"\n",
    "#df = pd.read_csv(diabetes_data) # This line is commented out, it would load the data using default settings.\n",
    "\n",
    "# Define a list of column names for the dataset, based on the dataset description.\n",
    "columns = [\n",
    "    'Pregnancies', # Column name for number of pregnancies.\n",
    "    'Glucose', # Column name for plasma glucose concentration.\n",
    "    'BloodPressure', # Column name for diastolic blood pressure.\n",
    "    'SkinThickness', # Column name for triceps skin fold thickness.\n",
    "    'Insulin', # Column name for 2-hour serum insulin.\n",
    "    'BMI', # Column name for body mass index.\n",
    "    'DiabetesPedigreeFunction', # Column name for diabetes pedigree function.\n",
    "    'Age', # Column name for age.\n",
    "    'Outcome' # Column name for class variable (diabetes outcome).\n",
    "]\n",
    "\n",
    "# Load the dataset from the CSV file using pandas read_csv function.\n",
    "df = read_csv(\n",
    "    diabetes_data, # Path to the CSV file.\n",
    "    header=None, # Indicate that the CSV file has no header row.\n",
    "    names=columns, # Assign the defined column names to the DataFrame.\n",
    "    na_values=\"?\", # Treat question marks '?' in the data as Not a Number (NaN) values.\n",
    "    sep=',' # Specify that the data is separated by commas.\n",
    ")\n",
    "\n",
    "# Print information about the loaded dataset.\n",
    "print(\"Dataset Info:\")\n",
    "# Print a concise summary of the DataFrame, including data types and non-null values.\n",
    "print(df.info())\n",
    "# Print a newline for better readability.\n",
    "print(\"\\nSample Data:\")\n",
    "# Display the first few rows of the DataFrame to get a glimpse of the data.\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b83b77b-36f5-4c20-93e9-c661398204de",
   "metadata": {},
   "source": [
    "## Domain Knowledge\n",
    "\n",
    "### Key Health Indicators\n",
    "\n",
    "- **Pregnancies:** Number of times pregnant\n",
    "- **Glucose:** Plasma glucose concentration (mg/dL)\n",
    "- **BloodPressure:** Diastolic blood pressure (mm Hg)\n",
    "- **SkinThickness:** Triceps skin fold thickness (mm)\n",
    "- **Insulin:** 2-Hour serum insulin (mu U/ml)\n",
    "- **BMI:** Body mass index (kg/m²)\n",
    "- **DiabetesPedigreeFunction:** Diabetes risk genetic score\n",
    "- **Age:** Years\n",
    "- **Outcome:** Diabetes diagnosis (0 = Negative, 1 = Positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3935acc8-763e-412a-891c-67a462674946",
   "metadata": {},
   "source": [
    "### Define helper functions for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375e8ca8-cd79-4b26-80c2-84d8d2ec5336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function called 'get_metrics' that takes true labels and predicted labels as input.\n",
    "def get_metrics(true_labels, predicted_labels):\n",
    "    \"\"\"Calculate and print performance metrics.\"\"\"\n",
    "    # Print the Accuracy score, rounded to 4 decimal places, by comparing true labels and predicted labels.\n",
    "    print(\"Accuracy:\", np.round(metrics.accuracy_score(true_labels, predicted_labels), 4))\n",
    "    # Print the Precision score, rounded to 4 decimal places, using weighted averaging for multi-class if needed.\n",
    "    print(\"Precision:\", np.round(metrics.precision_score(true_labels, predicted_labels, average=\"weighted\"), 4))\n",
    "    # Print the Recall score, rounded to 4 decimal places, using weighted averaging for multi-class if needed.\n",
    "    print(\"Recall:\", np.round(metrics.recall_score(true_labels, predicted_labels, average=\"weighted\"), 4))\n",
    "    # Print the F1 Score, rounded to 4 decimal places, using weighted averaging for multi-class if needed.\n",
    "    print(\"F1 Score:\", np.round(metrics.f1_score(true_labels, predicted_labels, average=\"weighted\"), 4))\n",
    "\n",
    "# Define a function called 'display_classification_report' that takes true labels, predicted labels, and class names as input.\n",
    "def display_classification_report(true_labels, predicted_labels, classes):\n",
    "    \"\"\"Display classification report.\"\"\" # Docstring for the function explaining its purpose.\n",
    "    # Prints the classification report using scikit-learn's metrics.classification_report function, using provided true labels, predicted labels, and class labels.\n",
    "    print(metrics.classification_report(true_labels, predicted_labels, labels=classes)) \n",
    "\n",
    "# Defines a function called 'display_confusion_matrix' that takes true labels, predicted labels, and class names as input.\n",
    "def display_confusion_matrix(true_labels, predicted_labels, classes):\n",
    "    \"\"\"Display confusion matrix.\"\"\"\n",
    "    # Calculates the confusion matrix using scikit-learn's metrics.confusion_matrix function.\n",
    "    cm = metrics.confusion_matrix(true_labels, predicted_labels, labels=classes)\n",
    "    # Creates a Pandas DataFrame from the confusion matrix 'cm', using class names for index and columns.\n",
    "    cm_frame = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "    # Prints the title \"Confusion Matrix:\" to the console.\n",
    "    print(\"Confusion Matrix:\")\n",
    "    # Prints the Pandas DataFrame 'cm_frame' which represents the confusion matrix.\n",
    "    print(cm_frame)\n",
    "\n",
    "# Define function to display comprehensive model performance metrics\n",
    "def display_model_performance_metrics(true_labels, predicted_labels, classes):\n",
    "    \"\"\"Display model performance metrics.\"\"\"\n",
    "    # Prints a header indicating the start of model performance metrics display.\n",
    "    print(\"Model Performance Metrics:\")\n",
    "    # Prints a separator line for visual clarity.\n",
    "    print(\"-\" * 30)\n",
    "    # Calls the 'get_metrics' function to calculate and print accuracy, precision, recall, and F1 score.\n",
    "    get_metrics(true_labels, predicted_labels)\n",
    "    # Prints a header indicating the start of the classification report.\n",
    "    print(\"\\nClassification Report:\")\n",
    "    # Prints a separator line for visual clarity.\n",
    "    print(\"-\" * 30)\n",
    "    # Calls the 'display_classification_report' function to print the classification report.\n",
    "    display_classification_report(true_labels, predicted_labels, classes)\n",
    "    # Prints a header indicating the start of the confusion matrix display.\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    # Prints a separator line for visual clarity.\n",
    "    print(\"-\" * 30)\n",
    "    # Calls the 'display_confusion_matrix' function to print the confusion matrix.\n",
    "    display_confusion_matrix(true_labels, predicted_labels, classes)\n",
    "\n",
    "# Define a function to plot the Receiver Operating Characteristic (ROC) curve for a classification model.\n",
    "def plot_model_roc_curve(clf, features, true_labels, label_encoder=None, class_names=None):\n",
    "    \"\"\"Plot ROC curve for the model.\"\"\"\n",
    "    # Determine class labels from classifier, label encoder, or provided class names.\n",
    "    if hasattr(clf, \"classes_\"): # Check if the classifier object 'clf' has attribute 'classes_' (scikit-learn classifiers).\n",
    "        class_labels = clf.classes_ # Get class labels from the classifier object.\n",
    "    elif label_encoder: # If 'label_encoder' is provided.\n",
    "        class_labels = label_encoder.classes_ # Get class labels from the label encoder.\n",
    "    elif class_names: # If 'class_names' are directly provided.\n",
    "        class_labels = class_names # Use the provided class names.\n",
    "    else: # If class labels cannot be determined from any source.\n",
    "        raise ValueError(\"Unable to derive prediction classes!\") # Raise a ValueError exception indicating inability to get class labels.\n",
    "\n",
    "    n_classes = len(class_labels) # Get the number of classes.\n",
    "    y_test = label_binarize(true_labels, classes=class_labels) # Binarize true labels for ROC curve calculation, handling multi-class if necessary.\n",
    "\n",
    "    # For binary classification (2 classes).\n",
    "    if n_classes == 2:\n",
    "        # Get probability scores for the positive class (index 1) if 'predict_proba' is available, otherwise use 'decision_function'.\n",
    "        y_score = clf.predict_proba(features)[:, 1] if hasattr(clf, \"predict_proba\") else clf.decision_function(features)\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_score) # Calculate False Positive Rate, True Positive Rate, and thresholds for ROC curve.\n",
    "        roc_auc = auc(fpr, tpr) # Calculate Area Under the ROC Curve (AUC).\n",
    "        plt.plot(fpr, tpr, label=f\"ROC curve (area = {roc_auc:.2f})\", linewidth=2.5) # Plot ROC curve for binary class with AUC value in label.\n",
    "    # For multi-class classification (more than 2 classes).\n",
    "    else:\n",
    "        y_score = clf.predict_proba(features) if hasattr(clf, \"predict_proba\") else clf.decision_function(features) # Get probability scores for all classes.\n",
    "        for i in range(n_classes): # Iterate through each class.\n",
    "            fpr, tpr, _ = roc_curve(y_test[:, i], y_score[:, i]) # Calculate FPR, TPR for each class vs. rest.\n",
    "            roc_auc = auc(fpr, tpr) # Calculate AUC for each class.\n",
    "            plt.plot(fpr, tpr, label=f\"ROC curve of class {class_labels[i]} (area = {roc_auc:.2f})\", linestyle=\":\", linewidth=2) # Plot ROC curve for each class with AUC value and linestyle.\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\") # Plot the diagonal line representing random guessing.\n",
    "    plt.xlim([0.0, 1.0]) # Set x-axis limits from 0 to 1.\n",
    "    plt.ylim([0.0, 1.05]) # Set y-axis limits from 0 to 1.05.\n",
    "    plt.xlabel(\"False Positive Rate\") # Set x-axis label.\n",
    "    plt.ylabel(\"True Positive Rate\") # Set y-axis label.\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC) Curve\") # Set plot title.\n",
    "    plt.legend(loc=\"lower right\") # Display legend in the lower right corner.\n",
    "    plt.show() # Show the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fd760c-6794-42df-90bd-e19c5e2295e2",
   "metadata": {},
   "source": [
    "### Prepare features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50acfee-c56a-4ba6-bc17-2c101c3e9a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features: Select all columns except 'Outcome' as features (independent variables).\n",
    "X = df.drop(columns=['Outcome']).values\n",
    "# Target: Select the 'Outcome' column as the target variable (dependent variable), representing diabetes status (1=Diabetic, 0=Non-Diabetic).\n",
    "y = df['Outcome'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e60bde-bb21-48ec-a9f3-6db1ea0a03bf",
   "metadata": {},
   "source": [
    "### Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c01e676-13bf-4302-bb62-3721ea884e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing sets (80% train, 20% test)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print a header to indicate class distribution information is being displayed.\n",
    "print(\"\\nClass Distribution:\")\n",
    "# Print the class distribution (counts of each class) in the training labels (train_y).\n",
    "print(\"Train:\", Counter(train_y))\n",
    "# Print the class distribution (counts of each class) in the test labels (test_y).\n",
    "print(\"Test:\", Counter(test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef90994a-dff6-4f36-a3c2-2c1227a988d6",
   "metadata": {},
   "source": [
    "### Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0518256a-b41b-415d-9b1e-0da6b62d799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features using StandardScaler to standardize the training features.\n",
    "scaler = StandardScaler().fit(train_X)\n",
    "# Transform the training features 'train_X' using the fitted scaler and store the result in 'train_SX'.\n",
    "train_SX = scaler.transform(train_X)\n",
    "# Transform the test features 'test_X' using the fitted scaler and store the result in 'test_SX'.\n",
    "test_SX = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a652c2-ede8-4e32-ac47-41237477ea67",
   "metadata": {},
   "source": [
    "### Build and train the DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d882b7d7-4e84-4014-9e85-11cc180087e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Sequential Deep Neural Network model using Keras.\n",
    "\n",
    "# Your code goes here\n",
    "\n",
    "# Configures the model for training use 'Adam' as optimizer, 'binary_crossentropy' \n",
    "# as loss funciton, and 'accuracy' as evaluation metrics\n",
    "\n",
    "# Your code goes here\n",
    "\n",
    "# Train the compiled DNN model using the training data.\n",
    "history = model.fit(\n",
    "    train_SX, train_y,\n",
    "    epochs=10, # Train for 10 epochs.\n",
    "    batch_size=5, # Use a batch size of 5 during training.\n",
    "    validation_split=0.1, # Use 10% of the training data for validation.\n",
    "    verbose=1 # Display training progress for each epoch.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d693824-66f4-4dd9-84cf-ea939420635e",
   "metadata": {},
   "source": [
    "### Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9279a92d-88c6-44fb-8327-3bd302eaa6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance on test set\n",
    "# Predict class labels (0 or 1) for the test set based on probability threshold of 0.5.\n",
    "y_pred = (model.predict(test_SX) > 0.5).astype(int)\n",
    "# Display model performance metrics (accuracy, precision, recall, F1-score, confusion matrix, classification report).\n",
    "display_model_performance_metrics(test_y, y_pred, classes=[0, 1])\n",
    "\n",
    "# Plot training history\n",
    "# Create a new figure with a size of 12x4 inches for the plots.\n",
    "plt.figure(figsize=(12, 4))\n",
    "# Create the first subplot in a 1x2 grid (1 row, 2 columns), which is for accuracy.\n",
    "plt.subplot(1, 2, 1)\n",
    "# Plot the training accuracy from the training history.\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "# Plot the validation accuracy from the training history.\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "# Set the title of the accuracy subplot.\n",
    "plt.title('Accuracy')\n",
    "# Display the legend for the accuracy subplot.\n",
    "plt.legend()\n",
    "\n",
    "# Create the second subplot in a 1x2 grid (1 row, 2 columns), which is for loss.\n",
    "plt.subplot(1, 2, 2)\n",
    "# Plot the training loss from the training history.\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "# Plot the validation loss from the training history.\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "# Set the title of the loss subplot.\n",
    "plt.title('Loss')\n",
    "# Display the legend for the loss subplot.\n",
    "plt.legend()\n",
    "# Show the complete figure with both subplots.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2c34aa-6573-45cd-8daa-d81ecac0337f",
   "metadata": {},
   "source": [
    "### Prediction using new patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a72d906-da49-4300-add1-74b8535babb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create new sample data (replace with your desired sample data)\n",
    "# Define a dictionary 'new_samples_data' to hold data for new samples.\n",
    "new_samples_data = {\n",
    "    # Define data for 'Sample1' as a dictionary of features and their values.\n",
    "    'Sample1': {'Pregnancies': 2, 'Glucose': 100, 'BloodPressure': 70, 'SkinThickness': 25, 'Insulin': 50, 'BMI': 30.0, 'DiabetesPedigreeFunction': 0.5, 'Age': 35},\n",
    "    # Define data for 'Sample2' as a dictionary of features and their values.\n",
    "    'Sample2': {'Pregnancies': 8, 'Glucose': 180, 'BloodPressure': 90, 'SkinThickness': 35, 'Insulin': 100, 'BMI': 40.0, 'DiabetesPedigreeFunction': 1.0, 'Age': 50}\n",
    "}\n",
    "# Create a Pandas DataFrame 'new_samples_df' from the 'new_samples_data' dictionary, orienting it by index.\n",
    "new_samples_df = pd.DataFrame.from_dict(new_samples_data, orient='index')\n",
    "\n",
    "# 2. Preprocess the new samples using the SAME scaler fitted on training data\n",
    "# Transform the new sample data using the 'scaler' object (fitted on training data) to standardize features.\n",
    "new_samples_scaled = scaler.transform(new_samples_df)\n",
    "\n",
    "# 3. Make predictions\n",
    "# Get probability predictions from the 'model' for the scaled new samples.\n",
    "new_probabilities = model.predict(new_samples_scaled) # Get probabilities\n",
    "\n",
    "# 4. Display the predictions\n",
    "# Print a header to indicate predictions for new samples.\n",
    "print(\"\\n--- Predictions for New Samples ---\")\n",
    "# Iterate through the new samples using their index and sample name.\n",
    "for i, sample_name in enumerate(new_samples_data.keys()):\n",
    "    # Predict the class label (0 or 1) by thresholding the probability at 0.5.\n",
    "    prediction = (new_probabilities[i] > 0.5).astype(int)\n",
    "    # Calculate the probability of being 'non-diabetic' (class 0) in percentage.\n",
    "    probability_non_diabetic = new_probabilities[i][0] * 100 # Probability for 'non-diabetic' class\n",
    "    # Calculate the probability of being 'diabetic' (class 1) in percentage.\n",
    "    probability_diabetic = new_probabilities[i][1] * 100    # Probability for 'diabetic' class\n",
    "    # Print the sample name.\n",
    "    print(f\"Sample: {sample_name}\")\n",
    "    # Print the predicted outcome (class label).\n",
    "    print(f\"  Predicted Outcome: {prediction}\")\n",
    "    # Print the probability of being 'non-diabetic'.\n",
    "    print(f\"  Probability (non-diabetic): {probability_non_diabetic:.2f}%\")\n",
    "    # Print the probability of being 'diabetic'.\n",
    "    print(f\"  Probability (diabetic): {probability_diabetic:.2f}%\")\n",
    "    # Print a separator line for better readability.\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358618fa-761b-42d7-bb5f-9afa0e64b6b6",
   "metadata": {},
   "source": [
    "## **Conclusion**\n",
    "This notebook successfully demonstrated the development and evaluation of a Deep Neural Network model for diabetes prediction using the Pima Indians Diabetes Dataset. \n",
    "- We covered the essential steps of a machine learning workflow, including data loading, preprocessing, model building with TensorFlow/Keras, training, and performance evaluation. \n",
    "- The model achieved a reasonable level of accuracy in predicting diabetes based on the provided health metrics.\n",
    "- This example provides a foundation for understanding how deep learning can be applied to healthcare classification problems and can be further extended by exploring different model architectures, hyperparameter tuning, and feature engineering techniques to potentially improve prediction performance.\n",
    "\n",
    "## Clean up\n",
    "\n",
    "Remember to shut down your Jupyter Notebook environment and delete any unnecessary files or resources once you've completed the tutorial.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
