{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submodule 4 - Model Building, Evaluation, Interpretation, and Deployment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This submodule will explore various model types, model evaluation techniques, delve into interpretability methods, and\n",
    "learn best practices for real-world deployment, ensuring responsible and effective use of AI/ML.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "At the end of this module, you should be able to:\n",
    "\n",
    "- Gain a comprehensive understanding of the AI/ML model building process.\n",
    "- Master\n",
    "  essential techniques for evaluating model performance and identifying potential biases.\n",
    "- Develop skills in\n",
    "  interpreting AI/ML models and understanding their decision-making processes.\n",
    "- Learn about the challenges\n",
    "  and best practices for deploying AI/ML models in real-world biomedical settings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- An AWS account with access to Amazon SageMaker\n",
    "- Basic understanding of Python programming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Started\n",
    "\n",
    "- Watch the Lecture Videos.\n",
    "- Complete the Quizzes to solidify your understanding.\n",
    "- Enhance your programming skills with Tutorials.\n",
    "- Challenge yourself with the Exercises.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ML Models and Model Evaluation\n",
    "\n",
    "The lecture cover machine learning (ML) models and methods for evaluating their performance. A machine learning model defines the relationship between input (independent) and output (dependent) variables in a dataset. Various types of models exist based on the nature of the input-output relationship, including regression, classification, and clustering models.\n",
    "\n",
    "**Regression models**, such as linear and non-linear regression, are supervised learning methods primarily used for predictions involving continuous variables. Simple linear regression examines the linear relationship between one independent and one dependent variable, while multiple linear regression incorporates additional predictors. Non-linear regression models fit data using polynomial transformations and are also used for continuous output variables.\n",
    "\n",
    "**Classification models**, another category of supervised learning, output categorical labels instead of continuous values. They are widely used in tasks such as spam detection and image classification. These models include linear models (logistic regression), non-parametric models (k-nearest neighbors), tree-based methods (decision trees and random forests), and neural networks. Logistic regression, for instance, uses probability to classify inputs and supports binary, multi-class, and ordinal categorization. Support Vector Machines (SVM) and decision trees can handle both classification and regression tasks, offering flexible options depending on data structure and desired output.\n",
    "\n",
    "**Clustering models**, represent unsupervised learning techniques. These models group unlabeled data points based on similarity, commonly using methods like K-means (partition-based clustering), hierarchical clustering, and density-based clustering. K-means divides data into predefined groups, while hierarchical clustering creates a tree-like structure of data groupings, allowing for a flexible number of clusters. Density-based clustering forms clusters based on areas of high data density, though it may struggle with datasets that vary in density or dimension.\n",
    "\n",
    "The lecture also address model evaluation, essential for tuning models and enhancing prediction accuracy. For classification models, common evaluation metrics include accuracy, precision, recall, and the F1 score. The Receiver Operating Characteristic (ROC) curve and its Area Under the Curve (AUC) measure a classifier's effectiveness across different thresholds, ideally achieving a high AUC score. Regression model evaluation often relies on metrics like the Coefficient of Determination (R²) and Mean Squared Error (MSE) to quantify model fit and prediction error. Clustering models use external validation methods, such as homogeneity and completeness, as well as internal metrics like compactness and separation, to assess clustering quality.\n",
    "\n",
    "Overall this lecture provides a comprehensive overview of ML models and their respective evaluation strategies, emphasizing practical and theoretical approaches to ensure robust and effective model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture Video\n",
    "\n",
    "[Watch the video on Google Drive](https://drive.google.com/file/d/19Kq5k75-cGgBQpwQKBcx4eb1ab_Nwl66/view?usp=drive_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "# Youtube\n",
    "#YouTubeVideo(id=\"ml_models_and_model_evaluation\", height=200, width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture Slides\n",
    "\n",
    "Download the lecture slides [ML Models and Model Evaluation](Submodule_4/Lectures/Submodule_4_Lecture_1_ML_Models_and_Model_Evaluation.pptx).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quizzes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install jupyterquiz\n",
    "\n",
    "from jupyterquiz import display_quiz\n",
    "\n",
    "display_quiz(\n",
    "    \"Submodule_4/Quizzes/Submodule_4_Quiz_1_ML_Models_and_Model_Evaluation.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Tunning, Model Interpretation and Model Deployment\n",
    "\n",
    "The lecture focuses on three main aspects of machine learning: model tuning, interpretation, and deployment. Model tuning involves adjusting hyperparameters, which are preset parameters in an algorithm that guide the model's learning process but are not derived from the data itself. Examples include the learning rate in neural networks and the regularization penalty in logistic regression. Tuning aims to balance the bias-variance tradeoff, a critical factor in model performance. High bias can lead to underfitting, where the model fails to capture relevant patterns in the data, while high variance can lead to overfitting, where the model performs well on training data but poorly on new data. Techniques like cross-validation, specifically K-fold and leave-one-out cross-validation, are commonly used to evaluate and fine-tune models.\n",
    "\n",
    "Hyperparameter tuning strategies, such as grid search and randomized search, help optimize model performance. Grid search tests a range of values across specified hyperparameters, but requires manually defining the parameter grid. Randomized search, a variation, randomly samples from parameter distributions, often making it more efficient for large or complex datasets. These methods, combined with cross-validation, provide a structured approach to finding optimal hyperparameters.\n",
    "\n",
    "Model interpretation is essential for understanding how a model makes predictions, particularly in the case of complex or \"black box\" algorithms. Interpretable models, such as decision trees, provide direct insights into variable importance and feature interactions, making them easier to understand and trust. For more complex models, model-agnostic interpretation tools and techniques can be employed to enable both global and local explanations, helping to clarify how specific features influence predictions. These tools, such as SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Model-agnostic Explanations), allow practitioners to analyze the overall behavior of a model as well as individual predictions. Global interpretation techniques, like feature importance rankings or partial dependence plots, reveal the overall influence of features on the model's predictions, while local interpretation methods, such as SHAP values or LIME, explain individual predictions by highlighting the contribution of each feature to a specific outcome. This interpretability is critical for debugging models, identifying issues like bias or overfitting, and improving transparency. Additionally, it plays a key role in effectively communicating results to stakeholders, ensuring that model decisions are understandable and aligned with domain knowledge. By leveraging interpretable models and model-agnostic tools, practitioners can build more reliable, fair, and transparent machine learning systems.\n",
    "\n",
    "Finally, model deployment involves saving the trained model and making it accessible for future predictions. One common approach is model persistence, where the model is stored on a permanent medium and used for batch or real-time predictions. Another method is custom development, in which the prediction logic is separated from the training process, enabling scalable deployment solutions. Best practices in deployment emphasize adherence to the FAIR data principles—ensuring that data is findable, accessible, interoperable, and reusable, which promotes long-term model usability and reliability.\n",
    "\n",
    "This lecture provide an overview of model tuning, interpretation, and deployment, emphasizing practical techniques and considerations to maximize a model’s performance, interpretability, and utility in real-world applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture Video\n",
    "[Watch the video on Google Drive](https://drive.google.com/file/d/1r7FSGehmo61qn5NS1mm54V3lUsjHLgSw/view?usp=drive_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "# Youtube\n",
    "#YouTubeVideo(id=\"model_tunning_interpretation_deployment\", height=200, width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture Slides\n",
    "\n",
    "Download the lecture slides [Model Tunning, Model Interpretation, Model Deployment](Submodule_4/Lectures/Submodule_4_Lecture_2_Model_Tuning_Interpretation_Deployment.pptx).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quizzes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterquiz import display_quiz\n",
    "\n",
    "display_quiz(\n",
    "    \"Submodule_4/Quizzes/Submodule_4_Quiz_2_Model_Tuning_Interpretation_Deployment.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tutorials\n",
    "\n",
    "- [Model Building and Evaluation](Submodule_4/Tutorials/Submodule_4_Tutorial_1_Model_Building_and_Evaluation.ipynb)\n",
    "- [Model Tunning, Model Interpretation, Model Deployment](Submodule_4/Tutorials/Submodule_4_Tutorial_2_Model_Tunning_Interpretation_Deployment.ipynb)\n",
    "- [Predict Drug Activity for Androgen Receptor](Submodule_4/Tutorials/Submodule_4_Tutorial_3_Predict_Drug_Activity_for_Androgen_Receptor.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exercises\n",
    "\n",
    "- [Exploratory Analysis of Diabetes Risk Factors](Submodule_4/Exercises/Submodule_4_Exercise_1_Exploratory_Analysis_of_Diabetes_Risk_Factors.ipynb) ([Solution](Submodule_4/Exercises/Submodule_4_Exercise_1_Exploratory_Analysis_of_Diabetes_Risk_Factors_Solution.ipynb))\n",
    "- [Predicting Diabetes Risk](Submodule_4/Exercises/Submodule_4_Exercise_2_Predicting_Diabetes_Risk.ipynb) ([Solution](Submodule_4/Exercises/Submodule_4_Exercise_2_Predicting_Diabetes_Risk_Solution.ipynb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "This submodule covers machine learning (ML) models and their evaluation, tuning, interpretation, and deployment. ML models, such as regression, classification, and clustering, are used to analyze and predict patterns in data. Model evaluation metrics, like accuracy, precision, recall, F1-score, and AUC-ROC, assess their performance. Model tuning involves optimizing hyperparameters to balance bias-variance trade-off and improve accuracy. Model interpretation techniques, like decision trees, SHAP and LIME, help understand how models make predictions. Finally, model deployment involves saving and making models accessible for future use, adhering to FAIR data principles for long-term usability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "A reminder to shutdown VM and delete any relevant resources. <br><br>\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
